{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Testing Notebook: Calwebb_Detector1, Jump step\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: FGS, MIRI, NIRCam, NIRISS, NIRSpec \n",
    "\n",
    "Tested on MIRI Ground Test data\n",
    "\n",
    "### Table of Contents\n",
    "<div style=\"text-align: left\"> \n",
    "\n",
    "<br>  [Introduction](#intro_ID) <br> [Run JWST Pipelines](#pipeline_ID) <br> [Imports](#imports_ID) <br> [Read in Input files](#runpipeline_ID) <br> [Insert Cosmic Ray jumps to be tested and run pipeline](#runscript_ID)  <br> [About This Notebook](#about_ID) <br>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "# Introduction\n",
    "\n",
    "\n",
    "This test is designed to test the jump step in the calwebb_detector1 pipeline. This is the step that checks for outliers in each individual ramp and flags jumps (cosmic rays or other anomalies). For more information on the pipeline step visit the links below. \n",
    "\n",
    "Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/jump/index.html\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/jump\n",
    "\n",
    "The data for this test was taken as part of ground testing. The file was originally named MIRM107-E-6021041029_1_493_SE_2016-01-21T04h22m18.fits and is an Imaging file from test IMG-RAD-17 with a point source centered at pixel (702,452) with a slope value of around 300 DN/s. It consists of 5 integrations of 20 frames each. The file was processed into a format compatible with the pipeline using a script called create_data and renamed to jw04192001001_01101_00001_MIRIMAGE_uncal.fits.\n",
    "\n",
    "There are also two simulated data files used in the testing. In Build 7.8, the jump step was extended so that data files with 3 and 4 groups per integration will be flagged for jumps rather than skipping the jump step. Two data files meeting these criteria were created for this test.\n",
    "\n",
    "\n",
    "### Calibration WG Requested Algorithm: \n",
    "\n",
    "A short description and link to the page: https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Ramp+Jump+Detection\n",
    "\n",
    "\n",
    "### Defining Terms\n",
    "Definition of terms or acronymns.\n",
    "\n",
    "JWST: James Webb Space Telescope\n",
    "\n",
    "MIRI: Mid-Infrared Instrument\n",
    "\n",
    "\n",
    "\n",
    "### Description of test\n",
    "\n",
    "This test is performed by taking the uncal file which was the output of the script create_data, adding known cosmic ray jumps of varying strength at specified pixels and running it through the calibration pipeline to see if the pixels are flagged as jumps. The pipeline flags the four neighboring pixels of a jump detection if the jump is high enough (10 sigma?). It then checks to see if the single pixel cosmic ray was detected, and whether the neighboring pixels were also flagged.\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline_ID\"></a>\n",
    "## Run JWST Pipelines\n",
    "\n",
    "The file was run through the calwebb_detector1 pipeline, outputting the resulting file for the jump step specifically. When running the calwebb_detector1 pipeline, increase the threshold for a detection in the jump step from 4 sigma to 6 sigma to avoid a current issue where the jump detection step flags too many pixels as jumps. We should also use a different saturation file to make sure saturation is handled correctly (while waiting for an update to the reference file in CRDS).\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "data_dir = TemporaryDirectory()\n",
    "os.chdir(data_dir.name)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports_ID\"></a>\n",
    "# Imports\n",
    "The following packages will need to be imported for the scripts to work.\n",
    "\n",
    "\n",
    "* jwst.datamodels for opening files as a JWST Datamodel\n",
    "* jwst.pipeline to run the pipeline step/module\n",
    "* numpy for calculations\n",
    "* os for path information  \n",
    "* get_bigdata to retrieve data from artifactory\n",
    "* inspect to get the docstring of our objects.\n",
    "* IPython.display for printing markdown output\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "45177853-942e-4949-9e30-f544d70ef5f4"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from jwst.datamodels import RampModel, ImageModel, dqflags\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.jump import JumpStep\n",
    "\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "import inspect\n",
    "from IPython.display import Markdown\n",
    "import matplotlib.pyplot as plt\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needed to read in old file with DATAMODL=MIRIRampModel instead of RampModel\n",
    "os.environ['SKIP_FITS_UPDATE'] = 'false'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jwst\n",
    "jwst.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw python docstring and show definition for Pipeline\n",
    "raw = inspect.getdoc(JumpStep)\n",
    "\n",
    "# To convert to markdown, you need convert line breaks from \\n to <br />\n",
    "markdown_text = \"<br />\".join(raw.split(\"\\n\"))\n",
    "\n",
    "# Here you can format markdown as an output using the Markdown method.\n",
    "Markdown(\"\"\"\n",
    "# Jump Step\n",
    "---\n",
    "{}\n",
    "\"\"\".format(markdown_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"runpipeline_ID\"></a>\n",
    "# Read in input files\n",
    "\n",
    "Use artifactory to store both input and specified saturation file, then read them out with bigdata to run them through the pipeline.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in Input files\n",
    "\n",
    "\n",
    "input_files = ['jw04192001001_01101_00001_MIRIMAGE_uncal.fits', \n",
    "               'det_image_seq1_MIRIMAGE_F1130Wexp1_3groups.fits',\n",
    "               'det_image_seq1_MIRIMAGE_F1130Wexp1_4groups.fits']\n",
    "\n",
    "for file in input_files:\n",
    "    input_file = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'jump',\n",
    "                     'jump_miri_test',\n",
    "                     file)\n",
    "\n",
    "#This readnoise file is needed for use with simulated data which has higher readnoise than actual data.\n",
    "readnoise = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'jump',                     \n",
    "                     'jump_miri_test', \n",
    "                     'jwst_mirisim_readnoise.fits')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"runscript_ID\"></a>\n",
    "# Insert Cosmic Ray jumps to be tested and run pipeline\n",
    "\n",
    "Put in the locations and strengths of several cosmic rays, then run the pipeline on the data.\n",
    "\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put in cosmic ray jumps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set variables\n",
    "rej_thresh = 6.0  # rejection threshold for jump step\n",
    "\n",
    "# Choose selected pixels to put cr hits of varying fluxes in\n",
    "xpos = [460, 480, 500, 520, 540, 560, 580]\n",
    "ypos = [150, 150, 150, 150, 150, 150, 150]\n",
    "crmags = [10, 25, 50, 100, 200, 500, 1000]\n",
    "\n",
    "frame = 5  # frame to add cr\n",
    "integration = 0  # integration to add crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up parameters and run pipeline\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'jw04192001001_01101_00001_MIRIMAGE_uncal.fits'\n",
    "im = RampModel('jw04192001001_01101_00001_MIRIMAGE_uncal.fits')\n",
    "\n",
    "imagefile = str(im.meta.filename)\n",
    "print(imagefile)\n",
    "\n",
    "# loop through arrays of x, y and crmags to populate array with values\n",
    "for x, y, crmag in zip(xpos, ypos, crmags):\n",
    "    # add cr to ramps from point of 'frame' in ramp\n",
    "    im.data[integration, frame:, y, x] = im.data[integration, frame:, y, x] + crmag\n",
    "   \n",
    "# run cube with cr hits through jump\n",
    "# set up pipeline parameters for input\n",
    "pipe1 = Detector1Pipeline()\n",
    "pipe1.jump.rejection_threshold = rej_thresh\n",
    " \n",
    "# set up output file name\n",
    "base, remainder = imagefile.split('_uncal')\n",
    "print(base)\n",
    "outname = base\n",
    "\n",
    "pipe1.jump.save_results = True\n",
    "pipe1.jump.output_file = outname + '.fits'\n",
    "pipe1.ramp_fit.output_file = outname + '.fits'\n",
    "pipe1.output_file = outname + '.fits'\n",
    "\n",
    "\n",
    "# Run pipeline on file\n",
    "pipe1.run(im)\n",
    "\n",
    "print('Pipeline run finished')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in jump output and look for jump data quality flags\n",
    "\n",
    "Read in the jump output file and look in known locations to see whether the added cosmic rays were flagged as jumps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load jump step output file\n",
    "with RampModel('jw04192001001_01101_00001_MIRIMAGE_jump.fits') as jumpinput:\n",
    "    # raises exception if file is not the correct model\n",
    "    jumpim = jumpinput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for cr flags in dq grpdq array in specified locations\n",
    "dqframe = jumpim.groupdq[integration, frame, :, :]\n",
    "\n",
    "# print output on which fluxes had neighbors flagged\n",
    "# output should include pixel coord, average pixel value nearby, cr value, whether neighbors were flagged\n",
    "print('   xpos       ypos      crmag      avgcounts  pixflagged  neighborflagged \\n')\n",
    "for x, y, crmag in zip(xpos, ypos, crmags):\n",
    "    # check if pixel is flagged\n",
    "    # set default flag\n",
    "    pixflagged = False\n",
    "    neighborflagged = False\n",
    "\n",
    "    # get stats on flux values near cr hit\n",
    "    avgcounts = np.mean(im.data[integration, frame, y - 10: y - 5, x - 10: x - 5])\n",
    "\n",
    "    if dqframe[y, x] & dqflags.pixel['JUMP_DET'] > 0:\n",
    "        pixflagged = True\n",
    "        # check neighbor pixels\n",
    "        if ((dqframe[y + 1, x] & dqflags.pixel['JUMP_DET'] > 0) and\n",
    "            (dqframe[y - 1, x] & dqflags.pixel['JUMP_DET'] > 0) and\n",
    "            (dqframe[y, x + 1] & dqflags.pixel['JUMP_DET'] > 0) and\n",
    "            (dqframe[y, x - 1] & dqflags.pixel['JUMP_DET'] > 0)):\n",
    "                neighborflagged = True\n",
    "\n",
    "    # write output\n",
    "    print('{:8.0f} {:8.0f} {:10.0f} {:15.2f} {:>10} {:>10} \\n'.format(x, y, crmag, avgcounts, str(pixflagged), \n",
    "                                                                      str(neighborflagged)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data to see what is being flagged\n",
    "i=10\n",
    "nframes = im.meta.exposure.ngroups\n",
    "frames = np.arange(nframes)\n",
    "\n",
    "# set up titles for plot\n",
    "plt.xlabel('Frame number')\n",
    "plt.ylabel('DN value up the ramp')\n",
    "\n",
    "for x, y in zip(xpos, ypos):\n",
    "    # get locations of flagged pixels within the ramps\n",
    "    jumps = jumpim.groupdq[integration, :, y, x] & dqflags.pixel['JUMP_DET'] > 0\n",
    "    #print(jumps)\n",
    "    ramp = jumpim.data[integration, :, y, x]\n",
    "\n",
    "    #if jumps.any():\n",
    "        #print('Value of pixel with jump', ramp[jumps])\n",
    "        #print('Frame of pixel with jump', frames[jumps])\n",
    "\n",
    "    # plot ramps of selected pixels and flagged jumps\n",
    "    plt.plot(ramp+i*10)\n",
    "    plt.plot(frames[jumps], ramp[jumps]+i*10, color='r', marker='o')\n",
    "    i = i+10\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show region of dq array to see if cross pixels were flagged \n",
    "data = jumpim.groupdq[integration, frame, 140:160, 440:600]\n",
    "plt.imshow(data, cmap='Greys', origin='lower', vmin=0,vmax=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test if three and four group data is being flagged appropriately\n",
    "\n",
    "Read in data files with three and four group data (simulated files), run through detector1 and check if the pixels are being flagged and that not too many pixels are being flagged.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smallgroup_files = ['det_image_seq1_MIRIMAGE_F1130Wexp1_3groups.fits',\n",
    "                    'det_image_seq1_MIRIMAGE_F1130Wexp1_4groups.fits']\n",
    "\n",
    "# Run the calwebb_detector1 pipeline\n",
    "\n",
    "# set up pipeline parameters \n",
    "rej_thresh=10.0  # rejection threshold for jump step\n",
    "\n",
    "print('There are ', len(smallgroup_files), ' images.')\n",
    "                \n",
    "# loop over list of files\n",
    "for file in input_files:\n",
    "       \n",
    "    # set up pipeline parameters for input\n",
    "    pipe1 = Detector1Pipeline()\n",
    "    pipe1.jump.rejection_threshold = rej_thresh\n",
    "    pipe1.jump.override_readnoise = readnoise\n",
    "    pipe1.ramp_fit.override_readnoise = readnoise\n",
    "    \n",
    "    pipe1.refpix.skip = True  # needs update to simulator for this to work properly with simulated data\n",
    "    \n",
    "    # set up output file name\n",
    "    base, remainder = file.split('.')\n",
    "    outname = base\n",
    "        \n",
    "    pipe1.output_file = outname+'.fits'\n",
    "\n",
    "    # Run pipeline on each file\n",
    "    rampfile = pipe1.run(file)\n",
    "   \n",
    "print('Detector 1 steps completed on all files.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test that the jump step isn't flagging too many pixels for the jump step in three and four group data. (Look at all files, but there is a known issue in Build 7.8 where MIRI data with 3 and 4 group integrations get all pixels flagged as jumps.) This test will show when the problem is fixed in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in each ramp file output from outlier_detection and see percentage of pixels flagged as jumps\n",
    "ratefiles = glob.glob('*rate.fits')\n",
    "\n",
    "flag_thresh = 1.0  # Percentage above which user should be notified of high percentage of flagged pixels\n",
    "\n",
    "for slopefile in ratefiles: \n",
    "    file = ImageModel(slopefile)\n",
    "    nx = file.meta.subarray.xsize\n",
    "    ny = file.meta.subarray.ysize\n",
    "    filename = file.meta.filename\n",
    "    print(filename)\n",
    "\n",
    "    numpix = nx * ny\n",
    "    \n",
    "    # Count number of pixels flagged as JUMP_DET\n",
    "    jumpcount = (file.dq & dqflags.pixel['JUMP_DET'] > 0).sum()\n",
    "    print('There are ', jumpcount, ' pixels flagged as jumps.')\n",
    "    \n",
    "    percentflagged = (jumpcount / numpix) * 100.\n",
    "\n",
    "    print('The percentage of pixels flagged is ', percentflagged)\n",
    "    if percentflagged > flag_thresh:\n",
    "        print('This percentage is higher than it should be. Review data through jump step')\n",
    "    print('\\n')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** M. Cracraft, Senior Staff Scientist, INS/MIRI\n",
    "<br>**Updated On:** 07/28/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
