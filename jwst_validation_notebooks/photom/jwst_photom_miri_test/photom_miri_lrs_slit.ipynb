{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Testing Notebook: MIRI LRS Slit spectroscopy\n",
    "# Step: photom() in Spec2Pipeline\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: MIRI \n",
    "\n",
    "### Table of Contents\n",
    "<div style=\"text-align: left\"> \n",
    "\n",
    "<br> [Imports](#imports_ID) <br> [Introduction](#intro_ID) <br> [Get Documentaion String for Markdown Blocks](#markdown_from_docs) <br> [Loading Data](#data_ID) <br> [Run JWST Pipeline](#pipeline_ID) <br> [Create Figure or Print Output](#residual_ID) <br> [About This Notebook](#about_ID) <br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "data_dir = TemporaryDirectory()\n",
    "os.chdir(data_dir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports_ID\"></a>\n",
    "# Imports\n",
    "List the library imports and why they are relevant to this notebook.\n",
    "\n",
    "\n",
    "* os for simple operating system functions\n",
    "* gwcs.wcstools for bounding box operations\n",
    "* astropy.io for opening fits files\n",
    "* inspect to get the docstring of our objects.\n",
    "* IPython.display for printing markdown output\n",
    "* jwst.datamodels for building model for JWST Pipeline\n",
    "* jwst.module.PipelineStep is the pipeline step being tested\n",
    "* matplotlib.pyplot to generate plot\n",
    "* matplotlib.patches to plot shapes\n",
    "* crds for retrieving a reference file\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from scipy import interpolate\n",
    "from IPython.display import Markdown\n",
    "from jwst.pipeline import Detector1Pipeline, Spec2Pipeline, collect_pipeline_cfgs\n",
    "from jwst.associations.asn_from_list import asn_from_list\n",
    "from jwst.associations.lib.rules_level2_base import DMSLevel2bBase\n",
    "from jwst.background import BackgroundStep\n",
    "from jwst.assign_wcs import AssignWcsStep\n",
    "from jwst.extract_2d import Extract2dStep\n",
    "from jwst.flatfield import FlatFieldStep\n",
    "from jwst.photom import PhotomStep\n",
    "from gwcs.wcstools import grid_from_bounding_box\n",
    "import crds\n",
    "from jwst import datamodels\n",
    "from jwst.datamodels import ImageModel\n",
    "#from ci_watson.artifactory_helpers import get_bigdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.utils.data import download_file\n",
    "from pathlib import Path\n",
    "from shutil import move\n",
    "from os.path import splitext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "# Introduction\n",
    "\n",
    "\n",
    "For this test we are using the **photom** step for MIRI LRS slit data. For more information on the pipeline step visit the links below. \n",
    "\n",
    "Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/photom/main.html#imaging-and-non-ifu-spectroscopy\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/photom\n",
    "\n",
    "\n",
    "\n",
    "### Defining Term\n",
    "Here is where you will define terms or acronymns that may not be known a general audience (ie a new employee to the institute or an external user). For example\n",
    "\n",
    "- JWST: James Webb Space Telescope\n",
    "- MIRI: Mid-Infrared Instrument\n",
    "- LRS: Low Resolution Spectrometer\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Pipeline steps up to Photom\n",
    "\n",
    "The data used in this test is from Program 1536, observation of BD+60 1753, exposures 1 and 2 using the ALONG-SLIT-NOD dither pattern. In this program, two exposures are executed with the target at 30 and 70% along the length of the slit. These two observations are subtracted from each other for background subtraction, then co-added in the 3rd stage of the pipeline.\n",
    "\n",
    "In the first steps we run the Detector1 pipeline, and the Spec2 pipeline steps before **photom**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_files(file_list):\n",
    "    for box_url,file_name in file_list:\n",
    "        if 'https' not in box_url:\n",
    "            box_url = 'https://stsci.box.com/shared/static/' + box_url\n",
    "        downloaded_file = download_file(box_url)\n",
    "        if Path(file_name).suffix == '':\n",
    "            ext = splitext(box_url)[1]\n",
    "            file_name += ext\n",
    "        move(downloaded_file, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_urls = ['https://stsci.box.com/shared/static/4ccmk6jv9lf46jaxklh890d69oywvms7.fits','https://stsci.box.com/shared/static/mj948lyb01ge3aglqxhvy1bwd4bvx1gm.fits']\n",
    "files = ['jw01536027001_03102_00001_mirimage_uncal.fits','jw01536027001_03102_00002_mirimage_uncal.fits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_download_list = [(url,name) for url,name in zip(file_urls,files)]\n",
    "get_box_files(box_download_list)\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detector1 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det1 = []\n",
    "\n",
    "# Run pipeline on both files\n",
    "for ff in files:\n",
    "    d1 = Detector1Pipeline.call(ff, save_results=True)\n",
    "    det1.append(d1)\n",
    "\n",
    "print(det1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spec2Pipeline\n",
    "\n",
    "To run the Spec2Pipeline we first create an association file for the 2 exposures, assigning the nods as each others' backgrounds for background subtraction. We then run the Spec2Pipeline, skipping the final extract1d step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn_files = [det1[0].meta.filename, det1[1].meta.filename]\n",
    "bgr_files = [det1[1].meta.filename, det1[0].meta.filename]\n",
    "\n",
    "asn = asn_from_list(asn_files, rule=DMSLevel2bBase, meta={'program':'test', 'target':'bd60', 'asn_pool':'test'})\n",
    "\n",
    "# now add the opposite nod as background exposure:\n",
    "asn['products'][0]['members'].append({'expname':bgr_files[0], 'exptype':'background'})\n",
    "asn['products'][1]['members'].append({'expname':bgr_files[1], 'exptype':'background'})\n",
    "\n",
    "# write this out to a json file\n",
    "with open('sp2-lrs-slit-test_asn.json', 'w') as fp:\n",
    "    fp.write(asn.dump()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Spec2Pipeline()\n",
    "#pipe2.flat_field.save_results = True\n",
    "pipe2.pathloss.save_results = True\n",
    "pipe2.extract_1d.skip= True\n",
    "\n",
    "sp2 = pipe2('sp2-lrs-slit-test_asn.json')\n",
    "print(sp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ss in sp2:\n",
    "    print('Bounding box for {0}: {1}'.format(ss.meta.filename, ss.meta.wcs.bounding_box))\n",
    "    #bbox_w = photom_nod1.meta.wcs.bounding_box[0][1] - photom_nod1.meta.wcs.bounding_box[0][0]\n",
    "    #bbox_ht = photom_nod1.meta.wcs.bounding_box[1][1] - photom_nod1.meta.wcs.bounding_box[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=[12,10])\n",
    "ax[0].imshow(sp2[0].data, origin='lower', aspect='equal', interpolation='None')\n",
    "ax[0].set_title('Nod 1')\n",
    "ax[0].set_xlim([sp2[0].meta.wcs.bounding_box[0][0], sp2[0].meta.wcs.bounding_box[0][1]])\n",
    "ax[0].set_ylim([sp2[0].meta.wcs.bounding_box[1][0], sp2[0].meta.wcs.bounding_box[1][1]])\n",
    "\n",
    "ax[1].imshow(sp2[1].data, origin='lower', aspect='equal', interpolation='None')\n",
    "ax[1].set_title('Nod 2')\n",
    "ax[1].set_xlim([sp2[1].meta.wcs.bounding_box[0][0], sp2[1].meta.wcs.bounding_box[0][1]])\n",
    "ax[1].set_ylim([sp2[1].meta.wcs.bounding_box[1][0], sp2[1].meta.wcs.bounding_box[1][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the Photom() output\n",
    "\n",
    "We retrieve the reference file from crds and use that to perform an arithmetic check that the calibration step is correctly implemented at 5 randomly chosen test locations in the bounding box. We also perform a check that the WCS information is consistent between the nods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make waves\n",
    "ffig = plt.figure(figsize=[6,10])\n",
    "print('Point x    Point y   Wavelength')\n",
    "print('********************************')\n",
    "\n",
    "point1 = (317,290)\n",
    "ra1, dec1, wave1 = sp2[0].meta.wcs(point1[0],point1[1])\n",
    "print('  {0}       {1}   {2:.3f}'.format(point1[0], point1[1], wave1))\n",
    "\n",
    "\n",
    "point2 = (317,250)\n",
    "ra2, dec2, wave2 = sp2[0].meta.wcs(point2[0],point2[1])\n",
    "print('  {0}       {1}   {2:.3f}'.format(point2[0], point2[1], wave2))\n",
    "point3 = (310,225)\n",
    "ra3, dec3, wave3 = sp2[0].meta.wcs(point3[0],point3[1])\n",
    "print('  {0}       {1}   {2:.3f}'.format(point3[0], point3[1], wave3))\n",
    "point4 = (334,310)\n",
    "ra4, dec4, wave4 = sp2[0].meta.wcs(point4[0],point4[1])\n",
    "print('  {0}       {1}    {2:.3f}'.format(point4[0], point4[1], wave4))\n",
    "point5 = (340,200)\n",
    "ra5, dec5, wave5 = sp2[0].meta.wcs(point5[0],point5[1])\n",
    "print('  {0}       {1}   {2:.3f}'.format(point5[0], point5[1], wave5))\n",
    "plt.imshow(sp2[0].data, origin='lower', aspect='equal')\n",
    "\n",
    "xpts = [point1[0], point2[0], point3[0], point4[0], point5[0]]\n",
    "ypts = [point1[1], point2[1], point3[1], point4[1], point5[1]]\n",
    "\n",
    "\n",
    "plt.xlim([sp2[0].meta.wcs.bounding_box[0][0], sp2[0].meta.wcs.bounding_box[0][1]])\n",
    "plt.ylim([sp2[0].meta.wcs.bounding_box[1][0], sp2[0].meta.wcs.bounding_box[1][1]])\n",
    "\n",
    "\n",
    "plt.scatter([point1[0],point2[0],point3[0],point4[0],point5[0]],[point1[1],point2[1],point3[1],point4[1],point5[1]], color='yellow', marker='.')\n",
    "plt.colorbar()\n",
    "ffig.show()\n",
    "\n",
    "waves = [wave1, wave2, wave3, wave4, wave5]\n",
    "\n",
    "# Make waves2\n",
    "ffig = plt.figure(figsize=[6,10])\n",
    "print('Point x    Point y   Wavelength')\n",
    "print('********************************')\n",
    "\n",
    "point1 = (317,290)\n",
    "ra1, dec1, wave1 = sp2[1].meta.wcs(point1[0],point1[1])\n",
    "print('  {0}       {1}   {2:.3f}'.format(point1[0], point1[1], wave1))\n",
    "\n",
    "\n",
    "point2 = (317,250)\n",
    "ra2, dec2, wave2 = sp2[1].meta.wcs(point2[0],point2[1])\n",
    "print('  {0}       {1}   {2:.3f}'.format(point2[0], point2[1], wave2))\n",
    "point3 = (310,225)\n",
    "ra3, dec3, wave3 = sp2[1].meta.wcs(point3[0],point3[1])\n",
    "print('  {0}       {1}   {2:.3f}'.format(point3[0], point3[1], wave3))\n",
    "point4 = (334,310)\n",
    "ra4, dec4, wave4 = sp2[1].meta.wcs(point4[0],point4[1])\n",
    "print('  {0}       {1}    {2:.3f}'.format(point4[0], point4[1], wave4))\n",
    "point5 = (340,200)\n",
    "ra5, dec5, wave5 = sp2[1].meta.wcs(point5[0],point5[1])\n",
    "print('  {0}       {1}   {2:.3f}'.format(point5[0], point5[1], wave5))\n",
    "plt.imshow(sp2[0].data, origin='lower', aspect='equal')\n",
    "\n",
    "xpts = [point1[0], point2[0], point3[0], point4[0], point5[0]]\n",
    "ypts = [point1[1], point2[1], point3[1], point4[1], point5[1]]\n",
    "\n",
    "\n",
    "plt.xlim([sp2[1].meta.wcs.bounding_box[0][0], sp2[1].meta.wcs.bounding_box[0][1]])\n",
    "plt.ylim([sp2[1].meta.wcs.bounding_box[1][0], sp2[1].meta.wcs.bounding_box[1][1]])\n",
    "\n",
    "\n",
    "plt.scatter([point1[0],point2[0],point3[0],point4[0],point5[0]],[point1[1],point2[1],point3[1],point4[1],point5[1]], color='yellow', marker='.')\n",
    "plt.colorbar()\n",
    "ffig.show()\n",
    "\n",
    "waves2 = [wave1, wave2, wave3, wave4, wave5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the WCS information matches for both nods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    assert (ww1 == ww2 for ww1, ww2 in zip(waves, waves2))\n",
    "    print('Wavelengths for points match between nods: Passed')\n",
    "except:\n",
    "    print(\"AssertionError: Wavelengths for points don't match between nods\")\n",
    "\n",
    "#assert(ww1 == ww2 for ww1, ww2 in zip(waves, waves2)), \"wavelengths for points points don't match between nods\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will check the photometric calibration arithmetic.\n",
    "\n",
    "**Reminder** : The photom reference file contains a few single values, and then some columns. Amongst the initial single values is 'photmjsr', which is a conversion factor from DN/s to MJy/sr (reffile.phot_table['photmjsr']. Then there are wavelength and relresponse columns, which determine the wavelength-dependent part of the spectral response. At each given pixel, the DN/s slope value in the pathloss output file is multiplied by a conversion factor conv_factor, where conv_factor = reffile.phot_table['photmjsr'] * reffile.phot_table['relresponse'] (wave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reffile = [ss.meta.ref_file.photom.name for ss in sp2]\n",
    "print(reffile)\n",
    "\n",
    "try:\n",
    "    assert reffile[0]==reffile[1]\n",
    "    print('Nods use the same Photom reference file: Passed')\n",
    "except:\n",
    "    print(\"AssertionError: Nods do not use the same Photom reference file\")\n",
    "#assert reffile[0]==reffile[1], \"Nods do not use the same Photom reference file\"\n",
    "\n",
    "# if this test passes and both nods use the same ref file, then just load in once and use for both.\n",
    "basename = crds.core.config.pop_crds_uri(reffile[0])\n",
    "filepath = crds.locate_file(basename, \"jwst\")\n",
    "ref =  datamodels.open(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = interpolate.interp1d(ref.phot_table['wavelength'][0,:], ref.phot_table['relresponse'][0,:])\n",
    "iresp = [f(ww) for ww in waves]\n",
    "\n",
    "print(iresp)\n",
    "\n",
    "# plot for sanity check!\n",
    "plt.figure(figsize=[8,8])\n",
    "plt.plot(ref.phot_table['wavelength'][0,:], ref.phot_table['relresponse'][0,:])\n",
    "plt.plot(waves, iresp, 'rx', label='interpolated points')\n",
    "\n",
    "\n",
    "plt.xlim([4, 12])\n",
    "plt.ylim([0,15])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create the list of conversion factors for each of these points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ref.phot_table['photmjsr'])\n",
    "\n",
    "fconv = [ref.phot_table['photmjsr'][0] * ir for ir in iresp]\n",
    "print(fconv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we check that these conversion factors match the ratio of the data that has gone through up to path loss and the photom-calibrated data at the location of our chosen points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_files = glob.glob('*pathloss.fits')\n",
    "print(ff_files)\n",
    "pathloss = []\n",
    "\n",
    "for f in ff_files:\n",
    "    ffs = datamodels.open(f)\n",
    "    pathloss.append(ffs)\n",
    "\n",
    "print(ff)\n",
    "    \n",
    "# make sure we are combining the right nods for both files\n",
    "if '00001' in sp2[0].meta.filename:\n",
    "    if '00002' in ff_files[0]:\n",
    "        pathloss.reverse()\n",
    "\n",
    "if '00002' in sp2[0].meta.filename:\n",
    "    if '00001' in ff_files[0]:\n",
    "        pathloss.reverse()\n",
    "\n",
    "print([ss.meta.filename for ss in sp2])\n",
    "print([fff.meta.filename for fff in pathloss])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = grid_from_bounding_box(pathloss[0].meta.wcs.bounding_box)\n",
    "ra, dec, lam = pathloss[0].meta.wcs(x, y)\n",
    "\n",
    "lam_vec = np.mean(lam, axis=1)\n",
    "\n",
    "print(pathloss[0].meta.wcs.bounding_box)\n",
    "\n",
    "pathloss_test = pathloss[0].data[6:396, :]\n",
    "pho_test = sp2[0].data[6:396, :]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(lam_vec, pho_test[:,318])\n",
    "plt.plot(lam_vec, pathloss_test[:,318])\n",
    "plt.title('LRS slit test, calibrated')\n",
    "plt.ylabel('MJy/sr')\n",
    "plt.savefig('photom_slit_test_cal.png')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dratio = [sp2[0].data[yy,xx]/pathloss[0].data[yy,xx] for xx,yy in zip(xpts, ypts)]\n",
    "\n",
    "# print these numbers next to each other to see if they match\n",
    "print('Ratio of data points     Calculated conversion factor')\n",
    "for rr, ff in zip(dratio, fconv):\n",
    "    print('{0:.5f}                {1:.5f}'.format(rr,ff))\n",
    "    \n",
    "    try:\n",
    "        assert np.isclose(rr,ff, rtol=1e-6)\n",
    "        print('Nods match to within 1e-6: Passed')\n",
    "    except:\n",
    "        print(\"AssertionError: Numbers don't match to within 1e-6\")\n",
    "    #assert np.isclose(rr,ff, rtol=1e-6), \"Numbers don't match to within 1e-6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check the same for Nod 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dratio2 = [sp2[1].data[yy,xx]/pathloss[1].data[yy,xx] for xx,yy in zip(xpts, ypts)]\n",
    "\n",
    "# print these numbers next to each other to see if they match\n",
    "print('Ratio of data points     Calculated conversion factor')\n",
    "for rr, ff in zip(dratio, fconv):\n",
    "    print('{0:.5f}                 {1:.5f}'.format(rr,ff))\n",
    "    try:\n",
    "        assert np.isclose(rr,ff, rtol=1e-6)\n",
    "        print('Nods match to within 1e-6: Passed')\n",
    "    except:\n",
    "        print(\"AssertionError: Numbers don't match to within 1e-6\")\n",
    "    #assert np.isclose(rr,ff, rtol=1e-6), \"Numbers don't match to within 1e-6\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If these tests return no AssertionErrors, the test has passed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Authors:\n",
    "* K. Murray, kmurray@stsci.edu, MIRI Branch\n",
    "* S. Kendrew, ssarah.kendrew@esa.int, ESA/MIRI Branch\n",
    "\n",
    "Last updated:\n",
    "March 17 2023"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
