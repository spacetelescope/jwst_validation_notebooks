{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Testing Notebook: Calwebb_Detector1 for MIRI TSO imaging\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: MIRI\n",
    "\n",
    "Tested on MIRI Simulated data\n",
    "\n",
    "### Table of Contents\n",
    "<div style=\"text-align: left\"> \n",
    "\n",
    "<br>  [Introduction](#intro_ID) <br> [Imports](#imports_ID) <br>[Run JWST Pipeline](#pipeline_ID) <br> [Examine Input and Output Data](#examine_data)  <br> [About This Notebook](#about_ID) <br>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "# Introduction\n",
    "\n",
    "This notebook is meant to process a data set through the Detector1 pipeline for TSO imaging data (calwebb_tso1). The steps are as follow:\n",
    "\n",
    "1) Read in an uncalibrated TSO imaging file.\n",
    "\n",
    "2) Process through calwebb_detctor1 using parameters set in calwebb_tso1.cfg.\n",
    "\n",
    "3) Test various steps and outputs from the pipeline run.\n",
    "\n",
    "These steps are set up with an example simulated MIRI dataset.\n",
    "\n",
    "The pipeline documentation can be found here: https://jwst-pipeline.readthedocs.io/en/latest/\n",
    "\n",
    "The pipeline code is available on GitHub: https://github.com/spacetelescope/jwst\n",
    "\n",
    "### Defining Terms\n",
    "\n",
    "Here is where you will define terms or acronymns that may not be known a general audience (ie a new employee to the institute or an external user). For example\n",
    "\n",
    "    JWST: James Webb Space Telescope\n",
    "    MIRI: Mid-Infrared Instrument\n",
    "    LRS: Low Resolution Spectrometer\n",
    "    TSO: Time Series Observation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports_ID\"></a>\n",
    "## Imports\n",
    "\n",
    "* jwst.datamodels for building model for JWST Pipeline\n",
    "* jwst.pipeline is the pipeline being tested\n",
    "* matplotlib.pyplot.plt to generate plot\n",
    "* numpy for array calculations and manipulation\n",
    "* pysiaf to get coordinates of MIRI apertures \n",
    "* astropy.io and download_file allow downloading and accessing files\n",
    "* ci_watson and get_bigdata allow accessing files stored in artifactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits, ascii\n",
    "from astropy.utils.data import download_file\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "from jwst.datamodels import RampModel, ImageModel, dqflags, CubeModel\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pysiaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in file and update headers to have needed keywords for TSO mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "data_dir = TemporaryDirectory()\n",
    "os.chdir(data_dir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkheaders(model):\n",
    "    \n",
    "    # check that header has keyword TSOVISIT set to true (all TSO data should have this set)\n",
    "    \n",
    "    if model.meta.visit.tsovisit != True:\n",
    "        model.meta.visit.tsovisit = True\n",
    "        print('Setting TSOVISIT keyword')\n",
    "        \n",
    "    # check that CRPIX1 and CRPIX2 are set to the center of the siaf aperture for the array being used.\n",
    "    # Read in array being used\n",
    "    array = model.meta.subarray.name\n",
    "    print(array)\n",
    "    if array == 'FULL':\n",
    "        siaf = pysiaf.Siaf('MIRI') \n",
    "        full = siaf['MIRIM_FULL']\n",
    "        model.meta.wcsinfo.crpix1 = full.XSciRef\n",
    "        model.meta.wcsinfo.crpix2 = full.YSciRef\n",
    "    if array == 'SUB64':\n",
    "        # subarray siaf values are not quite right in MIRISim. Need to centroid to find x and y\n",
    "        # start with siaf values\n",
    "        siaf = pysiaf.Siaf('MIRI')\n",
    "        sub = siaf['MIRIM_SUB64']\n",
    "        x_initial = sub.XSciRef - 8 # known 8 pixel shift in subarray source position fixed in latest MIRISim\n",
    "        y_initial = sub.YSciRef\n",
    "        \n",
    "        print(x_initial, y_initial)\n",
    "        \n",
    "        # Take initial estimate and centroid to find source\n",
    "        center = centroids.centroid_sources(model.data[0,0,:,:], x_initial, y_initial, box_size=11)\n",
    "        xcentroid = center[0][0]\n",
    "        ycentroid = center[1][0]\n",
    "        \n",
    "        print(center[0][0], center[1][0])   \n",
    "        model.meta.wcsinfo.crpix1 = xcentroid\n",
    "        model.meta.wcsinfo.crpix2 = ycentroid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline_ID\"></a>\n",
    "## Run JWST Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up parameters for individual steps and run calwebb_detector1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up pipeline parameters and file names\n",
    "# Input file names\n",
    "\n",
    "# This section to download data from remote box directory and run local\n",
    "mainurl =\"https://data.science.stsci.edu/redirect/JWST/TSO/pipeline_testing_miri_ima_tso/\"\n",
    "filename = 'pipetest_miri_imtso_FULL_10g10i_F770W.fits'\n",
    "file = download_file(mainurl+filename)\n",
    "\n",
    "# open file into correct format and write to local disk for processing\n",
    "with fits.open(file) as hdu:\n",
    "    hdu.info()\n",
    "    hdu.writeto(filename)\n",
    "\n",
    "satfile = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'jump',\n",
    "                     'jump_miri_test', \n",
    "                     'miri_sat_55k.fits')\n",
    "\n",
    "readnoisefile = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'jump',\n",
    "                     'jump_miri_test', \n",
    "                     'jwst_mirisim_readnoise.fits')\n",
    "\n",
    "tag='_b75_tso'  # string tag to distinguish different tests in output file name\n",
    "\n",
    "# Read in data file to model    \n",
    "with RampModel(filename) as modelinput:\n",
    "    # raises exception if file is not the correct model\n",
    "    model = modelinput"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step we pick 7 pixel locations, and manually add in jumps that represent cosmic ray hits. The magnitude of the hit is different for each. The hit is added in frame 5 (zero-indexed), first integration. This will be used for testing the jump detection step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cosmic ray jump testing by adding in cosmic rays\n",
    "# set variables\n",
    "\n",
    "# Choose selected pixels to put cr hits of varying fluxes in\n",
    "xpos = [460, 480, 500, 520, 540, 560, 580]\n",
    "ypos = [150, 150, 150, 150, 150, 150, 150]\n",
    "crmags = [10, 25, 50, 100, 200, 500, 1000]\n",
    "\n",
    "frame = 5  # frame to add cr\n",
    "integration = 0  # integration to add crs\n",
    "    \n",
    "# loop through arrays of x, y and crmags to populate array with values\n",
    "for x, y, crmag in zip(xpos, ypos, crmags):\n",
    "    # add cr to ramps from point of 'frame' in ramp\n",
    "    model.data[integration, frame:, y, x] = model.data[integration, frame:, y, x] + crmag    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we run the Detector1 pipeline. The jump detection threshold is set manually; this is important again for jump step testing. A number of reference files are overridden with versions that are compatible with MIRISim simulated data.\n",
    "\n",
    "As we are not running with the tso1 config file, we have to ensure a few steps are skipped manually:\n",
    "* ipc\n",
    "* first frame correction\n",
    "* last frame correction\n",
    "* refpix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detector1 pipeline\n",
    "\n",
    "# step parameters\n",
    "rej_thresh=8.0  # rejection threshold for jump step (higher for simulated data)\n",
    "    \n",
    "# set up pipeline parameters for input\n",
    "pipe1 = Detector1Pipeline()\n",
    "pipe1.jump.rejection_threshold = rej_thresh\n",
    "pipe1.saturation.override_saturation = satfile\n",
    "pipe1.jump.override_readnoise = readnoisefile\n",
    "pipe1.ramp_fit.override_readnoise = readnoisefile\n",
    "\n",
    "# skip steps to make it like 'tso1 config file'\n",
    "pipe1.ipc.skip = True\n",
    "pipe1.firstframe.skip = True\n",
    "pipe1.lastframe.skip = True\n",
    "    \n",
    "# Until MIRISim is updated, best to skip refpix step for simulated data\n",
    "pipe1.refpix.skip = True\n",
    "\n",
    "# check that header has needed keywords set\n",
    "        \n",
    "checkheaders(model)\n",
    "\n",
    "nints = model.meta.exposure.nints\n",
    "print('CRPIX1 = ',model.meta.wcsinfo.crpix1)\n",
    "print('CRPIX2 = ',model.meta.wcsinfo.crpix2)\n",
    "    \n",
    "# set up output file name\n",
    "base, remainder = filename.split('.')\n",
    "\n",
    "outname = base+tag\n",
    "print(outname)\n",
    "\n",
    "pipe1.saturation.output_file = outname+'.fits'\n",
    "pipe1.jump.output_file = outname+'.fits'    \n",
    "pipe1.ramp_fit.output_file = outname+'.fits'\n",
    "pipe1.output_file = outname+'.fits'\n",
    "            \n",
    "# Run pipeline on each file\n",
    "pipe1.run(model) \n",
    "\n",
    "print('Detector 1 steps completed.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(outname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"examine_data\"></a>\n",
    "## Examine input and output data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Take a look at the input data\n",
    "* Look at the last frame\n",
    "* plot a pixel up the ramp from the source\n",
    "* plot a pixel up the ramp from the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_data = model.data\n",
    "\n",
    "ngroups = model.meta.exposure.ngroups\n",
    "nints = model.meta.exposure.nints\n",
    "\n",
    "# identify a science pixel\n",
    "sci_px = [512, 692]\n",
    "\n",
    "# identify a pixel in blank sky\n",
    "bgr_px = [560, 915]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=[12,4])\n",
    "\n",
    "# plot 1: frame[-1] in the first integration\n",
    "lastgrp = ax[0].imshow(sci_data[0,ngroups-1,:,:], origin='lower', interpolation='None', aspect='equal', cmap='Greys',\n",
    "                      vmin=10000, vmax=12000)\n",
    "ax[0].scatter(sci_px[1], sci_px[0], marker='x', color='r', label='sci pixel')\n",
    "ax[0].scatter(bgr_px[1], bgr_px[0], marker='+', color='y', label='bgr pixel')\n",
    "ax[0].set_title('Group {} Int 0'.format(ngroups-1))\n",
    "ax[0].set_xlabel('px')\n",
    "ax[0].set_ylabel('px')\n",
    "\n",
    "# plot 2: pixel slope, spectrum\n",
    "\n",
    "ax[1].set_title('Slopes, sci pixel (red x)')\n",
    "for i in range(nints):\n",
    "    ax[1].plot(sci_data[i, :, sci_px[0], sci_px[1]])\n",
    "ax[1].set_xlabel('integration')\n",
    "ax[1].set_ylabel('DN')\n",
    "\n",
    "# plot 3: pixel slope, background\n",
    "\n",
    "ax[2].set_title('Slopes, bgr pixel (yellow +)')\n",
    "for i in range(nints):\n",
    "    ax[2].plot(sci_data[i, :, bgr_px[0], bgr_px[1]])\n",
    "ax[2].set_xlabel('integration')\n",
    "ax[2].set_ylabel('DN')\n",
    "\n",
    "fig.colorbar(lastgrp, ax=ax[0])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test individual output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Saturation output\n",
    "\n",
    "The saturation step should flag any saturated pixels in the DQ extension. We check this here by stepping through each integration and looking at the pixel values in a 25 x 25 px box, and checking the maximum counts against the groupdq attribute of the saturation output model. \n",
    "\n",
    "The code below should check that pixels with counts > satvalue are flagged, and report an error if the groupdq flag is incorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# read in file output from saturation step\n",
    "\n",
    "with RampModel(outname+'_saturation.fits') as satmodel:\n",
    "    # raises exception if file is not the correct model\n",
    "    data = satmodel.data\n",
    "    satdq = satmodel.groupdq\n",
    "\n",
    "satvalue = 55000\n",
    "print('Saturation level is: ', satvalue, ' counts.')\n",
    "\n",
    "# Test last frame of each integration for saturation and see if it was flagged.\n",
    "\n",
    "ngroups = model.meta.exposure.ngroups\n",
    "nints = model.meta.exposure.nints\n",
    "\n",
    "for integration in range(nints):\n",
    "    # check last frame for saturation in region of star\n",
    "    box = data[integration, ngroups-1 , 500:525, 680:705]\n",
    "    print()\n",
    "    print('Max value in 25x25 box around star position: ',np.nanmax(box))\n",
    "    satframe = satdq[integration, ngroups-1, 500:525, 680:705 ]\n",
    "    \n",
    "    satpix = (box >= satvalue)\n",
    "\n",
    "    # if pixels greater than value, then check that they are flagged\n",
    "    if satpix.any():\n",
    "        print('Saturation detected in last frame of integration: ', integration)\n",
    "        assert np.all(satframe[satpix] == dqflags.group['SATURATED'])\n",
    "    else:\n",
    "        print('No pixels saturate in last frame of integration: ', integration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at plots of output\n",
    "Compare the slope image from the _rate output file to the median of the slopes of the _rateints file. They should be similar in appearance and flux levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this plot will compare the slope image from the _rate file with the median of the slope images in the rateints file\n",
    "# check criterion: they should look similar and the maximim values seen in both these images should be similar\n",
    "\n",
    "#with ImageModel(outname+'_rate.fits') as rmod:\n",
    "    # raises exception if file is not the correct model\n",
    "#    rdata = rmod.data\n",
    " \n",
    "#with CubeModel(outname+'_rateints.fits') as rimod:\n",
    "    # raises exception if file is not the correct model\n",
    "#    rimoddata = rimod.data\n",
    "\n",
    "rmod = ImageModel(outname+'_rate.fits')\n",
    "rdata = rmod.data\n",
    "rimod = CubeModel(outname+'_rateints.fits')\n",
    "rimoddata = rimod.data\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=[8,10])\n",
    "\n",
    "rplt = ax[0].imshow(rdata, origin='lower', aspect='equal', interpolation='None', vmin=0, vmax=10)\n",
    "ax[0].set_title('Integrated rate file slope image')\n",
    "ax[0].set_xlabel('px')\n",
    "ax[0].set_ylabel('px')\n",
    "\n",
    "riplt = ax[1].imshow(np.median(rimoddata, axis=0), origin='lower', aspect='equal', interpolation='None',\n",
    "                    vmin=0, vmax=10)\n",
    "ax[1].set_title('Median of rateints file slope images')\n",
    "ax[1].set_xlabel('px')\n",
    "ax[1].set_ylabel('px')\n",
    "\n",
    "cbar = fig.colorbar(rplt, ax=ax, orientation='horizontal')\n",
    "cbar.set_label('DN/s')\n",
    "#fig.tight_layout()\n",
    "\n",
    "print('Max DN/s in the rate.fits slope image: {} DN/s'.format(np.max(rdata)))\n",
    "print('Max DN/s of the median of the rateints.fits slope images: {} DN/s'.format(np.nanmax(np.median(rimoddata, axis=0))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test output of jump step to see if specified pixels (and their neighbors) were flagged\n",
    "\n",
    "In this step we check the output of the jump detection step. This looks at the pixels to which a CR hit was added above, and checks whether they were flagged. The threshold can be adjusted above, and the step re-run to check consistence with the input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load jump step output file\n",
    "with RampModel(outname+'_jump.fits') as jumpim:\n",
    "    # raises exception if file is not the correct model\n",
    "    jumpdata = jumpim.data\n",
    "    jumpdq = jumpim.groupdq\n",
    "    \n",
    "integration = 0\n",
    "frame = 5\n",
    "\n",
    "# look for cr flags in dq grpdq array in specified locations\n",
    "dqframe = jumpdq[integration, frame, :, :]\n",
    "\n",
    "# print output on which fluxes had neighbors flagged\n",
    "# output should include pixel coord, average pixel value nearby, cr value, whether neighbors were flagged\n",
    "print('   xpos       ypos      crmag      avgcounts  pixflagged  neighborflagged \\n')\n",
    "for x, y, crmag in zip(xpos, ypos, crmags):\n",
    "    # check if pixel is flagged\n",
    "    # set default flag\n",
    "    pixflagged = False\n",
    "    neighborflagged = False\n",
    "\n",
    "    # get stats on flux values near cr hit\n",
    "    avgcounts = np.mean(jumpdata[integration, frame, y - 10: y - 5, x - 10: x - 5])\n",
    "\n",
    "    if dqframe[y, x] & dqflags.pixel['JUMP_DET'] > 0:\n",
    "        pixflagged = True\n",
    "        # check neighbor pixels\n",
    "        if ((dqframe[y + 1, x] & dqflags.pixel['JUMP_DET'] > 0) and\n",
    "            (dqframe[y - 1, x] & dqflags.pixel['JUMP_DET'] > 0) and\n",
    "            (dqframe[y, x + 1] & dqflags.pixel['JUMP_DET'] > 0) and\n",
    "            (dqframe[y, x - 1] & dqflags.pixel['JUMP_DET'] > 0)):\n",
    "                neighborflagged = True\n",
    "\n",
    "    # write output\n",
    "    print('{:8.0f} {:8.0f} {:10.0f} {:15.2f} {:>10} {:>10} \\n'.format(x, y, crmag, avgcounts, str(pixflagged), \n",
    "                                                                      str(neighborflagged)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot data to see what is being flagged\n",
    "i=10\n",
    "nframes = model.meta.exposure.ngroups\n",
    "frames = np.arange(nframes)\n",
    "\n",
    "# set up titles for plot\n",
    "plt.xlabel('Frame number')\n",
    "plt.ylabel('DN value up the ramp')\n",
    "\n",
    "for x, y in zip(xpos, ypos):\n",
    "    # get locations of flagged pixels within the ramps\n",
    "    jumps = jumpdq[integration, :, y, x] & dqflags.pixel['JUMP_DET'] > 0\n",
    "    ramp = jumpdata[integration, :, y, x]\n",
    "\n",
    "    # plot ramps of selected pixels and flagged jumps\n",
    "    plt.plot(ramp+i*10)\n",
    "    plt.plot(frames[jumps], ramp[jumps]+i*10, color='r', marker='o')\n",
    "    i = i+10\n",
    "\n",
    "#plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show region of dq array to see if cross pixels were flagged \n",
    "data = jumpdq[integration, frame, 140:160, 440:600]\n",
    "plt.imshow(data, cmap='Greys', origin='lower', vmin=0,vmax=5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSCD testing\n",
    "The RSCD step at the moment simply flags frames as 'DO_NOT_USE' in the groupdq array to avoid the frames that show the rscd effect being used for ramp fitting.\n",
    "\n",
    "For FULL frame FAST mode data, the RSCD reference file indicates that the first four frames in all integrations greater than 1 (or 0 for 0-indexing), should be flagged as 'DO_NOT_USE', which is indicated by a value 1 in the groupdq array. If the value of the flag in the frame is odd, then this frame has been correctly flagged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the groupdq output of the jump step to test whether the proper frames are flagged.\n",
    "# Choose any pixel in the frame (500, 500) to test, since they should all be flagged the same.\n",
    "\n",
    "print(jumpdq[:,:,500,500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** Misty Cracraft, Senior Staff Scientist, MIRI Branch\n",
    "<br>**Updated On:** 07/28/2020"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
