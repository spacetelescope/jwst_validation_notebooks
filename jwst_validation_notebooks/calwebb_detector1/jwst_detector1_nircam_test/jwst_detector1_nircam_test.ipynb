{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Notebook: calwebb_detector1, NIRCam imaging\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: e.g., NIRCam \n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "<div style=\"text-align: left\"> \n",
    "    \n",
    "<br> [Introduction\\*](#intro)\n",
    "<br> [JWST CalWG Algorithm\\*](#algorithm)\n",
    "<br> [Defining Terms](#terms)\n",
    "<br> [Test Description\\*](#description)\n",
    "<br> [Data Description\\*](#data_descr)\n",
    "<br> [Imports\\*](#imports)\n",
    "<br> [Convenience Functions](#convenience_functions)\n",
    "<br> [Loading the Data\\*](#download_data)\n",
    "<br> [calwebb_detector1 - Ramps to slopes](#detector1) \n",
    "<br> [Run the entire pipeline](#detector1_at_once)\n",
    "<br> [Run the individual pipeline steps](#detector1_step_by_step)\n",
    "    <br> [The `Data Quality Initialization` step](#dq_init)\n",
    "    <br> [The `Saturation Flagging` step](#saturation)\n",
    "    <br> [The `Superbias Subtraction` step](#superbias)\n",
    "    <br> [The `Reference Pixel Subtraction` step](#refpix)\n",
    "    <br> [The `Linearity Correction` step](#linearity)\n",
    "    <br> [The `Persistence Correction` step](#persistence)\n",
    "    <br> [The `Dark Current Subtraction` step](#dc)\n",
    "    <br> [The `Cosmic Ray Flagging` step](#jump)\n",
    "    <br> [The `Ramp_Fitting` step](#ramp_fitting)\n",
    "<br> [About This Notebook\\*](#about)\n",
    "<br>    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "# Introduction\n",
    "\n",
    "This is the validation notebook for Stage 1 of the JWST calibration pipeline, also known as *calwebb_detector1*. The [Stage 1 pipeline](https://jwst-pipeline.readthedocs.io/en/stable/jwst/pipeline/calwebb_detector1.html#calwebb-detector1) applies basic detector-level corrections to all exposure types (imaging, spectroscopic, coronagraphic, etc.). It is applied to one exposure at a time, beginning with an uncalibrated multiaccum ramp (*_uncal.fits file*). It is sometimes referred to as “ramps-to-slopes” processing. The output is a corrected but uncalibrated countrate or slope image (*_rate.fits and _rateints.fits file*). \n",
    "\n",
    "Pipeline description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"algorithm\"></a>\n",
    "# JWST CalWG Algorithm\n",
    "\n",
    "This stage takes the raw images and returns the level 2a files, calibrated to slope (counts/sec) images.\n",
    "The current status of the algorithms for this pipeline stage is summarized on the JWST CalWG algorithm Confluence page.  Links are provided to individual pages where the details of the algorithms are given along with notes on why those algorithms were picked.\n",
    "\n",
    "The algorithms for each step in each pipeline stage are split into \"baseline\" and \"enhanced\" versions (formerly known as \"vanilla\" and \"optimal\", respectively).  See Baseline and Enhanced Algorithms for more details.\n",
    "Input/Outputs of this stage refer to the main data products for the pipeline process. The full list of archive products for this (and all stages of the pipeline) is tabulated in Archive Products.\n",
    "\n",
    "[JWST CalWG algorithms for calwebb_detector1](https://outerspace.stsci.edu/display/JWSTCC/CALWEBB_DETECTOR1)\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"terms\"></a>\n",
    "# Defining Terms\n",
    "\n",
    "\n",
    "**JWST**: James Webb Space Telescope\n",
    "\n",
    "**NIR**: Near Infrared\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"description\"></a>\n",
    "# Test Description\n",
    "\n",
    "This test is performed by running simulated data through the full pipeline and performing a visual inspection of the outputs. Next, the notebook does quick checks after each step in the calwebb_detector1 pipeline, based on the algorithms defined. \n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_descr\"></a>\n",
    "# Data Description\n",
    "\n",
    "For this module, we will use an uncalibrated NIRCam simulated imaging exposure generated with Mirage.\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tempdir\"></a>\n",
    "# Set up Temporary Directory\n",
    "The following cell sets up a temporary directory (using python's `tempfile.TemporaryDirectory()`), and changes the script's active directory into that directory (using python's `os.chdir()`). This is so that, when the notebook is run through, it will download files to (and create output files in) the temporary directory rather than in the notebook's directory. This makes cleanup significantly easier (since all output files are deleted when the notebook is shut down), and also means that different notebooks in the same directory won't interfere with each other when run by the automated webpage generation process.\n",
    "\n",
    "If you want the notebook to generate output in the notebook's directory, simply don't run this cell.\n",
    "\n",
    "If you have a file (or files) that are kept in the notebook's directory, and that the notebook needs to use while running, you can copy that file into the directory (the code to do so is present below, but commented out).\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****\n",
    "#\n",
    "# Set this variable to False to not use the temporary directory\n",
    "#\n",
    "#****\n",
    "use_tempdir = True\n",
    "\n",
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if use_tempdir:\n",
    "    data_dir = TemporaryDirectory()\n",
    "\n",
    "    # If you have files that are in the notebook's directory, but that the notebook will need to use while\n",
    "    # running, copy them into the temporary directory here.\n",
    "    #\n",
    "    # files = ['name_of_file']\n",
    "    # for file_name in files:\n",
    "    #     shutil.copy(file_name, os.path.join(data_dir.name, file_name))\n",
    "\n",
    "    # Save original directory\n",
    "    orig_dir = os.getcwd()\n",
    "\n",
    "    # Move to new directory\n",
    "    os.chdir(data_dir.name)\n",
    "\n",
    "# For info, print out where the script is running\n",
    "print(\"Running in {}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If Desired, set up CRDS to use a local cache\n",
    "\n",
    "By default, the notebook template environment sets up its CRDS cache (the \"CRDS_PATH\" environment variable) in /grp/crds/cache. However, if the notebook is running on a local machine without a fast and reliable connection to central storage, it makes more sense to put the CRDS cache locally. Currently, the cell below offers several options, and will check the supplied boolean variables one at a time until one matches.\n",
    "\n",
    "* if `use_local_crds_cache` is False, then the CRDS cache will be kept in /grp/crds/cache\n",
    "* if `use_local_crds_cache` is True, the CRDS cache will be kept locally\n",
    "  * if `crds_cache_tempdir` is True, the CRDS cache will be kept in the temporary directory\n",
    "  * if `crds_cache_notebook_dir` is True, the CRDS cache will be kept in the same directory as the notebook.\n",
    "  * if `crds_cache_home` is True, the CRDS cache will be kept in $HOME/crds/cache\n",
    "  * if `crds_cache_custom_dir` is True, the CRDS cache will be kept in whatever is stored in the \n",
    "    `crds_cache_dir_name` variable.\n",
    "\n",
    "If the above cell (creating a temporary directory) is not run, then setting `crds_cache_tempdir` to True will store the CRDS cache in the notebook's directory (the same as setting `crds_cache_notebook_dir` to True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages that allow us to get information about objects:\n",
    "import asdf\n",
    "import copy\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Numpy library:\n",
    "import numpy as np\n",
    "\n",
    "# For downloading data\n",
    "import requests\n",
    "\n",
    "# Astropy tools:\n",
    "from astropy.io import fits\n",
    "from astropy.utils.data import download_file\n",
    "from astropy.visualization import ImageNormalize, ManualInterval, LogStretch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up matplotlib for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# Use this version for non-interactive plots (easier scrolling of the notebook)\n",
    "%matplotlib inline\n",
    "\n",
    "# Use this version (outside of Jupyter Lab) if you want interactive plots\n",
    "#%matplotlib notebook\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import JWST pipeline-related modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of possible data quality flags\n",
    "from jwst.datamodels import dqflags\n",
    "\n",
    "# The entire calwebb_detector1 pipeline\n",
    "from jwst.pipeline import calwebb_detector1\n",
    "\n",
    "# Individual steps that make up calwebb_detector1\n",
    "from jwst.dq_init import DQInitStep\n",
    "from jwst.saturation import SaturationStep\n",
    "from jwst.superbias import SuperBiasStep\n",
    "from jwst.ipc import IPCStep                                                                                    \n",
    "from jwst.refpix import RefPixStep                                                                \n",
    "from jwst.linearity import LinearityStep\n",
    "from jwst.persistence import PersistenceStep\n",
    "from jwst.dark_current import DarkCurrentStep\n",
    "from jwst.jump import JumpStep\n",
    "from jwst.ramp_fitting import RampFitStep\n",
    "from jwst import datamodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='convenience_functions'></a>\n",
    "# Define convenience functions and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define some functions and some parameters that we will use repeatedly throughout the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_jump(signal, jump_group, xpixel=None, ypixel=None, slope=None):\n",
    "    \"\"\"Function to plot the signal up the ramp for a\n",
    "    pixel and show the location of flagged jumps.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signal : numpy.ndarray\n",
    "        1D array of signal values\n",
    "        \n",
    "    jump_group : list\n",
    "        List of boolean values whether a jump is present or\n",
    "        not in each group\n",
    "        \n",
    "    slope : numpy.ndarray\n",
    "        1D array of signal values constructed from the slope\n",
    "    \"\"\"\n",
    "    groups = np.arange(len(signal))\n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    plt.plot(groups, signal, marker='o', color='black')\n",
    "    plt.plot(groups[jump_group], signal[jump_group], marker='o', color='red',\n",
    "             label='Flagged Jump')\n",
    "    \n",
    "    if slope is not None:\n",
    "        plt.plot(groups, slope, marker='o', color='blue', label='Data from slope')\n",
    "        \n",
    "    plt.legend(loc=2)\n",
    "\n",
    "    plt.xlabel('Groups')\n",
    "    plt.ylabel('Signal (DN)')\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    \n",
    "    if xpixel and ypixel:\n",
    "        plt.title('Pixel ('+str(xpixel)+','+str(ypixel)+')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_jumps(signals, jump_groups, pixel_loc, slopes=None):\n",
    "    \"\"\"Function to plot the ramp and show the jump location\n",
    "    for several pixels. For simplicity, let's force the input\n",
    "    number of pixels to be a square. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    signals : numpy.ndarray\n",
    "        2D array (groups x pix) of signal values\n",
    "        \n",
    "    jump_groups : numpy.ndarray\n",
    "        2D array containing boolean entries for each group of\n",
    "        each pixel, describing where the jumps were found\n",
    "        \n",
    "    pixel_loc : list\n",
    "        List of 2-tuples containing the (x, y)\n",
    "        location of the pixels with the jumps\n",
    "        \n",
    "    slopes : numpy.ndarray\n",
    "        2D array (groups x pix) of linear signal values\n",
    "        If not None, these will be overplotted onto the\n",
    "        plots of signals\n",
    "    \"\"\"\n",
    "    num_group, num_pix = signals.shape\n",
    "    root = np.sqrt(num_pix)\n",
    "    if int(root + 0.5) ** 2 != num_pix:\n",
    "        raise ValueError('Number of pixels input should be a square.')\n",
    "    \n",
    "    root = int(root)\n",
    "    groups = np.arange(num_group)\n",
    "    fig, axs = plt.subplots(root, root, figsize=(10, 10))\n",
    "\n",
    "    for index in range(len(pixel_loc)):\n",
    "        i = int(index % root)\n",
    "        j = int(index / root)\n",
    "        axs[i, j].plot(groups, signals[:, index], marker='o', color='black')\n",
    "        j_grp = jump_groups[:, index]\n",
    "        axs[i, j].plot(groups[j_grp], signals[j_grp, index],\n",
    "                       marker='o', linestyle='None', color='red')\n",
    "        \n",
    "        if slopes is not None:\n",
    "            axs[i, j].plot(groups, slopes[:, index], marker='o', color='blue')\n",
    "        \n",
    "        axs[i, j].set_title('Pixel ({}, {})'.format(pixel_loc[index][1], pixel_loc[index][0]))\n",
    "        \n",
    "    plt.xlabel('Groups')\n",
    "    plt.ylabel('Signal (DN)')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ramp(groups, signal, xpixel=None, ypixel=None, title=None):\n",
    "    \"\"\"Function to plot the up the ramp signal for a pixel.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    groups : numpy.ndarray\n",
    "        1D array of group numbers. X-axis values.\n",
    "        \n",
    "    signal : numpy.ndarray\n",
    "        1D array of pixel signal values.\n",
    "        \n",
    "    xpixel : int\n",
    "        X-coordinate of the pixel being plotted. Used for legend only.\n",
    "        \n",
    "    ypixel : int\n",
    "        Y-coordinate of the pixel being plotted. Used for legend only.\n",
    "        \n",
    "    title : str\n",
    "        String to use for the plot title\n",
    "    \"\"\"    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot()\n",
    "    if xpixel and ypixel:\n",
    "            plt.plot(groups, signal, marker='o',\n",
    "                     label='Pixel ('+str(xpixel)+','+str(ypixel)+')') \n",
    "            plt.legend(loc=2)\n",
    "\n",
    "    else:\n",
    "        plt.plot(groups, signal, marker='o')\n",
    "        \n",
    "    plt.xlabel('Groups')\n",
    "    plt.ylabel('Signal (DN)')\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ramps(groups, signal1, signal2, label1=None, label2=None, title=None):\n",
    "    \"\"\"Function to plot the up the ramp signal for two pixels\n",
    "    on a single plot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    groups : numpy.ndarray\n",
    "        1D array of group numbers. X-axis values.\n",
    "        \n",
    "    signal1 : numpy.ndarray\n",
    "        1D array of signal values for first pixel\n",
    "        \n",
    "    signal2 : numpy.ndarray\n",
    "        1D array of signal values for second pixel\n",
    "        \n",
    "    label1 : str\n",
    "        Label to place in the legend for pixel1\n",
    "        \n",
    "    label2 : str\n",
    "        Label to place in the legend for pixel2\n",
    "        \n",
    "    title : str\n",
    "        String to place in the title of the plot\n",
    "    \"\"\"    \n",
    "    fig = plt.figure(figsize=(6, 6))\n",
    "    ax = plt.subplot()\n",
    "    if label1:\n",
    "        plt.plot(groups, signal1, marker='o', color='black', label=label1)\n",
    "    else:\n",
    "        plt.plot(groups, signal1, marker='o', color='black')\n",
    "    if label2:\n",
    "        plt.plot(groups, signal2, marker='o', color='red', label=label2)\n",
    "    else:\n",
    "        plt.plot(groups, signal2, marker='o', color='red')\n",
    "    if label1 or label2:\n",
    "        plt.legend(loc=2)\n",
    "        \n",
    "    plt.xlabel('Groups')\n",
    "    plt.ylabel('Signal (DN)')\n",
    "    fig.tight_layout()\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.subplots_adjust(top=0.95)\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(data_2d, vmin, vmax, xpixel=None, ypixel=None, title=None):\n",
    "    \"\"\"Function to generate a 2D, log-scaled image of the data, \n",
    "    with an option to highlight a specific pixel (with a red dot).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data_2d : numpy.ndarray\n",
    "        Image to be displayed\n",
    "        \n",
    "    vmin : float\n",
    "        Minimum signal value to use for scaling\n",
    "        \n",
    "    vmax : float\n",
    "        Maximum signal value to use for scaling\n",
    "        \n",
    "    xpixel : int\n",
    "        X-coordinate of pixel to highlight\n",
    "        \n",
    "    ypixel : int\n",
    "        Y-coordinate of pixel to highlight\n",
    "        \n",
    "    title : str\n",
    "        String to use for the plot title\n",
    "    \"\"\"\n",
    "    norm = ImageNormalize(data_2d, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                          stretch=LogStretch())\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    im = ax.imshow(data_2d, origin='lower', norm=norm)\n",
    "    \n",
    "    if xpixel and ypixel:\n",
    "        plt.plot(xpixel, ypixel, marker='o', color='red', label='Selected Pixel')\n",
    "\n",
    "    fig.colorbar(im, label='DN')\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def side_by_side(data1, data2, vmin, vmax, title1=None, title2=None, title=None):\n",
    "    \"\"\"Show two images side by side for easy comparison. Optionally highlight\n",
    "    a given pixel with a red dot.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data1 : numpy.ndarray\n",
    "        First image to be displayed\n",
    "        \n",
    "    data2 : numpy.ndarray\n",
    "        Second image to be displayed\n",
    "        \n",
    "    vmin : float\n",
    "        Minimum signal value to use for scaling\n",
    "        \n",
    "    vmax : float\n",
    "        Maximum signal value to use for scaling\n",
    "            \n",
    "    title1 : str\n",
    "        Title to use for first (left) plot\n",
    "        \n",
    "    title2 : str\n",
    "        Title to use for the second (right) plot\n",
    "\n",
    "    title : str\n",
    "        String to use for the plot title\n",
    "    \"\"\"\n",
    "    norm = ImageNormalize(data1, interval=ManualInterval(vmin=vmin, vmax=vmax),\n",
    "                          stretch=LogStretch())\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(11, 8))\n",
    "    im = axes[0].imshow(data1, origin='lower', norm=norm)\n",
    "    im = axes[1].imshow(data2, origin='lower', norm=norm)\n",
    "    \n",
    "    axes[0].set_xlabel('Pixel column')\n",
    "    axes[0].set_ylabel('Pixel row')\n",
    "    axes[1].set_xlabel('Pixel column')\n",
    "    \n",
    "    if title1:\n",
    "        axes[0].set_title(title1)\n",
    "    if title2:\n",
    "        axes[1].set_title(title2)\n",
    "        \n",
    "    fig.subplots_adjust(right=0.8)\n",
    "    cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "    fig.colorbar(im, cax=cbar_ax, label='DN')\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_load\"></a>\n",
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.utils.data import download_file\n",
    "from pathlib import Path\n",
    "from shutil import move\n",
    "from os.path import splitext\n",
    "\n",
    "def get_box_files(file_list):\n",
    "    for box_url,file_name in file_list:\n",
    "        if 'https' not in box_url:\n",
    "            box_url = 'https://stsci.box.com/shared/static/' + box_url\n",
    "        downloaded_file = download_file(box_url, timeout=600)\n",
    "        if Path(file_name).suffix == '':\n",
    "            ext = splitext(box_url)[1]\n",
    "            file_name += ext\n",
    "        move(downloaded_file, file_name)\n",
    "        \n",
    "file_urls = ['https://stsci.box.com/shared/static/j46wpyirlbqo30e7c9719ycnuc1qk2lu.fits']\n",
    "\n",
    "file_names = ['jw98765001001_01101_00003_nrcb5_uncal.fits']        \n",
    "\n",
    "box_download_list = [(url,name) for url,name in zip(file_urls,file_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_box_files(box_download_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='detector1'></a>\n",
    "# The calwebb_detector1 pipeline: Ramps to slopes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sections below, we will run the Stage 1 pipeline on a single uncalibrated NIRCam file. We will first call the entire [*calwebb_detector1* pipeline](https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1) on the file. The pipeline is a wrapper which will string together all of the appropriate steps in the proper order. \n",
    "\n",
    "The final output from this call is an uncalibrated slope image which is ready to go into the Stage 2 pipeline. \"Uncalibrated\" in this case means that the data are in units of DN/sec. \n",
    "\n",
    "After that, we will go back to the original uncalibrated ramp and manually run it through each of the steps that comprise the Stage 1 pipeline. For each step we will examine the output.\n",
    "\n",
    "See [Figure 1](https://jwst-docs.stsci.edu/jwst-data-reduction-pipeline/stages-of-processing/calwebb_detector1) on the calwebb_detector1 algorithm page for a map of which steps are performed on NIR data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='detector1_at_once'></a>\n",
    "# Run the entire `calwebb_detecor1` pipeline\n",
    "\n",
    "In this section we run the entire calwebb_detector1 pipeline with a single call. In this case the pipeline code can determine which instrument was used to collect the data and runs the appropriate steps in the proper order.\n",
    "\n",
    "We set parameter values for some of the individual steps, save some outputs, etc, and then call the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create an instance of the pipeline class\n",
    "detector1 = calwebb_detector1.Detector1Pipeline()\n",
    "\n",
    "# Set some parameters that pertain to the\n",
    "# entire pipeline\n",
    "detector1.save_results = True\n",
    "\n",
    "# Set some parameters that pertain to some of\n",
    "# the individual steps\n",
    "detector1.refpix.use_side_ref_pixels = True\n",
    "detector1.refpix.odd_even_rows = False\n",
    "\n",
    "# Save outputs from steps to examine\n",
    "detector1.dq_init.save_results = True\n",
    "detector1.saturation.save_results = True\n",
    "detector1.superbias.save_results = True\n",
    "detector1.refpix.save_results = True\n",
    "detector1.linearity.save_results = True\n",
    "detector1.dark_current.save_results = True\n",
    "detector1.persistence.save_results = True\n",
    "detector1.jump.save_results = True\n",
    "detector1.ramp_fit.save_opt = True\n",
    "detector1.ramp_fit.save_results = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Call the run() method\n",
    "run_output = detector1.run(file_names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary output of the calwebb_detector1 pipeline is a file containing a rate image for the exposure. The units of the data are ADU/sec.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the rate file name from the uncal file name\n",
    "rate_file = file_names[0].replace('uncal.fits', 'rate.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use getdata to quickly read in the science data from the rate file\n",
    "rate_data = fits.getdata(rate_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the rate image\n",
    "show_image(rate_data, 0.5, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the linear step file name from the uncal file name\n",
    "linear_file = rate_file.replace('rate.fits', 'linearity.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the science data from the linear file\n",
    "lin_data = fits.getdata(linear_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will look in more detail at the effects of the linearity correction step in the [linearity](#linearity) section below. For now, let's just look at the final group of the integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the data in the final group of the linearized data:\n",
    "show_image(lin_data[0, -1, :, :], 100, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='detector1_step_by_step'></a>\n",
    "# Run the individual pipeline steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the sections below we run the steps contained within calwebb_detector1 one at a time, in order to check the outputs for each step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dq_init'></a>\n",
    "### The `Data Quality Initialization` step\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step populates the Data Quality (DQ) mask that is associated with the data file. The DQ flags from the `MASK` reference file are copied into the `PIXELDQ` extension of the input file. A table showing the [mapping of bit values](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/references_general.html#data-quality-flags) in the `MASK` file decribes what types of bad pixels can be flagged. Any other bad pixel types will be ignored.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/dq_init/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "There are no optional arguments for this step\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the `MASK` reference file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we ran the step above and saved the outputs, we'll skip this part and just load the outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Using the run() method. Instantiate and set parameters\n",
    "# dq_init_step = DQInitStep()\n",
    "# dq_init_step.save_results = True\n",
    "\n",
    "# # Call the run() method on the uncal file\n",
    "# dq_init = dq_init_step.run(file_names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with datamodels.open(file_names[0].replace('uncal.fits', 'dq_init.fits')) as dq_init:\n",
    "dq_init = datamodels.open(file_names[0].replace('uncal.fits', 'dq_init.fits'))\n",
    "print(dq_init.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the list of JWST bad pixel types\n",
    "dqflags.pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixel values in the `SCI` extension are not changed in this step. Instead, the DQ flags are copied into the `PIXELDQ` extension. The `GROUPDQ` values are not changed in this step. Let's check the `PIXELDQ` values and see what has changed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print some basic information on the number of flagged pixels\n",
    "idx_pixelDQ = np.where(dq_init.pixeldq.flatten() == 0.)[0]\n",
    "num_flagged = dq_init.pixeldq.size - len(idx_pixelDQ)\n",
    "print('Total pixels in PIXELDQ: {}'.format(dq_init.pixeldq.size))\n",
    "print('{} pixels have no flags.'.format(len(idx_pixelDQ)))\n",
    "print('{} pixels ({:.2f}% of the detector) have flags.'.format(num_flagged, num_flagged / dq_init.pixeldq.size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(dq_init.pixeldq, 0, 100, title='Pixel DQ extension')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(unique, counts) = np.unique(dq_init.pixeldq, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of counts for each flag: ')\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='saturation'></a>\n",
    "## The `Saturation Flagging` step\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step checks the signal values in all pixels across all groups, and adds a [`saturated` flag](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/references_general.html#data-quality-flags) to the `GROUPDQ` extension for pixels and groups where the signal is above the saturation limit.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/saturation/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "There are no optional arguments for this step\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`SATURATION`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/saturation/reference_files.html) reference file. This file contains a map of the saturation threshold in ADU for each pixel on the detector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we ran the step above and saved the outputs, we'll skip this part and just load the outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Using the run() method\n",
    "# saturation_step = SaturationStep()\n",
    "# saturation_step.output_dir = output_dir\n",
    "# saturation_step.save_results = True\n",
    "\n",
    "# # Call using the the output from the previously-run dq_init step\n",
    "# saturation = saturation_step.run(dq_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with datamodels.open(file_names[0].replace('uncal.fits', 'saturation.fits')) as saturation:\n",
    "saturation = datamodels.open(file_names[0].replace('uncal.fits', 'saturation.fits'))   \n",
    "print(saturation.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there are any saturated values, they should appear in the `GROUPDQ` arrays. Let's examine the `GROUPDQ` data and see if there are any detected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find indexes of saturated pixels\n",
    "saturated = np.where(saturation.groupdq & dqflags.pixel['SATURATED'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sat_flags = len(saturated[0])\n",
    "print(('Found {} saturated flags. This may include multiple saturated '\n",
    "       'groups within a given pixel'.format(num_sat_flags)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's find a pixel that saturated part of the way up the ramp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 4D boolean map of whether the saturation flag is present or not.\n",
    "saturated = (saturation.groupdq & dqflags.pixel['SATURATED'] > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collapse that down to a 2D map that lists the number of saturated groups \n",
    "# for each pixel.\n",
    "saturated_2d = np.sum(saturated[0, :, :, :], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get coordinates of pixels that are saturated in some, but not all, groups.\n",
    "partial_sat = np.where((saturated_2d > 0) & (saturated_2d < saturated.shape[1]))\n",
    "print(\"{} pixels are partially saturated.\".format(len(partial_sat[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's choose one of these partially saturated pixels and look at the signal values up the ramp, along with which groups are flagged as saturated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sat_y, sat_x = partial_sat\n",
    "sat_index = 123\n",
    "y = sat_y[sat_index]\n",
    "x = sat_x[sat_index]\n",
    "grps = saturated[0, :, y, x]\n",
    "print('Saturation flags up the ramp (0 is not saturated, 2 is saturated): {}'\n",
    "      .format(saturation.groupdq[0, :, y, x]))\n",
    "print('Pixel signal values up the ramp: {}'.format(saturation.data[0, :, y, x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot these in order to get a clearer look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get the science and DQ values for the pixel.\n",
    "groups = np.arange(saturation.data.shape[1])\n",
    "full_ramp = saturation.data[0, :, y, x]\n",
    "sat_dq = saturation.groupdq[0, :, y, x].astype(bool)\n",
    "\n",
    "# Make a copy of the science data and set all saturated groups to NaN\n",
    "saturated_points = copy.deepcopy(saturation.data[0, :, y, x])\n",
    "saturated_points[~sat_dq] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the pixel's values up the ramp and denote the saturated groups\n",
    "plot_ramps(groups, full_ramp, saturated_points, label1='Not Saturated',\n",
    "           label2='Saturated', title='Pixel ({}, {})'.format(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a id='superbias'> </a>\n",
    "## The `Superbias Subtraction` step\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step subtracts the superbias reference frame from each group of the science exposure.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/superbias/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "There are no optional arguments for this step\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`SUPERBIAS`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/superbias/reference_files.html) reference file. This file contains a map of the superbias signal in ADU for each pixel on the detector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we ran the step above and saved the outputs, we'll skip this part and just load the outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Using the run() method\n",
    "# superbias_step = SuperBiasStep()\n",
    "# superbias_step.output_dir = output_dir\n",
    "# superbias_step.save_results = True\n",
    "\n",
    "# # Call using the the output from the previously-run saturation step\n",
    "# superbias = superbias_step.run(saturation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with datamodels.open(file_names[0].replace('uncal.fits', 'superbias.fits')) as superbias:\n",
    "superbias = datamodels.open(file_names[0].replace('uncal.fits', 'superbias.fits'))    \n",
    "print(superbias.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visually compare the science products to the raw `uncal` data, looking only at the last group of the first integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the shape of the data in the datamodel output from the step\n",
    "superbias.data[0, 0, :, :].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the data before and after superbias subtraction\n",
    "side_by_side(saturation.data[0, 0, :, :], superbias.data[0, 0, :, :], vmin=11000, vmax=18000,\n",
    "            title1='Before superbias subtraction', title2='After superbias subtraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='refpix'></a>\n",
    "## The `Reference Pixel Subtraction` step\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step uses the reference pixels, which are not sensitive to illumination, to subtract group- and amplifier-dependent signal originating in the readout electronics from the data. There are two distinct corrections that are applied here.\n",
    "\n",
    "First, the rows of reference pixels on the top and bottom of the detector are used to subtract amplifier-dependent offsets from each group. Within a given amplifier, the mean value of all reference pixels in even numbered columns is subtracted from the science pixels in the even numbered columns. The same strategy is used for the odd numbered columns. \n",
    "\n",
    "The second part of the reference pixel subtraction step uses the reference pixels along the left and right sides of the detector to mitigate 1/f noise. This noise is visible in the data as horizontal banding that stretches across the entire detector. \n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/refpix/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "[Full details on the optional arguments](https://jwst-pipeline.readthedocs.io/en/stable/jwst/refpix/arguments.html).\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step does not use any reference files.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to better show the effects from the 2 parts of the reference file subtraction, we're going to run this step twice. First we'll perform only the mean value subtraction using the top and bottom reference pixels. Then on the second run, we'll perform both the mean value subtraction and the 1/f subtraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='refpix_run'></a>\n",
    "##### Using the run() method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A reminder of the available parameters that can be set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the spec attribute to print available parameters\n",
    "print(RefPixStep.spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this 'partial' run, we need to turn off the 1/f correction that\n",
    "# uses the reference pixels on the sides of the detector. Also, we'll\n",
    "# save the output using a unique name so as not to confuse the file\n",
    "# with the output where we run the entire repix subtraction step.\n",
    "\n",
    "refpix_step_no_sidepix = RefPixStep()\n",
    "refpix_step_no_sidepix.save_results = True\n",
    "refpix_step_no_sidepix.output_file = 'refpix_test_no_side_pixels'\n",
    "\n",
    "# Turn off the 1/f correction\n",
    "refpix_step_no_sidepix.use_side_ref_pixels = False\n",
    "\n",
    "# Call using the the output from the previously-run superbias step\n",
    "refpix_no_sidepix = refpix_step_no_sidepix.run(superbias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next run the full correction. This will produce the output that we will feed into subsequent steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate and set parameters\n",
    "refpix_step = RefPixStep()\n",
    "refpix_step.save_results = True\n",
    "\n",
    "# Call using the saturation instance from the previously-run\n",
    "# saturation step\n",
    "refpix = refpix_step.run(superbias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's explore the output from this step. As with all NIR detectors, the outermost 4 rows and columns comprise the reference pixels.\n",
    "\n",
    "Let's use the datamodels from before and after the reference pixel subtraction to have a look at the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll zoom in on the top few rows in order to see the changes. Note how the \"odd/even\" effect dominates the signal prior to reference pixel subtraction. Even numbered columns and odd numbered columns have significantly different signal levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side by side, before/after reference pixel subtraction\n",
    "side_by_side(superbias.data[0, 5, 2030:, 1030:1050], refpix.data[0, 5, 2030:, 1030:1050],\n",
    "             vmin=0, vmax=30000, title1='Before Refpix Subtraction',\n",
    "             title2='After Refpix Subtraction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Image of the difference before/after reference pixel subtraction\n",
    "show_image(superbias.data[0, 5, 2030:, 1030:1050] - refpix.data[0, 5, 2030:, 1030:1050],\n",
    "           vmin=7000, vmax=16000, title='Difference: Before - After Refpix Subtraction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look at the difference in the data after the mean value subtraction compared to the case where both the mean value subtraction and the 1/f correction are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Side by side view of the reference pixel subtraction with and without\n",
    "# using the side reference pixels to subtract 1/f noise\n",
    "side_by_side(refpix_no_sidepix.data[0, 5, :, :], refpix.data[0, 5, :, :],\n",
    "             vmin=20, vmax=150, title1='No Side Repix Correction',\n",
    "             title2='With Side Refpix Correction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the difference image before and after the side reference\n",
    "# pixels are used to subtract the 1/f noise\n",
    "show_image(refpix.data[0, 5, :, :] - refpix_no_sidepix.data[0, 5, :, :],\n",
    "           vmin=-10, vmax=10, title=\"Difference with/without using side refpix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='linearity'></a>\n",
    "## The `Linearity Correction` step \n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step applies the classical linearity correction to the data on a pixel-by-pixel, integration-by-integration, group-by-group manner.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/linearity/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "There are no optional arguments for this step\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`LINEARITY`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/linearity/reference_files.html) reference file. This file contains the polynomial coefficients used to apply the linearity correction to non-linear data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we ran the step above and saved the outputs, we'll skip this part and just load the outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Using the run() method\n",
    "# linearity_step = LinearityStep()\n",
    "# linearity_step.output_dir = output_dir\n",
    "# linearity_step.save_results = True\n",
    "\n",
    "# # Call using the refpix instance from the previously-run\n",
    "# # refpix step\n",
    "# linearity = linearity_step.run(refpix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with datamodels.open(file_names[0].replace('uncal.fits', 'linearity.fits')) as linearity:\n",
    "linearity = datamodels.open(file_names[0].replace('uncal.fits', 'linearity.fits'))\n",
    "print(linearity.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the signal up the ramp for a high signal pixel, in order to more easily see how the linearity correction changed the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the 3rd group, find the difference between the data before and after\n",
    "# linearity correction. Find the pixels where this difference is greater than\n",
    "# 20 DN, and also where the signal in the final group is over 40,000 DN.\n",
    "lin_fix = linearity.data[0, 3, :, :] - refpix.data[0, 3, :, :]\n",
    "well_exposed = np.where((linearity.data[0, -1, :, :] > 40000.) & (lin_fix > 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('{} pixels meet the criteria above.'.format(len(well_exposed[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick one of these pixels and plot the signal before and after the linearity correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 3\n",
    "lin_pix_x, lin_pix_y = (well_exposed[1][index], well_exposed[0][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of group numbers to plot against\n",
    "group_nums = np.arange(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ramps(group_nums, refpix.data[0, :, lin_pix_y, lin_pix_x],\n",
    "           linearity.data[0, :, lin_pix_y, lin_pix_x], label1='Uncorrected', label2='Corrected',\n",
    "           title='Pixel ({}, {})'.format(lin_pix_x, lin_pix_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the pixel reached saturation in group 9. So in group 9, the linearity correction made no changes. Between groups 0 to 8, you can see the original signal (in black) becoming more and more non-linear as signal increases, along with how the linearity correction modified the signal (red)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='persistence'></a>\n",
    "## The `Persistence Correction` step \n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step uses a model to calculate the amount of signal in each group of each pixel that comes from persistence. This persistence signal is then subtracted, pixel-by-pixel and group-by-group, from the data.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/persistence/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "[Optional arguments](https://jwst-pipeline.readthedocs.io/en/stable/jwst/persistence/arguments.html) for this step include setting the threshold signal value above which pixels are flagged in the DQ extension, as well as saving the subtracted persistence signal in a separate file.\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`TRAPDENSITY`, `PERSAT`, and `TRAPPARS`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/persistence/reference_files.html) reference files. The TRAPDENSITY file contains a map of the relative number of traps per pixel. The PERSAT reference file contains a map of the persistence saturation level, and the TRAPPARS reference file contains parameters related to the persistence calculation model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: this is skipped for now. Test will be added later.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(PersistenceStep.spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Using the run() method\n",
    "# persist_step = PersistenceStep()\n",
    "# persist_step.output_dir = output_dir\n",
    "# persist_step.save_results = True\n",
    "\n",
    "# # Specify the trapsfilled file, which contains the\n",
    "# # state of the charge traps in the preceding exposure\n",
    "# persist_step.input_trapsfilled = persist_file\n",
    "\n",
    "# # Let's also save a separate file that contains the\n",
    "# # subtracted persistence signal \n",
    "# persist_step.save_persistence = True\n",
    "\n",
    "# # Call using the refpix instance from the previously-run\n",
    "# # linearity step\n",
    "# persist = persist_step.run(linearity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the optional output file that contains the subtracted persistence signal. \n",
    "\n",
    "NOTE: In this case the output is pretty boring. It turns out that the trap density map reference file for NIRCam is empty because it is not yet well characterized. This means that the persistence signal is zero in all pixels for all exposures. Once the map is updated in commissioning, this step will start calculating persistence values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Name of the file containing a map of the calculated persistence signal\n",
    "# persist_signal_file = os.path.join(output_dir, '{}output_pers.fits'.format(input_file_base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read in the map of persistence signal\n",
    "# persist_signal = fits.getdata(persist_signal_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The file contains the persistence signal for each group of each integration, as we can see by the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# persist_signal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.min(persist_signal), np.max(persist_signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the persistence signal in the final group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_image(persist_signal[0, -1, :, :], 0, .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dc'></a>\n",
    "##  The `Dark Current Subtraction` step \n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step subtracts the dark current, group by group, from the input integrations.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/dark_current/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "There are no optional arguments for this step\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`DARK`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/dark_current/reference_files.html) reference file. This file contains the measured mean dark current associated with the detector and subarray.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: This is one of the longer-running steps of calwebb_detector1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we ran the step above and saved the outputs, we'll skip this part and just load the outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Using the run() method\n",
    "# dark_step = DarkCurrentStep()\n",
    "# dark_step.save_results = True\n",
    "\n",
    "# # Call using the persistence instance from the previously-run\n",
    "# # persistence step\n",
    "# dark = dark_step.run(linearity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with datamodels.open(file_names[0].replace('uncal.fits', 'dark_current.fits')) as dark:\n",
    "dark = datamodels.open(file_names[0].replace('uncal.fits', 'dark_current.fits')) \n",
    "print(dark.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the data before and after superbias subtraction\n",
    "side_by_side(linearity.data[0, 0, :, :], dark.data[0, 0, :, :], vmin=0, vmax=500,\n",
    "            title1='Before dark correction', title2='After dark correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='jump'></a>\n",
    "## The `Cosmic Ray Flagging` step\n",
    "\n",
    "#### Summary\n",
    "\n",
    "This step searches for \"jumps\" in the ramp data. In this case, a jump in a pixel's ramp is defined as a large deviation in the count rate relative to that in the other groups. When a jump is found, the associated flag is added to the `GROUPDQ` extension for the group and pixel where the jump was detected. The science data are not modified at all. In the subsequent ramp-fitting step, the algorithm will look into the `GROUPDQ` array and ignore any groups where the jump flag has been set.\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/jump/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "The jump step has [several optional arguments](https://jwst-pipeline.readthedocs.io/en/stable/jwst/jump/arguments.html)\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`READNOISE`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/readnoise_reffile.html) and [`GAIN`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/gain_reffile.html) reference files. These files contain maps of the readnoise and gain values across the detector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we ran the step above and saved the outputs, we'll skip this part and just load the outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the available parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(JumpStep.spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Using the run() method\n",
    "# jump_step = JumpStep()\n",
    "# jump_step.output_dir = output_dir\n",
    "# jump_step.save_results = True\n",
    "# jump_step.rejection_threshold = 9\n",
    "\n",
    "# # Call using the dark instance from the previously-run\n",
    "# # dark current subtraction step\n",
    "# jump = jump_step.run(dark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with datamodels.open(file_names[0].replace('uncal.fits', 'jump.fits')) as jump:\n",
    "jump = datamodels.open(file_names[0].replace('uncal.fits', 'jump.fits'))\n",
    "print(jump.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examine the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what some of these jumps look like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many total jump flags were added? Note that some pixels\n",
    "# will have more than one group flagged with a jump.\n",
    "jump_flags = np.where(jump.groupdq & dqflags.pixel['JUMP_DET'] > 0)\n",
    "print('{} jump flags detected.'.format(len(jump_flags[0])))\n",
    "\n",
    "# Create a 4-dimensional map of the jump flags\n",
    "jump_map = (jump.groupdq & dqflags.pixel['JUMP_DET'] > 0)\n",
    "\n",
    "# Collapse down to a 2D map of the number of flagged jumps in each pixel\n",
    "jump_map_2d = np.sum(jump_map[0, :, :, :], axis=0)\n",
    "\n",
    "# Determine how many pixels have jump flags\n",
    "jump_map_indexes = np.where(jump_map_2d > 0)\n",
    "impacted_pix = np.sum(jump_map_2d > 0)\n",
    "total_pix = 2048 * 2048\n",
    "print(('{} pixels ({:.2f}% of the detector) have been flagged with '\n",
    "      'at least one jump.'.format(impacted_pix, 100. * impacted_pix / total_pix)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot some of the pixels impacted by jumps. The red marks signify flagged jumps. These signal values will be ignored in subsequent ramp-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The jump map is 4-dimensional, just like the science data\n",
    "jump_map.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of group numbers to plot against\n",
    "group_indexes = np.arange(jump_map.shape[1]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick one pixel with a flagged jump, and find the group(s) with the jump flags\n",
    "j_index = 10112\n",
    "jumpy = jump_map_indexes[0][j_index]\n",
    "jumpx = jump_map_indexes[1][j_index]\n",
    "jump_grp = jump_map[0, :, jumpy, jumpx]\n",
    "print('Jump located in group(s) {} of pixel ({}, {})'.format(group_indexes[jump_grp], jumpx, jumpy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the signal up the ramp for this pixel\n",
    "plot_jump(jump.data[0, :, jumpy, jumpx], jump_grp, xpixel=jumpx, ypixel=jumpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a grid of some examples of flagged jumps. The red marks signify flagged jumps. These signal values will be ignored in subsequent ramp-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes_to_plot = [200, 401, 600, 30010, 31000, 1202, 1400, 21600, 10112]\n",
    "jump_data = np.zeros((jump.shape[1], len(indexes_to_plot)))\n",
    "jump_grps = np.zeros((jump.shape[1], len(indexes_to_plot))).astype(bool)\n",
    "jump_locs = []\n",
    "for counter, idx in enumerate(indexes_to_plot):\n",
    "    #integ, grp, y, x = jump_flags[idx]\n",
    "    y = jump_map_indexes[0][idx]\n",
    "    x = jump_map_indexes[1][idx]\n",
    "    grp = jump_map[0, :, y, x]\n",
    "\n",
    "    jump_data[:, counter] = jump.data[0, :, y, x]\n",
    "    jump_grps[:, counter] = grp\n",
    "    jump_locs.append((x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_jumps(jump_data, jump_grps, jump_locs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ramp_fitting'></a>\n",
    "## The `Ramp Fitting` step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Summary\n",
    "\n",
    "This step performs line-fitting to the corrected data, and produces a slope image for each integration. For a given pixel, any groups within an integration that contain a jump flag or that are flagged as saturated are ignored.\n",
    "\n",
    "For the purposes of this notebook, we will use the `save_opt` parameter to tell the ramp-fitting step to save an optional output file that contains some of the details on the ramp fits. This information will be used for the plots after the step is run. By default, `save_opt` is False and the optional outputs are not saved.\n",
    "\n",
    "\n",
    "#### Documentation\n",
    "\n",
    "[Full description](https://jwst-pipeline.readthedocs.io/en/stable/jwst/ramp_fitting/description.html) of the step.\n",
    "\n",
    "#### Arguments\n",
    "\n",
    "The jump step has [several optional arguments](https://jwst-pipeline.readthedocs.io/en/stable/jwst/ramp_fitting/arguments.html), including the ability to save optional outputs into a second file.\n",
    "\n",
    "#### Reference files used\n",
    "\n",
    "This step uses the [`READNOISE`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/readnoise_reffile.html) and [`GAIN`](https://jwst-pipeline.readthedocs.io/en/stable/jwst/references_general/gain_reffile.html) reference files. These files contain maps of the readnoise and gain values across the detector.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run the step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we ran the step above and saved the outputs, we'll skip this part and just load the outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List the available parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RampFitStep.spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Using the run() method\n",
    "# ramp_fit_step = RampFitStep()\n",
    "# ramp_fit_step.save_results = True\n",
    "\n",
    "# # Let's save the optional outputs, in order\n",
    "# # to help with visualization later\n",
    "# ramp_fit_step.save_opt = True\n",
    "\n",
    "# # Call using the dark instance from the previously-run\n",
    "# # jump step\n",
    "# ramp_fit = ramp_fit_step.run(jump)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramp_fit = datamodels.open(file_names[0].replace('uncal.fits', '0_ramp_fit.fits')), datamodels.open(file_names[0].replace('uncal.fits', '1_ramp_fit.fits'))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important detail here is that there are two output files: \n",
    "\n",
    "1. The file ending with `*_0_rampfitstep.fits` contains the mean slope image across all integrations in the exposure.\n",
    "\n",
    "2. The file ending with `*_1_rampfitstep.fits` contains a separate slope image for each integration. In this case our exposure contains only a single integration, so the data in the two files are identical."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are working with the output datamodels in this notebook. Unlike the preceeding steps, where the output was a single datamodel, the ramp_fitting step outputs a tuple of 2 datamodel instances. The first element in the tuple is the datamodel instance containing the mean rate image, while the second element is the datamodel instance containing a separate slope image for each integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ramp_fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(ramp_fit[0]), type(ramp_fit[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the shape of the two output data models. The output with the mean slope image is only 2-dimensional, while the output with one slope image for each integration is 3-dimensional, even in this case where we have only one integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramp_fit[0].shape, ramp_fit[1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that in our case with a single integration, the two datamodel instances contain identical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ramp_fit[0].data[500, 500], ramp_fit[1].data[0, 500, 500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And note that the data in these files are the slopes from the ramp fitting, so the units have changed from DN to DN/sec."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the units of the ramp-fit data\n",
    "ramp_fit[0].meta.bunit_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the data from the third output file, which contains the optional outputs. Our goal is to grab the intercept values from the line-fitting and use them to re-create the plots from the jump step and overplot the best-fit signals on top of the signals that went into the step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the name of the optional output file\n",
    "optional_file = file_names[0].replace('uncal.fits', 'fitopt.fits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the file and examine the extensions\n",
    "hdulist = fits.open(optional_file)\n",
    "hdulist.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intercepts from the line-fitting are stored in the `YINT` extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdulist['YINT'].data[0, :, 200, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our plots below, we need the intercept values from the line-fitting. Let's ignore all but the first plane of the extension, since those are zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intercepts = hdulist['YINT'].data[0, 0, :, :]\n",
    "hdulist.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the pixels to be plotted, create linear ramps using the output slopes and intercepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the exposure time associated with each group\n",
    "num_groups = ramp_fit[0].meta.exposure.ngroups\n",
    "group_time = ramp_fit[0].meta.exposure.group_time\n",
    "group_times = np.arange(num_groups) * group_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct linear ramps from the slope and intercept values\n",
    "lin_ramps = np.zeros((jump.shape[1], len(indexes_to_plot)))\n",
    "for counter, idx in enumerate(indexes_to_plot):\n",
    "    y = jump_map_indexes[0][idx]\n",
    "    x = jump_map_indexes[1][idx]\n",
    "    grp = jump_map[0, :, y, x]\n",
    "\n",
    "    rate = ramp_fit[0].data[y, x]\n",
    "    intercept = intercepts[y, x]\n",
    "    lin_ramps[:, counter] = intercept + (rate * group_times)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the linear ramp for the single pixel we showed after the jump step\n",
    "lin_data = intercepts[jumpy, jumpx] + (ramp_fit[0].data[jumpy, jumpx] * group_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot again the single pixel from the jump step, along with its\n",
    "# reconstructed best-fit linear fit\n",
    "plot_jump(jump.data[0, :, jumpy, jumpx], jump_grp, xpixel=jumpx,\n",
    "          ypixel=jumpy, slope=lin_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the same as above, but for the collection of pixels\n",
    "# we plotted after the jump step\n",
    "plot_jumps(jump_data, jump_grps, jump_locs, slopes=lin_ramps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the slope image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(ramp_fit[0].data, 0, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on with the dark pixels scattered across the left side of the detector? It turns out they have signal values of exactly zero in the slope image. Let's have a closer look, and ignore the reference pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipix = ramp_fit[0].data[4:2044, 4:2044]\n",
    "zero_pix = np.where(scipix == 0.0)\n",
    "print('{} science pixels have a slope that is exactly zero.'.format(len(zero_pix[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick one of these pixels, and examine the pixel's signals up the ramp, as well as its data quality flags up the ramp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 45\n",
    "\n",
    "# Add 4 to the coordinates because we stripped off the 4 columns/rows of \n",
    "# refpix in the np.where statement above\n",
    "y = 4 + zero_pix[0][idx]\n",
    "x = 4 + zero_pix[1][idx]\n",
    "print('({}, {}) has a slope of 0.'.format(x, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the slope (should be zero), signal values up the ramp, and DQ flags up the ramp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scipix[y-4, x-4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearity.data[0, :, y, x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearity.groupdq[0, :, y, x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does a DQ flag value of 2 mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print JWST bad pixel flag definitions\n",
    "dqflags.pixel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this pixel (and the others with values of 0 in the slope image) have been flagged as saturated in all groups. In this case, the pipeline cannot calculate a slope value, and assigns a value of zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Original Author:** Bryan Hilbert, updated by Alicia Canipe, NIRCam\n",
    "<br>**Updated On:** 07/28/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Notebook](#title_ID)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
