{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Testing Notebook: Calwebb_Image3, Resample step\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: MIRI\n",
    "\n",
    "Tested on MIRI Simulated data\n",
    "\n",
    "### Table of Contents\n",
    "<div style=\"text-align: left\"> \n",
    "\n",
    "<br>  [Introduction](#intro_ID) <br> [Run JWST Pipelines](#pipeline_ID) <br> [Imports](#imports_ID) <br> [Create an association table for your cal files and run them through calwebb_image3](#runpipeline_ID) <br> [Find Stars in Image and Determine their Coordinates](#runscript_ID) <br> [Compare RA and Dec to expected Values](#residual_ID) <br> [About This Notebook](#about_ID) <br>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "# Introduction\n",
    "\n",
    "\n",
    "This test is designed to test the resample step in the calwebb_spec3 pipeline. This step takes the dither positions in an association table and combines them into 1 output product. Resample applies the distortion correction using the drizzling algorithm (as defined in the DrizzlePac handbook) and combines the listed files. For more information on the pipeline step visit the links below. \n",
    "\n",
    "Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/resample/main.html\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/resample\n",
    "\n",
    "The data for this test were created with the MIRI Data Simulator, and the documentation for that code can be found here: http://miri.ster.kuleuven.be/bin/view/Public/MIRISim_Public\n",
    "\n",
    "\n",
    "### Calibration WG Requested Algorithm: \n",
    "\n",
    "A short description and link to the page: https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Resample+Slit+Spectra\n",
    "\n",
    "\n",
    "### Defining Terms\n",
    "Definition of terms or acronymns.\n",
    "\n",
    "JWST: James Webb Space Telescope\n",
    "\n",
    "MIRI: Mid-Infrared Instrument\n",
    "\n",
    "MIRISim: MIRI Data Simulator\n",
    "\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "data_dir = TemporaryDirectory()\n",
    "os.chdir(data_dir.name)\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"imports_ID\"></a>\n",
    "# Imports\n",
    "The following packages will need to be imported for the scripts to work.\n",
    "\n",
    "\n",
    "* astropy.io for opening files\n",
    "* ci_watson.artifactory_helpers to read in data from artifactory\n",
    "* jwst.datamodels for opening files as a JWST Datamodel\n",
    "* jwst.pipeline to run the pipeline step/module\n",
    "* jwst.associations to create association table\n",
    "* numpy for calculations\n",
    "* matplotlib.pyplot.plt to generate plot\n",
    "* os for path information  \n",
    "* photutils for star finding and aperture photometry\n",
    "* regtest to retrieve data from artifactory needed to run notebook\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "45177853-942e-4949-9e30-f544d70ef5f4"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.io import ascii, fits\n",
    "from astropy.modeling import models, fitting\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "import glob\n",
    "\n",
    "import jwst\n",
    "from jwst.pipeline import Detector1Pipeline, Spec2Pipeline, Spec3Pipeline\n",
    "from jwst import associations, datamodels\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "from jwst.associations.lib.rules_level2_base import DMSLevel2bBase\n",
    "from jwst.associations.asn_from_list import asn_from_list\n",
    "from jwst.regtest.regtestdata import RegtestData\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in uncal data from artifactory \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Downloading input files\")\n",
    " \n",
    "#This readnoise file is needed for use with simulated data which has higher readnoise than actual data.\n",
    "readnoise = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'jump',                     \n",
    "                     'jump_miri_test', \n",
    "                     'jwst_mirisim_readnoise.fits')\n",
    "\n",
    "Slitfile1 = get_bigdata('jwst_validation_notebooks',\n",
    "                                     'validation_data',\n",
    "                                     'calwebb_spec2',\n",
    "                                    'spec2_miri_test',\n",
    "                                    'miri_lrs_slit_pt_nod1_v2.3.fits')\n",
    " \n",
    "Slitfile2 = get_bigdata('jwst_validation_notebooks',\n",
    "                                     'validation_data',\n",
    "                                     'calwebb_spec2',\n",
    "                                    'spec2_miri_test',\n",
    "                                    'miri_lrs_slit_pt_nod2_v2.3.fits')\n",
    "\n",
    "files = [Slitfile1, Slitfile2]\n",
    "\n",
    "print(\"Finished Downloads\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline_ID\"></a>\n",
    "# Run JWST Pipeline\n",
    "\n",
    "First we run the data through the Detector1() pipeline to convert the raw counts into slopes. This should use the calwebb_detector1.cfg file. The output of this stage will then be run through the Spec2Pipeline. Extract_1d is the final step of this pipeline stage, so we will just run through the whole pipeline.\n",
    "\n",
    "[Top of Page](#title_ID)\n",
    "\n",
    "### Detector 1 Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the calwebb_detector1 pipeline\n",
    "\n",
    "# set up pipeline parameters \n",
    "rej_thresh=10.0  # rejection threshold for jump step\n",
    "\n",
    "det1 = []\n",
    "\n",
    "# Run pipeline on both files\n",
    "for ff in files:\n",
    "    d1 = Detector1Pipeline.call(ff, steps={'jump':{'rejection_threshold':rej_thresh, 'override_readnoise': readnoise},\n",
    "                                           'ramp_fit': {'override_readnoise': readnoise}, 'refpix': {'skip': True}},\n",
    "                                save_results=True)\n",
    "    det1.append(d1)\n",
    "\n",
    "print(det1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(jwst.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spec2 Pipeline\n",
    "\n",
    "For the Spec2Pipeline we have to produce an association telling the pipeline that the nods should be used as each other's background. Then we call the pipeline with default parameters & settings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn_files = [det1[0].meta.filename, det1[1].meta.filename]\n",
    "asn = asn_from_list(asn_files, rule=DMSLevel2bBase, meta={'program':'test', 'target':'bd60', 'asn_pool':'test'})\n",
    "\n",
    "# now add the opposite nod as background exposure:\n",
    "asn['products'][0]['members'].append({'expname': 'miri_lrs_slit_pt_nod2_v2.3_rate.fits', 'exptype':'background'})\n",
    "asn['products'][1]['members'].append({'expname': 'miri_lrs_slit_pt_nod1_v2.3_rate.fits', 'exptype':'background'})\n",
    "\n",
    "# write this out to a json file\n",
    "with open('lrs-slit-test_spec2asn.json', 'w') as fp:\n",
    "    fp.write(asn.dump()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp2 = Spec2Pipeline.call('lrs-slit-test_spec2asn.json', save_results=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1ds = glob.glob('*_x1d.fits')\n",
    "\n",
    "fig = plt.figure(figsize=[10,5])\n",
    "\n",
    "for xx in x1ds:\n",
    "    sp = datamodels.open(xx)\n",
    "    lab = sp.meta.filename\n",
    "    plt.plot(sp.spec[0].spec_table['WAVELENGTH'], sp.spec[0].spec_table['FLUX'], label=lab)\n",
    "\n",
    "plt.title('Extracted spectra', fontsize='x-large')\n",
    "plt.xlabel('wavelength (micron)', fontsize='large')\n",
    "plt.legend()\n",
    "plt.ylabel('flux (Jy)', fontsize='large')\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spec3 Pipeline\n",
    "\n",
    "Next we run the Spec3 Pipeline. This also takes an association file as input, which lists the associated science files that will need to be combined into a single product.\n",
    "\n",
    "[Top of Page](#title_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use asn_from_list to create association table\n",
    "\n",
    "calfiles = glob.glob('*_cal.fits')\n",
    "asn = asn_from_list(calfiles, rule=DMS_Level3_Base, product_name='lrs_slit_pipetest_combined.fits')\n",
    "\n",
    "# dump association table to a .json file for use in image3\n",
    "with open('lrs_slit_pipetest_stage3.json', 'w') as fp:\n",
    "    fp.write(asn.dump()[1])\n",
    "\n",
    "print(asn)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp3 = Spec3Pipeline.call('lrs_slit_pipetest_stage3.json', save_results=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plots & tests\n",
    "\n",
    "We produce some plots below to check the output of the resample step. What are we looking for?\n",
    "\n",
    "* The combined 2D image should be 387 (rows) x 62 (columns) in size. \n",
    "* The combined resampled image (the positive trace) should be centred in the image, flanked by 2 negative traces which correspond to the subtarcted complementary traces from the individual nod images. We check in the plot below that the trace is centred.\n",
    "\n",
    "* In the extracted products, the wavelength calibration for all 3 spectra should match - there should be no systematic offset. \n",
    "\n",
    "There aren't numerical tests for all these checks so they do require some visual inspection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2d3_file = glob.glob('*pipetest*_s2d.fits')\n",
    "s2d3 = datamodels.open(s2d3_file[0])\n",
    "x1d3_file = glob.glob('*pipetest*_x1d.fits')\n",
    "x1d3 = datamodels.open(x1d3_file[0])\n",
    "\n",
    "assert np.shape(s2d3.data)==(387,62), \"Spec3 output does not have the expected shape. Its shape is {0}\".format(np.shape(s2d3.data)\n",
    "                                                                                                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# the spec2 resampled files\n",
    "s2d2_file = glob.glob('*nod*_s2d.fits')\n",
    "print(s2d2_file)\n",
    "\n",
    "fig1, ax = plt.subplots(ncols=3, nrows=1, figsize=[15,8])\n",
    "for ii, ff in enumerate(s2d2_file):\n",
    "    s2d2 = datamodels.open(ff)\n",
    "    ax[ii].imshow(s2d2.data, origin='lower', interpolation='None')\n",
    "    ax[ii].set_title(s2d2.meta.filename)\n",
    "    \n",
    "\n",
    "\n",
    "ax[2].imshow(s2d3.data, origin='lower', aspect='auto', interpolation='None')\n",
    "ax[2].set_title('Combined resampled image (Spec3)')\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_files = glob.glob('*_x1d.fits')\n",
    "\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=[10,6])\n",
    "\n",
    "for ef in extracted_files:\n",
    "    x1d = datamodels.open(ef)\n",
    "    ax.plot(x1d.spec[0].spec_table['WAVELENGTH'], x1d.spec[0].spec_table['FLUX'], label=x1d.meta.filename)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title('Comparison of extracted spectra (spec 2 and spec 3)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** S. Kendrew, sarah.kendrew@esa.int, ESA and INS/STScI\n",
    "<br>**Updated On:** May 28th 2021 (first version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
