{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Testing Notebook: Calwebb_Image3, Resample step\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: FGS, MIRI, NIRCam, NIRISS, NIRSpec \n",
    "\n",
    "Tested on MIRI Simulated data\n",
    "\n",
    "### Table of Contents\n",
    "<div style=\"text-align: left\"> \n",
    "\n",
    "<br>  [Introduction](#intro_ID) <br> [Run JWST Pipelines](#pipeline_ID) <br> [Imports](#imports_ID) <br> [Create an association table for your cal files and run them through calwebb_image3](#runpipeline_ID) <br> [Find Stars in Image and Determine their Coordinates](#runscript_ID) <br> [Compare RA and Dec to expected Values](#residual_ID) <br> [About This Notebook](#about_ID) <br>\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "# Introduction\n",
    "\n",
    "\n",
    "This test is designed to test the resample step in the calwebb_image3 pipeline. At the end of the calwebb_image3 pipeline, the set of files defined in an association table will be distortion corrected and combined. Resample is the step that applies the distortion correction using the drizzling algorithm (as defined in the DrizzlePac handbook) and combines the listed files. For more information on the pipeline step visit the links below. \n",
    "\n",
    "Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/resample/main.html\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/resample\n",
    "\n",
    "The data for this test were created with the MIRI Data Simulator, and the documentation for that code can be found here: http://miri.ster.kuleuven.be/bin/view/Public/MIRISim_Public\n",
    "\n",
    "\n",
    "### Calibration WG Requested Algorithm: \n",
    "\n",
    "A short description and link to the page: https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Image+Combination\n",
    "\n",
    "\n",
    "### Defining Terms\n",
    "Definition of terms or acronymns.\n",
    "\n",
    "JWST: James Webb Space Telescope\n",
    "\n",
    "MIRI: Mid-Infrared Instrument\n",
    "\n",
    "MIRISim: MIRI Data Simulator\n",
    "\n",
    "### Description of test\n",
    "\n",
    "This test is performed by creating a set of simulated data with multiple point sources located at specified coordinates. The simulator puts in the expected distortion, so the initial output data comes out of the simulator in distorted coordinates. When this data is then run through calwebb_detector1, calwebb_image2 and calwebbb_image3, the combined, undistorted image should have the point sources registered at the expected locations. In flight, this test can be repeated with known stars that should be found at their expected coordinates.\n",
    "\n",
    "### Create the data for testing\n",
    "\n",
    "The set of data used in this particular test were created with the MIRI Data Simulator (MIRISim). Referring to the MIRISim link, you can see how to set up and run the simulator to re-create the input files if you wish. The data was run with a scene.ini file that specified what the scene should look like, with coordinates for the stars given in units of arcsecond offsets from the center of the field of view. The scene.ini file as well as the setup files simuation.ini and simulator.ini are needed to run the simulation.\n",
    "\n",
    "Once in the mirisim conda environment, the simulation is run with the command line:\n",
    "> mirisim simulation.ini\n",
    "\n",
    "The simulator created four files, two exposures each at two different dither positions, using the specified filter. Make sure the WCSAXES header keyword in the SCI extension is set to 2 and not 4. If it is set to 4, change it to 2.\n",
    "\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline_ID\"></a>\n",
    "## Run JWST Pipelines\n",
    "\n",
    "The four files were then run individually through the calwebb_detector1 and calwebb_image2 pipelines. When running the calwebb_detector1 pipeline, increase the threshold for a detection in the jump step from 4 sigma to 10 sigma to avoid a current issue where the jump detection step flags a large percentage of pixels as jumps. This can be done on the command line. (commands to be typed start with $)\n",
    "\n",
    "The pipelines can be run on the command line with the following commands or put into a script while using the pipeline conda environment.\n",
    "\n",
    "$ strun calwebb_detector1.cfg filename --steps.jump.rejection_threshold 10.0\n",
    "\n",
    "The output of the calwebb_detector1 pipeline is a set of four *rate.fits files which will then be run through the calwebb_image2 pipeline.\n",
    "\n",
    "$ strun calwebb_image2.cfg filename\n",
    "\n",
    "The output of the calwebb_image2 pipeline was then a set of four *cal.fits files. An association table was created that included these four files as input, and then the files and the association table were run through the calwebb_image3 pipeline. \n",
    "\n",
    "The cal files are stored in artifactory, and this notebook is meant to pull those files for the test of resample. Step through the cells of this notebook to run calwebb_image3 and then check the alignment.\n",
    "\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<a id=\"imports_ID\"></a>\n",
    "# Imports\n",
    "The following packages will need to be imported for the scripts to work.\n",
    "\n",
    "\n",
    "* astropy.io for opening files\n",
    "* astropy.stats for sigma clipping routine\n",
    "* astropy.visualization for image plotting\n",
    "* ci_watson.artifactory_helpers to read in data from artifactory\n",
    "* jwst.datamodels for opening files as a JWST Datamodel\n",
    "* jwst.pipeline to run the pipeline step/module\n",
    "* jwst.associations to create association table\n",
    "* numpy for calculations\n",
    "* matplotlib.pyplot.plt to generate plot\n",
    "* os for path information  \n",
    "* photutils for star finding and aperture photometry\n",
    "* regtest to retrieve data from artifactory needed to run notebook\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "45177853-942e-4949-9e30-f544d70ef5f4"
    }
   },
   "outputs": [],
   "source": [
    "from astropy.io import ascii, fits\n",
    "from astropy.stats import sigma_clipped_stats\n",
    "from astropy.table import Column\n",
    "from astropy.visualization import SqrtStretch\n",
    "from astropy.visualization.mpl_normalize import ImageNormalize\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "from jwst.datamodels import DrizProductModel, ImageModel\n",
    "from jwst.pipeline import Image3Pipeline\n",
    "from jwst import associations\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "from jwst.associations import asn_from_list\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from photutils import CircularAperture, DAOStarFinder, CircularAnnulus, aperture_photometry\n",
    "from jwst.regtest.regtestdata import RegtestData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"runpipeline_ID\"></a>\n",
    "# Open an association table for your cal files and run them through calwebb_image3\n",
    "\n",
    "Load the association table to use the .cal files that were output from calwebb_image2. That will be the input for calwebb_image3 that uses the resample step to combine each of the individual images.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use regtest infrastructure to access all input files associated with the association file\n",
    "\n",
    "rtdata = RegtestData(inputs_root=\"jwst_validation_notebooks\", env=\"validation_data\")\n",
    "rtdata.get_asn(\"resample/resample_miri_test/starfield_74_asnfile.json\")\n",
    "rtdata.input #this should be the list of files associated with the asn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Calwebb_image3 on the association table\n",
    "    \n",
    "# set any specific parameters\n",
    "# tweakreg parameters to allow data to run\n",
    "fwhm=2.5  # Gaussian kernel FWHM of objects expected, default=2.5\n",
    "minobj=5  # minimum number of objects needed to match positions for a good fit, default=15\n",
    "snr= 250 # signal to noise threshold, default=5\n",
    "sigma= 3 # clipping limit, in sigma units, used when performing fit, default=3\n",
    "fit_geom='shift' # ftype of affine transformation to be considered when fitting catalogs, default='general'\n",
    "use2dhist=False  # boolean indicating whether to use 2D histogram to find initial offset, default=True\n",
    "   \n",
    "pipe3=Image3Pipeline()    \n",
    "pipe3.tweakreg.kernel_fwhm = fwhm\n",
    "pipe3.tweakreg.snr_threshold = snr\n",
    "pipe3.tweakreg.minobj = minobj\n",
    "pipe3.tweakreg.sigma = sigma\n",
    "pipe3.tweakreg.fitgeometry = fit_geom\n",
    "pipe3.tweakreg.use2dhist = use2dhist\n",
    "#pipe3.skymatch.skip = True        # test to see if this affects the final output\n",
    "pipe3.source_catalog.save_results = True\n",
    "pipe3.save_results = True\n",
    "\n",
    "    \n",
    "# run Image3\n",
    "\n",
    "im = pipe3.run(rtdata.input)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"runscript_ID\"></a>\n",
    "# Find stars in image and determine their coordinates\n",
    "\n",
    "The output of the pipeline command in the previous step (given our association table) is an i2d.fits file. This file is in the format of a JWST Data model type of DrizProductModel and should be opened as such. It is this file that we will use for source finding and to determine whether the stars are found in the expected locations. The i2d file and the associated text file containing the input coordinates of the stars can be found in artifactory.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read in combined i2d data file and list of coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the combined data file and list of coordinates\n",
    "\n",
    "with ImageModel('starfield_74_combined_i2d.fits') as im:\n",
    "    # raises exception if file is not the correct model    \n",
    "    pass\n",
    "\n",
    "\n",
    "coords = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'resample',\n",
    "                     'resample_miri_test', \n",
    "                     'radec_coords.txt')\n",
    "\n",
    "# read in text file with RA and Dec input coordinates\n",
    "RA_in, Dec_in = np.loadtxt( coords, dtype=str, unpack=True)\n",
    "\n",
    "# put RA and Dec into floats\n",
    "RA_sim = RA_in.astype(float)\n",
    "Dec_sim = Dec_in.astype(float)\n",
    "\n",
    "\n",
    "# pull out data portion of input file\n",
    "data = im.data\n",
    "\n",
    "# print stats on input image\n",
    "mean, median, std = sigma_clipped_stats(data, sigma=200.0, maxiters=5)  # default sigma=3\n",
    "print(mean, median, std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run DAOStar finder to find sources in the image and examine the image and positions marked. \n",
    "The block of code below will find the sources in the image, create apertures for each source found, and output the table of x, y coordinates along with the peak pixel value. It will also show a scaled version of the image and mark in blue the positions of sources found.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run DAOStarFinder to find sources in image\n",
    "\n",
    "ap_radius = 4.  # radius for aperture for centroiding and photometry\n",
    "\n",
    "daofind = DAOStarFinder(fwhm=3.0, threshold=10.*std)    # default threshold=5*std, fwhm=3\n",
    "sources = daofind(data)    \n",
    "print(sources['xcentroid','ycentroid','peak'])   \n",
    "\n",
    "# create apertures for sources\n",
    "\n",
    "positions = (sources['xcentroid'], sources['ycentroid'])\n",
    "apertures = CircularAperture(positions, r=ap_radius)\n",
    "\n",
    "# mark sources on image frame to see if the correct sources were found\n",
    "norm = ImageNormalize(stretch=SqrtStretch())\n",
    "# keep image stretch in mind for plotting. sky subtracted range ~ (-15, 10), single sample ~ (0, 20)\n",
    "plt.imshow(data, cmap='Greys', origin='lower', vmin=-15,vmax=10, norm=norm)\n",
    "apertures.plot(color='blue', lw=1.5, alpha=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run photometry on apertures (with a specified annulus for background subtraction)\n",
    "\n",
    "Set a specified annulus (inner and outer radii for the annulus).\n",
    "\n",
    "Run photometry on aperture and annuli.\n",
    "\n",
    "Subtract background values in annulus from aperture photometry.\n",
    "\n",
    "Output should be a table of photometry values printed to the screen (full table has columns id, xcenter, ycenter, aperture_sum and the added columns annulus_median, aperture_bkg and aperture_sum_bkgsub). You can choose which columns you wish to see printed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set values for inner and outer annuli to collect background counts\n",
    "\n",
    "inner_annulus = 10.\n",
    "outer_annulus = 15.\n",
    "\n",
    "# set up annulus for background\n",
    "background_aper = CircularAnnulus(positions, r_in=inner_annulus, r_out=outer_annulus)\n",
    "\n",
    "# perform photometry on apertures for targets and background annuli\n",
    "phot_table = aperture_photometry(im.data, apertures)\n",
    "\n",
    "# perform background subtraction with outlier rejection\n",
    "bkg_median = []\n",
    "bkg_mask = background_aper.to_mask(method='center')\n",
    "bmask = bkg_mask[0]\n",
    "for mask in bkg_mask:\n",
    "    aper_data = bmask.multiply(data)\n",
    "    aper_data = aper_data[mask.data > 0]\n",
    "    \n",
    "    # perform sigma-clipped median\n",
    "    _, median_sigclip, _ = sigma_clipped_stats(aper_data)\n",
    "    bkg_median.append(median_sigclip)\n",
    "bkg_median = np.array(bkg_median)\n",
    "\n",
    "\n",
    "# do calculations on background regions found in annuli\n",
    "# Get average background per pixel\n",
    "phot_table['annulus_median'] = bkg_median\n",
    "# Get total background in the science aperture (per pixel * area in aperture)\n",
    "phot_table['aperture_bkg'] = bkg_median * apertures.area\n",
    "# subtract background in aperture from flux in aperture\n",
    "phot_table['aperture_sum_bkgsub'] = phot_table['aperture_sum'] - phot_table['aperture_bkg']\n",
    "\n",
    "print(phot_table['aperture_sum','annulus_median','aperture_bkg','aperture_sum_bkgsub'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Put x, y coordinates into RA and Dec using the wcs information from the files.\n",
    "The output of the next block of code should be a table showing the x and y centroid positions as well as the associated RA and Dec values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using wcs info from images, put coordinates into RA, Dec\n",
    "ra, dec = im.meta.wcs(sources['xcentroid'], sources['ycentroid'])\n",
    "\n",
    "# add RA, Dec to sources table\n",
    "\n",
    "ra_col = Column(name='RA', data=ra)\n",
    "dec_col = Column(name='Dec', data=dec)\n",
    "sources.add_column(ra_col)\n",
    "sources.add_column(dec_col)\n",
    "\n",
    "# print RA, Dec for each x, y position found\n",
    "print(sources['xcentroid', 'ycentroid', 'RA', 'Dec'])   \n",
    "\n",
    "# add option to print out list of sources with flux values\n",
    "outtable = 'sourcelist_phot_rate.txt'\n",
    "sources.add_column(phot_table['aperture_sum'])\n",
    "sources.add_column(phot_table['aperture_sum_bkgsub'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compare the RA and Dec positions used to create the simulated data to the values found in the output image.\n",
    "Difference each set of RA and Dec coordinates in both the input list and the found coordinates, taking into account any angles close to 360/0 degrees. If the difference for both the RA and Dec are below a set tolerance, then the positions match. Take the matched positions and convert the differences from degrees to milli arcseconds, and output the RA and Dec positions as well as the differences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare input RA, Dec to found RA, Dec\n",
    "print('       RA found       Dec found    RA_Diff (mas)  Dec_diff (mas)  Bkg sub flux  pass/fail')\n",
    "\n",
    "for i in np.arange(0,len(RA_sim)):\n",
    "    for j in np.arange(0,len(ra)):\n",
    "        ra_diff = 180 - abs(abs(RA_sim[i] - ra[j])-180)\n",
    "        dec_diff = 180 - abs(abs(Dec_sim[i] - dec[j])-180)\n",
    "\n",
    "        if ra_diff < 1e-5 and dec_diff < 1e-5:\n",
    "            # put differences in milliarcseconds\n",
    "            ra_diff = ra_diff * 3600000\n",
    "            dec_diff = dec_diff * 3600000\n",
    "            if ra_diff < 30 and dec_diff < 30: \n",
    "                test = 'pass' \n",
    "            else: \n",
    "                test = 'fail'\n",
    "            print('{:15.6f} {:15.6f} {:15.6f} {:15.6f} {:15.6f} {}'.format(ra[j], dec[j], ra_diff, dec_diff, \n",
    "                                                                        phot_table['aperture_sum_bkgsub'][j], test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"residual_ID\"></a>\n",
    "# Compare output RA and Dec to expected values\n",
    "\n",
    "The output RA and Dec coordinates should match the input RA and Dec coordinates to within 1/10 of a PSF FWHM (~0.03 arcsec for F770W).\n",
    "\n",
    "Output RA_Diff and Dec_diff above should be on order of 30 or fewer milliarcseconds.\n",
    "\n",
    "Check to see if your input flux is roughly what you expected based on the input data.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** M. Cracraft, Research and Instrument Scientist II, INS/MIRI\n",
    "<br>**Updated On:** 08/09/2019 to add in aperture photometry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An extra optional test that can be done is to plot the flux values against x or y values. Previous testing has shown a spatial dependence of the flux with y values, so a quick plot can show whether this problem is fixed or not. Prior to the resample step, there is no pattern, after the step, a pattern is clear. Just do this as a last check. If the scatter is not random, there may be a problem that needs to be checked. (Of course, this only works if you give an equivalent if not equal input count level to each input star.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title('Surface brightness vs. y position on detector')\n",
    "plt.ylim(35500,37500) # help weed out sources that were erroneously 'hits' (bad pixels, cosmic rays, etc)\n",
    "plt.xlabel('y centroid position')\n",
    "plt.ylabel('Surface brightness')\n",
    "plt.plot(sources['ycentroid'], phot_table['aperture_sum_bkgsub'], marker='o',linestyle='') #ylim=(30000,40000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
