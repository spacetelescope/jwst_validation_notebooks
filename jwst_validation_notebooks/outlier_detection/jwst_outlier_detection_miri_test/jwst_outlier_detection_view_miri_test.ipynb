{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Notebook: MIRI view outlier_detection\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: e.g., FGS, MIRI, NIRCam, NIRISS\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "\n",
    "<div style=\"text-align: left\"> \n",
    "    \n",
    "<br> [Introduction](#intro)\n",
    "<br> [JWST CalWG Algorithm](#algorithm)\n",
    "<br> [Defining Terms](#terms)\n",
    "<br> [Test Description](#description)\n",
    "<br> [Data Description](#data_descr)\n",
    "<br> [Imports](#imports)\n",
    "<br> [Loading the Data](#data_load)\n",
    "<br> [Run the Pipeline](#pipeline)\n",
    "<br> [Perform Tests or Visualization](#testing) \n",
    "<br> [About This Notebook](#about)\n",
    "<br>    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Introduction\n",
    "\n",
    "This notebook allows visual inspection of a set of dithered images that are combined as part of calwebb_image3. The notebook will take a set of four simulated images, starting with the uncal format files that are the output of MIRISim. These images will have a randomized location for about 50 point sources and no extended sources.\n",
    "\n",
    "These data files will be processed through calwebb_detector1, calwebb_image2 and calwebb_image3 and the output *i2d data file will be inspected. Past versions of the pipeline had the background subtracted twice, so the background levels were strongly negative, and other versions have had the background pixels wrongly flagged by outlier_detection. Part of this notebook is simply a visual inspection to be sure there is nothing obviously wrong with the output. While this notebook will look at the output of calwebb_image3 as a whole, the main task is to find where outlier_detection is incorrectly flagging pixels.\n",
    "\n",
    "This notebook also inserts 'cr hits' at various random locations in each cal image (output of calwebb_image2), before running them through calwebb_image3. This notebook then tests whether the cr hits are correctly flagged as outliers by the outlier_detection step. There is also a visual comparison between the combined data with and without outlier_detection being performed to see if the output image has fewer artifacts in the version with outlier_detection.\n",
    "\n",
    "> Pipeline documentation: https://jwst-pipeline.readthedocs.io/en/latest/jwst/outlier_detection/main.html\n",
    "\n",
    "> Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/outlier_detection\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"algorithm\"></a>\n",
    "# JWST CalWG Algorithm\n",
    "\n",
    "The outlier detection algorithm is defined in the confluence page listed here. It is used to reject outlier pixels found when comparing multiple dithered images together. Images are compared in overlapping regions and any pixel that seems to be an outlier (based on iterative sigma clipping) can be flagged and rejected from any combined set or mosaic of images.\n",
    "\n",
    "> https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Outlier+Detection\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"terms\"></a>\n",
    "# Defining Terms\n",
    "\n",
    "Here are some of the terms that will be used in this notebook.\n",
    "\n",
    "JWST: James Webb Space Telescope\n",
    "\n",
    "MIRI: Mid-Infrafred Instrument\n",
    "\n",
    "MIRISim: MIRI data simulator\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"description\"></a>\n",
    "# Test Description\n",
    "\n",
    "This test takes a set of simulated images (at different dithered positions) and proceses them through all three stages of the Imager pipeline: calwebb_detector1, calwebb_image2, and calwebb_image3. A set of random pixels have added simulated 'cr hits' and this notebook checks that those pixels are properly flagged as outliers. The tests being run here also look at the output of the full image3 pipeine (the combined i2d data), check that the source_catalog output catalog marks the locations of our point sources, and checks on the number of pixels that are flagged in the outlier_detection step to be sure that the step is not flagging too many pixels. There is also a comparison between the images run through calwebb_image3 with and without outlier_detection performed to see if the outliers were detected and removed from the image as they should be with outlier_detection.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_descr\"></a>\n",
    "# Data Description\n",
    "\n",
    "The set of data used in this particular test were created with the MIRI Data Simulator (MIRISim). The simulator created four imaging mode files, one exposure each at four different dither positions, using the specified filter. There are approximately 50 point sources scattered through the images.\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tempdir\"></a>\n",
    "# Set up Temporary Directory\n",
    "The following cell sets up a temporary directory (using python's `tempfile.TemporaryDirectory()`), and changes the script's active directory into that directory (using python's `os.chdir()`). This is so that, when the notebook is run through, it will download files to (and create output files in) the temporary directory rather than in the notebook's directory. This makes cleanup significantly easier (since all output files are deleted when the notebook is shut down), and also means that different notebooks in the same directory won't interfere with each other when run by the automated webpage generation process.\n",
    "\n",
    "If you want the notebook to generate output in the notebook's directory, simply don't run this cell.\n",
    "\n",
    "If you have a file (or files) that are kept in the notebook's directory, and that the notebook needs to use while running, you can copy that file into the directory (the code to do so is present below, but commented out).\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "import shutil\n",
    "data_dir = TemporaryDirectory()\n",
    "\n",
    "# If you have files that are in the notebook's directory, but that the notebook will need to use while\n",
    "# running, copy them into the temporary directory here.\n",
    "#\n",
    "# files = ['name_of_file']\n",
    "# for file_name in files:\n",
    "#     shutil.copy(file_name, os.path.join(data_dir.name, file_name))\n",
    "\n",
    "os.chdir(data_dir.name)\n",
    "print(data_dir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "# Imports\n",
    "List the package imports and why they are relevant to this notebook.\n",
    "\n",
    "\n",
    "* astropy.io for opening fits files\n",
    "* astropy visualization for viewing images\n",
    "* jwst pipeline to get the pipeline stages being tested\n",
    "* jwst.datamodels for building model for JWST Pipeline\n",
    "* ci_watson tools to retrieve data from artifactory\n",
    "* matplotlib.pyplot.plt to generate plots\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.visualization import LogStretch, PercentileInterval, ManualInterval, LinearStretch\n",
    "from astropy import table\n",
    "from astropy.visualization import (MinMaxInterval, SqrtStretch, ImageNormalize)\n",
    "\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "import glob\n",
    "\n",
    "from jwst.pipeline import Detector1Pipeline, Image2Pipeline, Image3Pipeline\n",
    "from jwst import associations\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "from jwst.associations import asn_from_list\n",
    "from jwst.datamodels import RampModel, ImageModel, dqflags\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_load\"></a>\n",
    "# Loading the Data\n",
    "\n",
    "### Data for internal use: Artifactory method\n",
    "Artifactory should be used for data that is for internal use only.\n",
    "\n",
    "The MIRISim data and any needed reference files to use with this simulated data are stored in artifactory.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_files = ['starfield_50star4ptdither_seq1_MIRIMAGE_F1130Wexp1.fits', \n",
    "               'starfield_50star4ptdither_seq2_MIRIMAGE_F1130Wexp1.fits',\n",
    "               'starfield_50star4ptdither_seq3_MIRIMAGE_F1130Wexp1.fits',\n",
    "               'starfield_50star4ptdither_seq4_MIRIMAGE_F1130Wexp1.fits']\n",
    "\n",
    "for file in input_files:\n",
    "    input_file = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'outlier_detection',\n",
    "                     'outlier_detection_miri_test',\n",
    "                     file)\n",
    "\n",
    "\n",
    "#This readnoise file is needed for use with simulated data which has higher readnoise than actual data.\n",
    "readnoise = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'jump',                     \n",
    "                     'jump_miri_test', \n",
    "                     'jwst_mirisim_readnoise.fits')\n",
    "\n",
    "\n",
    "print(\"Finished Downloads\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "# Run the Pipeline steps\n",
    "\n",
    "The sections below will run the data through multiple pipeline steps, starting with calwebb_detector1 and calwebb_image2.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the calwebb_detector1 pipeline\n",
    "\n",
    "# set up pipeline parameters \n",
    "rej_thresh=10.0  # rejection threshold for jump step\n",
    "\n",
    "print('There are ', len(input_files), ' images.')\n",
    "        \n",
    "slopelist = []    \n",
    "    \n",
    "# loop over list of files\n",
    "for file in input_files:\n",
    "       \n",
    "    # set up pipeline parameters for input\n",
    "    pipe1 = Detector1Pipeline()\n",
    "    pipe1.jump.rejection_threshold = rej_thresh\n",
    "    pipe1.jump.override_readnoise = readnoise\n",
    "    pipe1.ramp_fit.override_readnoise = readnoise\n",
    "    \n",
    "    pipe1.refpix.skip = True  # needs update to simulator for this to work properly with simulated data\n",
    "    \n",
    "    # set up output file name\n",
    "    base, remainder = file.split('.')\n",
    "    outname = base\n",
    "        \n",
    "    pipe1.output_file = outname+'.fits'\n",
    "\n",
    "    # Run pipeline on each file\n",
    "    rampfile = pipe1.run(file)\n",
    "    slopelist.append(rampfile)\n",
    "    \n",
    "    # Close the input files\n",
    "    #file.close()\n",
    "\n",
    "print('Detector 1 steps completed on all files.')\n",
    "print(slopelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Calwebb_image2 on output files from detector1\n",
    "    \n",
    "print('There are ', len(slopelist), ' images.')\n",
    "\n",
    "# create an object for the pipeline    \n",
    "\n",
    "callist = []\n",
    "ratefilenames = []\n",
    "\n",
    "# cycle through files\n",
    "for rampfile in slopelist:\n",
    "    pipe2 = Image2Pipeline()\n",
    "    filename = rampfile.meta.filename\n",
    "    ratefilenames.append(filename)\n",
    "    # Set pipeline parameters\n",
    "\n",
    "    pipe2.save_results = True\n",
    "    pipe2.output_file = filename +'_cal.fits'\n",
    "    pipe2.resample.save_results = True\n",
    "    pipe2.suffix = None\n",
    "\n",
    "    calfile = pipe2.run(rampfile)\n",
    "\n",
    "    callist.append(calfile)\n",
    "    \n",
    "print(callist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an ordered list of the calibrated file names\n",
    "print(ratefilenames)\n",
    "cal_files = [ele.replace('rate', 'cal') for ele in ratefilenames]\n",
    "print(cal_files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create association table of data output from calwebb_image2.\n",
    "\n",
    "The calwebb_image3 pipeline takes in an association table of a set of images which should be combined. The association table can also be used to specify a background image to be subtracted or a source catalog to be used within the pipeline (sourcecat is not typically used with MIRI)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use asn_from_list to create association table\n",
    "\n",
    "asn = asn_from_list.asn_from_list(cal_files, rule=DMS_Level3_Base, product_name='starfield_50star4ptdither_combined.fits')\n",
    "\n",
    "# use this if you need to add non'science' exposure types\n",
    "#asn['products'][0]['members'][1]['exptype'] = 'background'\n",
    "#asn['products'][0]['members'][2]['exptype'] = 'sourcecat'\n",
    "\n",
    "# dump association table to a .json file for use in image3\n",
    "with open('starfield_50star4ptdither_asnfile.json', 'w') as fp:\n",
    "    fp.write(asn.dump()[1])\n",
    "\n",
    "print(asn)    \n",
    "\n",
    "print(cal_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert outliers\n",
    "\n",
    "Insert 'outliers' into the files to see if they are detected by the outlier_detection step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose random pixel locations to produce outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixloc = []\n",
    "for i in range(len(cal_files)):\n",
    "    pixloc.append([random.randint(20,1010),random.randint(430,1010)])\n",
    "    pixloc.append([random.randint(20,1010),random.randint(430,1010)])\n",
    "    pixloc.append([random.randint(20,1010),random.randint(430,1010)])\n",
    "    pixloc.append([random.randint(20,1010),random.randint(430,1010)])\n",
    "pixloc2 = np.array(pixloc)\n",
    "\n",
    "print(pixloc2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign pixel values to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This block of code caused a pipeline crash in image3. Use the cell below instead, as that ran to completion\n",
    "\n",
    "#for i in range(len(cal_files)):\n",
    "#    with ImageModel(cal_files[i]) as im:\n",
    "#        print(im.meta.filename)    \n",
    "#        j = 4*i\n",
    "#        med = np.median(im.data)\n",
    "#        print(med)\n",
    "        \n",
    "        # Put in elevated flux values at randomized coordinates\n",
    "#        im.data[pixloc2[j,0],pixloc2[j,1]] = med*5.0\n",
    "#        im.data[pixloc2[j+1,0],pixloc2[j+1,1]] = med*10.0\n",
    "#        im.data[pixloc2[j+2,0],pixloc2[j+2,1]] = med*15.0\n",
    "#        im.data[pixloc2[j+3,0],pixloc2[j+3,1]] = med*20.0\n",
    "        \n",
    "#        im.save(im.meta.filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(cal_files)):\n",
    "     with fits.open(cal_files[i]) as h:      \n",
    "        j = 4*i\n",
    "        med = np.median(h['SCI'].data)\n",
    "        h['SCI'].data[pixloc2[j,0],pixloc2[j,1]] = med*5.0\n",
    "        h['SCI'].data[pixloc2[j+1,0],pixloc2[j+1,1]] = med*10.0\n",
    "        h['SCI'].data[pixloc2[j+2,0],pixloc2[j+2,1]] = med*15.0\n",
    "        h['SCI'].data[pixloc2[j+3,0],pixloc2[j+3,1]] = med*20.0\n",
    "        h.writeto(cal_files[i],overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the images with outliers added to see if any landed on sources or might be less likely to be detected\n",
    "i = 0\n",
    "for image in cal_files:\n",
    "    imagetest = ImageModel(image) \n",
    "    print(imagetest.meta.filename)\n",
    "    print('Min value ', np.nanmin(imagetest.data), 'Max value ', np.nanmax(imagetest.data))\n",
    "    j = 4*i\n",
    "    crs = pixloc2[j:j+4]\n",
    "    print(crs)\n",
    "    yvals = pixloc2[j:j+4,0]\n",
    "    xvals = pixloc2[j:j+4,1]\n",
    "\n",
    "    plt.figure(figsize=(15,15))\n",
    "    plt.imshow(imagetest.data,cmap=\"Greys\",origin='lower',vmin=0, vmax=50)\n",
    "    plt.colorbar()\n",
    "    plt.scatter(xvals, yvals,lw=1, s=10,color='red')\n",
    "    i += 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run calwebb_image3 on the association table, setting any specific parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use association table created in previous step with calwebb_image3\n",
    "    \n",
    "# set any specific parameters\n",
    "# tweakreg parameters to allow data to run\n",
    "fwhm=3.762  # Gaussian kernel FWHM of objects expected, default=2.5\n",
    "minobj=5  # minimum number of objects needed to match positions for a good fit, default=15\n",
    "snr= 100 # signal to noise threshold, default=5\n",
    "sigma= 3 # clipping limit, in sigma units, used when performing fit, default=3\n",
    "fit_geom='shift' # ftype of affine transformation to be considered when fitting catalogs, default='general'\n",
    "use2dhist=False  # boolean indicating whether to use 2D histogram to find initial offset, default=True\n",
    "\n",
    "pipe3=Image3Pipeline()    \n",
    "pipe3.tweakreg.kernel_fwhm = fwhm\n",
    "pipe3.tweakreg.snr_threshold = snr\n",
    "pipe3.tweakreg.minobj = minobj\n",
    "pipe3.tweakreg.sigma = sigma\n",
    "pipe3.tweakreg.fitgeometry = fit_geom\n",
    "pipe3.tweakreg.use2dhist = use2dhist\n",
    "pipe3.source_catalog.kernel_fwhm = fwhm\n",
    "pipe3.source_catalog.snr_threshold = snr\n",
    "pipe3.skymatch.save_results = True\n",
    "pipe3.outlier_detection.save_results = True\n",
    "pipe3.resample.save_results = True\n",
    "pipe3.source_catalog.save_results = True\n",
    "pipe3.save_results = True\n",
    "\n",
    "# run Image3\n",
    "pipe3.run('starfield_50star4ptdither_asnfile.json')    \n",
    "print('Image 3 pipeline finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"testing\"></a>\n",
    "# Perform Tests or Visualization\n",
    "\n",
    "View the image and check number of pixels being flagged as outliers. \n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in i2d file\n",
    "\n",
    "im_i2d = ImageModel('starfield_50star4ptdither_combined_i2d.fits')\n",
    "\n",
    "#norm = ImageNormalize(im_i2d.data, interval=MinMaxInterval(),\n",
    "#                      stretch=LinearStretch())\n",
    "\n",
    "# mask out DO_NOT_USE values where data has been set to 0 in the combined image\n",
    "masked_im = np.ma.masked_where((im_i2d.data == 0), im_i2d.data)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap(\"Greys\").copy()  # Can be any colormap that you want after the cm\n",
    "cmap.set_bad(color='white') # color to mark all DO_NOT_USE pixels\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "#plt.imshow(im_i2d.data,origin='lower',norm=norm,vmin=-5, vmax=4)\n",
    "plt.imshow(masked_im, origin='lower', cmap = cmap, vmin=5, vmax=20)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image examination\n",
    "The image output should have the Four Quadrant phase masks on the left of the image masked out (values of 0). The image area should be smooth in the background regions with multiple point sources bright against the background. Passing criteria for the Lyot mask region are still being determined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check output of source catalog against image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "photfile = 'starfield_50star4ptdither_combined_cat.ecsv'\n",
    "data = table.Table.read(photfile, format='ascii', comment='#')\n",
    "print(len(data),' sources detected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in ecsv photom file\n",
    "from astropy.visualization import LogStretch, PercentileInterval, ManualInterval\n",
    "from astropy import table\n",
    "from matplotlib.colors import LogNorm\n",
    "from astropy.visualization import (MinMaxInterval, SqrtStretch,\n",
    "                                   ImageNormalize)\n",
    "\n",
    "norm = ImageNormalize(im_i2d.data, interval=MinMaxInterval(),\n",
    "                      stretch=SqrtStretch())\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "#plt.imshow(viz2(im_i2d.data),cmap='gray')\n",
    "plt.imshow(im_i2d.data,origin='lower', vmin=5, vmax=15)\n",
    "plt.colorbar()\n",
    "plt.scatter(data['xcentroid'], data['ycentroid'],lw=1, s=10,color='red')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check over source catalog match\n",
    "If the red dots marking sources found in image above are centered on the point sources, the test passes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check DQ Flagging of outlier detection \n",
    "Read in the individual crf files which are output from outlier_detection and check the dq extension to see how many pixels out of each image are flagged as outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "image3crffiles = glob.glob('*crf.fits')\n",
    "output_files = sorted(image3crffiles)\n",
    "print(image3crffiles)\n",
    "print()\n",
    "print(output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the names of the crf files as output by calwebb_image3. \n",
    "# This handwritten list is based on the naming of the files as they appear at the time the code was written (May 2021).\n",
    "# If the filename convention changes, this block will need to be updated.\n",
    "\n",
    "#output_files = []\n",
    "#counter = 0\n",
    "#for item in cal_files:\n",
    "#    name = 'starfield_50star4ptdither_combined'\n",
    "#    crffile = name+\"_\"+str(counter)+\"_a3001_crf.fits\"\n",
    "#    output_files.append(crffile)\n",
    "#    counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print calfiles and output_files to see the mapping of the filenames\n",
    "print(cal_files)\n",
    "print()\n",
    "print(output_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dq_after = []\n",
    "all_out_dqs = []\n",
    "\n",
    "for i in range(len(output_files)):\n",
    "    with ImageModel(output_files[i]) as crf:\n",
    "        j = 4*i\n",
    "        dq_after.append([pixloc2[j,:],crf.dq[pixloc2[j,0],pixloc2[j,1]]])\n",
    "        dq_after.append([pixloc2[j+1,:],crf.dq[pixloc2[j+1,0],pixloc2[j+1,1]]])\n",
    "        dq_after.append([pixloc2[j+2,:],crf.dq[pixloc2[j+2,0],pixloc2[j+2,1]]])\n",
    "        dq_after.append([pixloc2[j+3,:],crf.dq[pixloc2[j+3,0],pixloc2[j+3,1]]])\n",
    "        \n",
    "        all_out_dqs.append((crf.dq[pixloc2[j,0],pixloc2[j,1]] & dqflags.pixel['OUTLIER'] > 0))\n",
    "        all_out_dqs.append((crf.dq[pixloc2[j+1,0],pixloc2[j+1,1]] & dqflags.pixel['OUTLIER'] > 0))\n",
    "        all_out_dqs.append((crf.dq[pixloc2[j+2,0],pixloc2[j+2,1]] & dqflags.pixel['OUTLIER'] > 0))\n",
    "        all_out_dqs.append((crf.dq[pixloc2[j+3,0],pixloc2[j+3,1]] & dqflags.pixel['OUTLIER'] > 0))\n",
    "\n",
    "print(dq_after)\n",
    "print()\n",
    "print(all_out_dqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in each crf file output from outlier_detection and see percentage of pixels flagged as outlier\n",
    "\n",
    "flag_thresh = 1.0  # Percentage above which user should be notified of high percentage of flagged pixels\n",
    "\n",
    "for crffile in output_files: \n",
    "    file = ImageModel(crffile)\n",
    "    nx = file.meta.subarray.xsize\n",
    "    ny = file.meta.subarray.ysize\n",
    "    filename = file.meta.filename\n",
    "    print(filename)\n",
    "\n",
    "    numpix = nx * ny\n",
    "    \n",
    "    # Test that all pixels flagged with OUTLIER are also flagged as DO_NOT_USE\n",
    "    outlierarray = (file.dq & dqflags.pixel['OUTLIER'] > 0)\n",
    "    badarray = (file.dq & dqflags.pixel['DO_NOT_USE'] > 0)\n",
    "    try:\n",
    "        assert outlierarray.all() == badarray.all()\n",
    "    except:\n",
    "        print('Pixels flagged as outliers and \"DO_NOT_USE\" do not match')\n",
    "    \n",
    "    # Count number of pixels flagged as OUTLIER\n",
    "    jumpcount = (file.dq & dqflags.pixel['OUTLIER'] > 0).sum()\n",
    "    print('There are ', jumpcount, ' pixels flagged as outliers.')\n",
    "    \n",
    "    percentflagged = (jumpcount / numpix) * 100.\n",
    "\n",
    "    print('The percentage of pixels flagged is ', percentflagged)\n",
    "    if percentflagged > flag_thresh:\n",
    "        print('This percentage is higher than it should be. Review data through outlier step')\n",
    "    print('\\n')    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out whether all of the added cr hits were flagged as outliers\n",
    "\n",
    "print('Output DQ values: ', all_out_dqs)\n",
    "try:\n",
    "    assert np.alltrue(all_out_dqs) == True\n",
    "    print('MIRI Outlier Detection test: Passed')\n",
    "except:\n",
    "    print('AssertionError: At least one cr hit was not flagged')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output above should show percentages below some chosen threshold. If the percentage of pixels flagged as outliers are above the set threshold, there will be error messages printed. If no error messages are printed, this test is presumed to pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at what the combined image would look like if no outlier_detection was performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn = asn_from_list.asn_from_list(cal_files, rule=DMS_Level3_Base, product_name='starfield_50star4ptdither_combined_no_outlier.fits')\n",
    "\n",
    "# use this if you need to add non'science' exposure types\n",
    "#asn['products'][0]['members'][1]['exptype'] = 'background'\n",
    "#asn['products'][0]['members'][2]['exptype'] = 'sourcecat'\n",
    "\n",
    "# dump association table to a .json file for use in image3\n",
    "with open('starfield_50star4ptdither_no_outlier_asnfile.json', 'w') as fp:\n",
    "    fp.write(asn.dump()[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use association table created in previous step with calwebb_image3\n",
    "    \n",
    "# set any specific parameters\n",
    "# tweakreg parameters to allow data to run\n",
    "fwhm=3.762  # Gaussian kernel FWHM of objects expected, default=2.5\n",
    "minobj=5  # minimum number of objects needed to match positions for a good fit, default=15\n",
    "snr= 100 # signal to noise threshold, default=5\n",
    "sigma= 3 # clipping limit, in sigma units, used when performing fit, default=3\n",
    "fit_geom='shift' # ftype of affine transformation to be considered when fitting catalogs, default='general'\n",
    "use2dhist=False  # boolean indicating whether to use 2D histogram to find initial offset, default=True\n",
    "\n",
    "pipe3=Image3Pipeline()    \n",
    "pipe3.tweakreg.kernel_fwhm = fwhm\n",
    "pipe3.tweakreg.snr_threshold = snr\n",
    "pipe3.tweakreg.minobj = minobj\n",
    "pipe3.tweakreg.sigma = sigma\n",
    "pipe3.tweakreg.fitgeometry = fit_geom\n",
    "pipe3.tweakreg.use2dhist = use2dhist\n",
    "pipe3.source_catalog.kernel_fwhm = fwhm\n",
    "pipe3.source_catalog.snr_threshold = snr\n",
    "pipe3.skymatch.save_results = True\n",
    "\n",
    "pipe3.outlier_detection.skip = True\n",
    "\n",
    "pipe3.resample.save_results = True\n",
    "pipe3.source_catalog.save_results = True\n",
    "pipe3.save_results = True\n",
    "\n",
    "# run Image3\n",
    "pipe3.run('starfield_50star4ptdither_no_outlier_asnfile.json')    \n",
    "print('Image 3 pipeline finished.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at combined image with and without outlier detection to see if the added cosmic rays show up in the final image without outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in i2d file without outlier_detection run.\n",
    "\n",
    "im_i2d2 = ImageModel('starfield_50star4ptdither_combined_no_outlier_i2d.fits')\n",
    "\n",
    "#norm = ImageNormalize(im_i2d2.data, interval=MinMaxInterval(),\n",
    "#                      stretch=LinearStretch())\n",
    "\n",
    "# mask out DO_NOT_USE values where data has been set to 0 in the combined image\n",
    "masked_im2 = np.ma.masked_where((im_i2d2.data == 0), im_i2d2.data)\n",
    "\n",
    "cmap = matplotlib.cm.get_cmap(\"Greys\").copy()  # Can be any colormap that you want after the cm\n",
    "cmap.set_bad(color='white') # color to mark all DO_NOT_USE pixels\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "#plt.imshow(im_i2d2.data,origin='lower',norm=norm,vmin=-5, vmax=4)\n",
    "plt.imshow(masked_im2, origin='lower', cmap = cmap, vmin=5, vmax=20)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare to image with outlier_detection run\n",
    "\n",
    "#norm = ImageNormalize(im_i2d.data, interval=MinMaxInterval(),\n",
    "#                      stretch=LinearStretch())\n",
    "\n",
    "plt.figure(figsize=(15,15))\n",
    "#plt.imshow(im_i2d.data,origin='lower',norm=norm,vmin=-5, vmax=4)\n",
    "plt.imshow(masked_im, origin='lower', cmap = cmap, vmin=5, vmax=20)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Passing criteria\n",
    "\n",
    "If the inserted cosmic rays were flagged by the outlier_detection step (no AssertionError) and the outlier_detection run version of the combined image appears cleaner with fewer to no cosmic rays showing, the test passes. If there are only one or two sources that were not properly flagged, they could have been located on a source or been otherwise difficult to detect. Check the locations of the outliers as shown in earlier parts of the notebook to see if any outliers might be likely to fail to be detected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** Misty Cracraft, Senior Staff Scientist, MIRI Branch\n",
    "<br>**Updated On:** 02/17/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
