{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Testing Notebook: MIRI LRS Time Series Observation\n",
    " \n",
    " \n",
    "## Detector1Pipeline() test\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: MIRI\n",
    "\n",
    "### Table of Contents\n",
    "<div style=\"text-align: left\"> \n",
    "\n",
    "<br> [Imports](#imports_ID) <br> [Introduction](#intro_ID) <br> [Get Documentaion String for Markdown Blocks](#markdown_from_docs) <br> [Loading Data](#data_ID) <br> [Run JWST Pipeline](#pipeline_ID) <br> [Create Figure or Print Output](#residual_ID) <br> [About This Notebook](#about_ID) <br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports_ID\"></a>\n",
    "# Imports\n",
    "List the library imports and why they are relevant to this notebook.\n",
    "\n",
    "\n",
    "* astropy.io for opening fits files\n",
    "* astropy.utils for remote data retrieval\n",
    "* inspect to get the docstring of our objects.\n",
    "* IPython.display for printing markdown output\n",
    "* jwst.datamodels for building model for JWST Pipeline\n",
    "* jwst.module.PipelineStep is the pipeline step being tested\n",
    "* matplotlib.pyplot to generate plot\n",
    "\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "45177853-942e-4949-9e30-f544d70ef5f4"
    }
   },
   "outputs": [],
   "source": [
    "# from astropy.io import fits\n",
    "import inspect\n",
    "import numpy as np\n",
    "import glob\n",
    "from IPython.display import Markdown\n",
    "from jwst.datamodels import RampModel, ImageModel, CubeModel\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import astropy.io.fits as fits\n",
    "from astropy.utils.data import download_file\n",
    "\n",
    "from pysiaf import Siaf\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "# Introduction\n",
    "\n",
    "In this notebook we're testing the Detector1Pipeline() step for MIRI Low Resolution Spectroscopy (LRS) Time Series Observations (TSOs). The step takes the Level 1 data and converraw counts to DN/s units (the \"ramps to slopes\" stage). This is not a TSO-specific step, so we test to ensure the pipeline runs without crashing and executes the stage as planned; there is a dedicated configuration file for stage 1 processing for TSOs, calwebb_tso1.cfg.\n",
    "\n",
    "Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/blob/master/jwst/pipeline/calwebb_detector1.py\n",
    "\n",
    "\n",
    "### Calibration WG Requested Algorithm: \n",
    "\n",
    "A short description and link to the page: \n",
    "\n",
    "\n",
    "### Defining Term\n",
    "Here is where you will define terms or acronymns that may not be known a general audience (ie a new employee to the institute or an external user). For example\n",
    "\n",
    "* JWST: James Webb Space Telescope\n",
    "* MIRI: Mid-Infrared Instrument\n",
    "* LRS: Low Resolution Spectrometer\n",
    "* TSO: Time Series Observation\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"markdown_from_docs\"></a>\n",
    "# Get Documentation String for Markdown Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get raw python docstring\n",
    "raw = inspect.getdoc(RampModel)\n",
    "\n",
    "# To convert to markdown, you need convert line breaks from \\n to <br />\n",
    "markdown_text = \"<br />\".join(raw.split(\"\\n\"))\n",
    "\n",
    "# Here you can format markdown as an output using the Markdown method.\n",
    "Markdown(\"\"\"\n",
    "# RampModel\n",
    "---\n",
    "{}\n",
    "\"\"\".format(markdown_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_ID\"></a>\n",
    "# Loading Data\n",
    "\n",
    "We are using here a simulated TSO observation, generated with MIRISim. It is a single exposure of a star with 100 groups per integration and 10 integrations. LRS TSOs uses the SLITLESSPRISM subarray, so the data do not cover the full array. \n",
    "\n",
    "The data are stored on Box and we will retrieve from there.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainurl =\"https://data.science.stsci.edu/redirect/JWST/TSO/pipeline_testing_miri_LRS_tso/\"\n",
    "fname = 'pipetest_miri_lrs_tso_100G10I.fits'\n",
    "fdld = download_file(mainurl+fname)\n",
    "hdu = fits.open(fdld)\n",
    "hdu.info()\n",
    "# dm = some code to create datamodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the data dimensions against the SIAF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_data(hdu, aperture, tso=True):\n",
    "    ''' This function will verify the format of the data extensions against the SIAF information and header keywords.\n",
    "    '''\n",
    "    siaf = Siaf(instrument='MIRI')\n",
    "    ap = siaf[aperture]\n",
    "\n",
    "    ap_corners = ap.corners(to_frame='det')\n",
    "    ap_rows = np.int(ap_corners[1][2]-ap_corners[1][1])\n",
    "    ap_cols = np.int(ap_corners[0][1]-ap_corners[0][0])\n",
    "    \n",
    "    h = hdu[0].header\n",
    "    h_groups = h['NGROUPS']\n",
    "    h_ints= h['NINTS']\n",
    "    \n",
    "    # these checks are generally applicable for all types of exposures\n",
    "    assert np.shape(hdu['SCI'])[3] == ap_cols, \"Dimensions of SCI extension don't match the SIAF\"\n",
    "    assert np.shape(hdu['SCI'])[2] == ap_rows, \"Dimensions of SCI extension don't match the SIAF\"\n",
    "    assert np.shape(hdu['SCI'])[1] == h_groups, \"Dimensions of SCI extensions don't match the header keyword (groups)\"\n",
    "    assert np.shape(hdu['SCI'])[0] == h_ints, \"Dimensions of SCI extensions don't match the header keyword (integrations)\"\n",
    "    \n",
    "    assert np.shape(hdu['PIXELDQ'])[0] == ap_rows, \"Dimensions of PIXELDQ extension don't match the SIAF\"\n",
    "    assert np.shape(hdu['PIXELDQ'])[1] == ap_cols, \"Dimensions of PIXELDQ extension don't match the SIAF\" \n",
    "    \n",
    "    assert np.shape(hdu['REFOUT'])[3] == np.int(ap_cols/4), \"Dimensions of REFOUT extension are incompatible with the SIAF\"\n",
    "    assert np.shape(hdu['REFOUT'])[2] == ap_rows, \"Dimensions of REFOUT extension don't match the SIAF\"\n",
    "    assert np.shape(hdu['REFOUT'])[1] == h_groups, \"Dimensions of REFOUT extensions don't match the header keyword (groups)\"\n",
    "    assert np.shape(hdu['REFOUT'])[0] == h_ints, \"Dimensions of REFOUT extensions don't match the header keyword (integrations)\"\n",
    "    \n",
    "    # this check only needs to be run for TSO exposures:\n",
    "    if (tso==True):\n",
    "        assert h['TSOVISIT'], \"TSOVISIT keyword not set to True\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(np.shape(hdu['REFOUT']))\n",
    "verify_data(hdu, 'MIRIM_SLITLESSPRISM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make some plots:\n",
    "\n",
    "* look at the last frame in an integration for a counts check\n",
    "* plot the ramp for a pixel on and off the spectrum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_data = hdu['SCI'].data\n",
    "pri_h = hdu[0].header\n",
    "\n",
    "ngroups = pri_h['NGROUPS']\n",
    "nints = pri_h['NINTS']\n",
    "\n",
    "# identify a science pixel\n",
    "sci_px = [350, 37]\n",
    "\n",
    "# identify a pixel in blank sky\n",
    "bgr_px = [250, 15]\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=3, figsize=[12,4])\n",
    "\n",
    "# plot 1: frame[-1] in the first integration\n",
    "lastgrp = ax[0].imshow(sci_data[0,ngroups-1,:,:], origin='lower', interpolation='None', aspect='auto')\n",
    "ax[0].scatter(sci_px[1], sci_px[0], marker='x', color='r', label='sci pixel')\n",
    "ax[0].scatter(bgr_px[1], bgr_px[0], marker='+', color='y', label='bgr pixel')\n",
    "ax[0].set_title('Group {} Int 0'.format(ngroups-1))\n",
    "ax[0].set_xlabel('px')\n",
    "ax[0].set_ylabel('px')\n",
    "\n",
    "# plot 2: pixel slope, spectrum\n",
    "\n",
    "ax[1].set_title('Slopes, sci pixel (red x)')\n",
    "for i in range(nints):\n",
    "    ax[1].plot(sci_data[i, :, sci_px[0], sci_px[1]])\n",
    "ax[1].set_xlabel('integration')\n",
    "ax[1].set_ylabel('DN')\n",
    "\n",
    "# plot 3: pixel slope, background\n",
    "\n",
    "ax[2].set_title('Slopes, bgr pixel (yellow +)')\n",
    "for i in range(nints):\n",
    "    ax[2].plot(sci_data[i, :, bgr_px[0], bgr_px[1]])\n",
    "ax[2].set_xlabel('integration')\n",
    "ax[2].set_ylabel('DN')\n",
    "\n",
    "fig.colorbar(lastgrp, ax=ax[0])\n",
    "fig.tight_layout()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check that the file can be loaded as data model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sci_mod = RampModel(hdu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline_ID\"></a>\n",
    "# Run JWST Pipeline\n",
    "\n",
    "Here we run the Detector1Pipeline() step on the data, using all default inputs. \n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#output = PipelineStep.call(dm)\n",
    "\n",
    "step = Detector1Pipeline()\n",
    "det1 = step.call(sci_mod, config_file='calwebb_tso1.cfg', save_results=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"residual_ID\"></a>\n",
    "# Output checks\n",
    "\n",
    "We will not look into the individual outputs of the steps as the algorithms should be similar to non-TSO observations. Items to verify:\n",
    "\n",
    "* can both the rate and rateints file be loaded as a datamodel?\n",
    "* plot the time series in DN/s of the rateints file\n",
    "* are the values in the rateints file comparable with that seen in the rate file?\n",
    "* is the rate seen for the sci & background pixels consistent with the ramp values seen in DN?\n",
    "\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fb9e82bd-ecca-4033-ad38-8772e288b145"
    }
   },
   "source": [
    "### Load in the output files\n",
    "\n",
    "These were stored in the working directory with extensions \\_rate.fits and \\_rateints.fits. The rate file is compatible with the ImageModel, rateints file with CubeModel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfile = glob.glob('*_rate.fits')\n",
    "rifile = glob.glob('*_rateints.fits')\n",
    "print(rfile)\n",
    "print(rifile)\n",
    "\n",
    "rmod = ImageModel(rfile[0])\n",
    "rimod = CubeModel(rifile[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple format checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Shape of the rate file: {}'.format(np.shape(rmod.data)))\n",
    "print('Shape of the rateints file: {}'.format(np.shape(rimod.data)))\n",
    "\n",
    "assert np.shape(rimod)[1] == np.shape(rmod)[0], \"Shapes of rate and rateints file don't match\"\n",
    "assert np.shape(rimod)[2] == np.shape(rmod)[1], \"Shapes of rate and rateints file don't match\"\n",
    "assert np.shape(rimod)[0] == nints, \"Shape of rateints model doesn't match the exposure specification\"\n",
    "assert np.shape(rimod)[1] == np.shape(sci_mod)[2], \"Shape of output doesn't match input model\"\n",
    "assert np.shape(rimod)[2] == np.shape(sci_mod)[3], \"Shape of output doesn't match input model\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Produce plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this plot will compare the slope image from the _rate file with the median of the slope images in the rateints file\n",
    "# check criterion: they should look similar and the maximim values seen in both these images should be similar\n",
    "# NOTE: what is the numerical criterion to check for? not sure.\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=[8,10])\n",
    "\n",
    "rplt = ax[0].imshow(rmod.data, origin='lower', aspect='auto', interpolation='None')\n",
    "ax[0].set_title('Integrated rate file slope image')\n",
    "ax[0].set_xlabel('px')\n",
    "ax[0].set_ylabel('px')\n",
    "\n",
    "riplt = ax[1].imshow(np.median(rimod.data, axis=0), origin='lower', aspect='auto', interpolation='None')\n",
    "ax[1].set_title('Median of rateints file slope images')\n",
    "ax[1].set_xlabel('px')\n",
    "ax[1].set_ylabel('px')\n",
    "\n",
    "cbar = fig.colorbar(rplt, ax=ax, orientation='horizontal')\n",
    "cbar.set_label('DN/s')\n",
    "#fig.tight_layout()\n",
    "\n",
    "print('Max DN/s in the rate.fits slope image: {} DN/s'.format(np.max(rmod.data)))\n",
    "print('Max DN/s of the median of the rateints.fits slope images: {} DN/s'.format(np.max(np.median(rimod.data, axis=0))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second plot looks at the time series across the NINTS integrations for a 5-pixel box around the 2 reference pixels we defined above.\n",
    "# Not sure what the numerical check shoudl be here but:\n",
    "# * the full and dashed lines should be very similar\n",
    "# * the blue line should be higher than the black line\n",
    "\n",
    "scibox = np.zeros(nints)\n",
    "bgrbox = np.zeros(nints)\n",
    "\n",
    "ratescibox = np.median(rmod.data[sci_px[0]-2:sci_px[0]+3, sci_px[1]-2:sci_px[1]+3])\n",
    "ratebgrbox = np.median(rmod.data[bgr_px[0]-2:bgr_px[0]+3, bgr_px[1]-2:bgr_px[1]+3])\n",
    "\n",
    "for i in range(nints):\n",
    "    scibox[i] = np.median(rimod.data[i,sci_px[0]-2:sci_px[0]+3, sci_px[1]-2:sci_px[1]+3])\n",
    "    bgrbox[i] = np.median(rimod.data[i,bgr_px[0]-2:bgr_px[0]+3, bgr_px[1]-2:bgr_px[1]+3])\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(scibox, 'bx-', lw=2, label='median 5x5 science px, rateints')\n",
    "ax.plot(bgrbox, 'k+-', lw=2, label='median 5x5 background px, rateints')\n",
    "ax.axhline(y=ratescibox, ls='--', lw=2, color='b', label='median 5x5 science px, rate')\n",
    "ax.axhline(y=ratebgrbox, ls='--', lw=2, color='k', label='median 5x5 bgr px, rate')\n",
    "ax.grid()\n",
    "ax.set_xlabel('Integration')\n",
    "ax.set_ylabel('median DN/s')\n",
    "ax.set_ylim([0, np.max(scibox)+50])\n",
    "ax.legend(loc='best')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integration times table (TO DO)\n",
    "\n",
    "The output rateints file shoudl contain an extension with a table listing the start and end times for each integration. Chekc that this is present, and that the times are consistent with the exposure start time and group time.\n",
    "\n",
    "NOTE: this can currently not be tested as the simulated data do not contain the INT_TIMES data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQ Extenstion (TO DO)\n",
    "\n",
    "Should include some checks on the Data Quality flags."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** Sarah Kendrew, ESA Instrument Scientist, MIRI branch\n",
    "<br>**Updated On:** 24 July 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
