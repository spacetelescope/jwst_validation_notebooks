{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Notebook:  calwebb_ami3, ami_average\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: NIRISS\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "<div style=\"text-align: left\"> \n",
    "    \n",
    "<br> [Introduction\\*](#intro)\n",
    "<br> [JWST CalWG Algorithm\\*](#algorithm)\n",
    "<br> [Defining Terms](#terms)\n",
    "<br> [Test Description\\*](#description)\n",
    "<br> [Data Description\\*](#data_descr)\n",
    "<br> [Imports\\*](#imports)\n",
    "<br> [Loading the Data\\*](#data_load)\n",
    "<br> [Run the Pipeline](#pipeline)\n",
    "<br> [Perform Tests or Visualization](#testing) \n",
    "<br> [About This Notebook\\*](#about)\n",
    "<br>    \n",
    "\n",
    "</div>\n",
    "\n",
    "<a id=\"intro\"></a>\n",
    "# Introduction\n",
    "\n",
    "This is the validation notebook for the AMI average step. This step averages the results of LG processing from the ami_analyze step for multiple exposures of a given target. It computes a simple average for all 8 components of the “ami” product files from all input exposures. For more information on the pipeline step visit the links below. \n",
    "\n",
    "Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/ami_average/index.html\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/blob/master/jwst/ami/ami_average.py\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"algorithm\"></a>\n",
    "# JWST CalWG Algorithm\n",
    "\n",
    "\n",
    "Confluence page: https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Average+Fringe+Params\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"terms\"></a>\n",
    "# Defining Terms\n",
    "\n",
    "* **JWST**: James Webb Space Telescope\n",
    "* **NIRISS**: Near-Infrared Imager and Slitless Spectrograph\n",
    "* **AMI**: Aperture Masking Interferometry (NIRISS observing mode)\n",
    "* **LG**: Lacour-Greenbaum image plane modeling algorithm [(Greenbaum et al. 2015)](https://ui.adsabs.harvard.edu/abs/2015ApJ...798...68G/abstract)\n",
    "* **Interferometric observables**: quantities extracted from interferograms that describe the phase and visibility of the object\n",
    "* **OIFITS**: Optical Interferometry Flexible Image Transport System; file format used of optical interferometry\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"description\"></a>\n",
    "# Test Description\n",
    "\n",
    "This test is performed by comparing interferometric observables from multiple exposures averaged together by the pipeline step to those averaged together manually. The data are first calibrated through the Detector1, Image 2, and AMI3 ami_analyze (observable extraction) steps. We use multiple 'ami_analyze.fits' products as the starting point, and produce a single 'amiaveragestep.fits' product. While all eight data extensions of the input files are currently averaged, we are mainly interested in the four observable extensions: closure phase, closure amplitude, visibility phase, and visibility amplitude, as well as the pupil phases and fringe coefficients extensions. We test that each element of the pipeline-averaged arrays of each of these observables is equal to within $1\\times 10^{-6}$ to the same element in the manually-averaged array of observables.\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_descr\"></a>\n",
    "# Data Description\n",
    "\n",
    "The data used for this test were created with MIRAGE (Multi-Instrument RAmp GEnerator). The data set contains simulated observations of **AB Dor** (a known binary system) and **HD-37093** (a suitable calibration star) in filter F480M at four primary dither positions. These simulations do not contain bad pixels. For this test, we use two exposures of AB Dor at dither positions 2 and 3, which are cropped to 35 x 35 pixels. \n",
    "\n",
    "\n",
    "Outputs of any of the three AMI3 pipeline steps have the following structure:\n",
    "1. FIT: a 2D image of the fitted model\n",
    "2. RESID: a 2D image of the fit residuals\n",
    "3. CLOSURE_AMP: table of closure amplitudes\n",
    "4. CLOSURE_PHA: table of closure phases\n",
    "5. FRINGE_AMP: table of fringe amplitudes\n",
    "6. FRINGE_PHA: table of fringe phases\n",
    "7. PUPIL_PHA: table of pupil phases\n",
    "8. SOLNS: table of fringe coefficients\n",
    "\n",
    "**Note:** Observations at different dither positions are trimmed to different dimensions depending on their location on the SUB80 detector subarray, and the AMI3 pipeline currently crashes if input files have image extensions with different dimensions. Therefore we must currently make sure that the 'FIT' and 'RESID' extensions of the input files have the same dimensions before averaging.\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tempdir\"></a>\n",
    "# Set up Temporary Directory\n",
    "The following cell sets up a temporary directory (using python's `tempfile.TemporaryDirectory()`), and changes the script's active directory into that directory (using python's `os.chdir()`). This is so that, when the notebook is run through, it will download files to (and create output files in) the temporary directory rather than in the notebook's directory. This makes cleanup significantly easier (since all output files are deleted when the notebook is shut down), and also means that different notebooks in the same directory won't interfere with each other when run by the automated webpage generation process.\n",
    "\n",
    "If you want the notebook to generate output in the notebook's directory, simply don't run this cell.\n",
    "\n",
    "If you have a file (or files) that are kept in the notebook's directory, and that the notebook needs to use while running, you can copy that file into the directory (the code to do so is present below, but commented out).\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****\n",
    "#\n",
    "# Set this variable to False to not use the temporary directory\n",
    "#\n",
    "#****\n",
    "use_tempdir = True\n",
    "\n",
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if use_tempdir:\n",
    "    data_dir = TemporaryDirectory()\n",
    "\n",
    "    # If you have files that are in the notebook's directory, but that the notebook will need to use while\n",
    "    # running, copy them into the temporary directory here.\n",
    "    #\n",
    "    # files = ['name_of_file']\n",
    "    # for file_name in files:\n",
    "    #     shutil.copy(file_name, os.path.join(data_dir.name, file_name))\n",
    "\n",
    "    # Save original directory\n",
    "    orig_dir = os.getcwd()\n",
    "\n",
    "    # Move to new directory\n",
    "    os.chdir(data_dir.name)\n",
    "\n",
    "# For info, print out where the script is running\n",
    "print(\"Running in {}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If Desired, set up CRDS to use a local cache\n",
    "\n",
    "By default, the notebook template environment sets up its CRDS cache (the \"CRDS_PATH\" environment variable) in /grp/crds/cache. However, if the notebook is running on a local machine without a fast and reliable connection to central storage, it makes more sense to put the CRDS cache locally. Currently, the cell below offers several options, and will check the supplied boolean variables one at a time until one matches.\n",
    "\n",
    "* if `use_local_crds_cache` is False, then the CRDS cache will be kept in /grp/crds/cache\n",
    "* if `use_local_crds_cache` is True, the CRDS cache will be kept locally\n",
    "  * if `crds_cache_tempdir` is True, the CRDS cache will be kept in the temporary directory\n",
    "  * if `crds_cache_notebook_dir` is True, the CRDS cache will be kept in the same directory as the notebook.\n",
    "  * if `crds_cache_home` is True, the CRDS cache will be kept in $HOME/crds/cache\n",
    "  * if `crds_cache_custom_dir` is True, the CRDS cache will be kept in whatever is stored in the \n",
    "    `crds_cache_dir_name` variable.\n",
    "\n",
    "If the above cell (creating a temporary directory) is not run, then setting `crds_cache_tempdir` to True will store the CRDS cache in the notebook's directory (the same as setting `crds_cache_notebook_dir` to True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "# Imports\n",
    "\n",
    "* os for interacting with the operating system\n",
    "* numpy for array handling\n",
    "* astropy.io for opening fits files\n",
    "* jwst.datamodels for building model for JWST Pipeline\n",
    "* jwst.pipeline to run Detector1, Image1 pipelines on test data\n",
    "* jwst.ami to run AmiAnalyzeStep, AmiAverageStep\n",
    "* matplotlib.pyplot.plt to generate plots\n",
    "* ci_watson.artifactory_helpers.get_bigdata for downloading test data\n",
    "* glob for pathname expansion\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from astropy.io import fits\n",
    "from jwst import datamodels\n",
    "from jwst.pipeline import Detector1Pipeline, Image2Pipeline\n",
    "from jwst.ami import AmiAnalyzeStep, AmiAverageStep\n",
    "import matplotlib.pyplot as plt\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_load\"></a>\n",
    "# Loading the Data\n",
    "\n",
    "Load the data from Artifactory (for internal use only)\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get uncalibrated data files\n",
    "datafiles = []\n",
    "file = get_bigdata('jwst_validation_notebooks',\n",
    "                'validation_data',\n",
    "                'ami_analyze',\n",
    "                'jw01093001001_01101_00006_nis_uncal.fits')\n",
    "datafiles.append(file)\n",
    "file = get_bigdata('jwst_validation_notebooks',\n",
    "                'validation_data',\n",
    "                'ami_analyze',\n",
    "                'jw01093001001_01101_00007_nis_uncal.fits')\n",
    "datafiles.append(file)\n",
    "\n",
    "# Get non-standard reference files and AMI3 config file\n",
    "superbiasfile = get_bigdata('jwst_validation_notebooks',\n",
    "                'validation_data',\n",
    "                'ami_analyze',\n",
    "                'jwst_niriss_superbias_sim.fits')\n",
    "darkfile = get_bigdata('jwst_validation_notebooks',\n",
    "                'validation_data',\n",
    "                'ami_analyze',\n",
    "                'jwst_niriss_dark_sub80_sim.fits')\n",
    "\n",
    "flatfieldfile = get_bigdata('jwst_validation_notebooks',\n",
    "                'validation_data',\n",
    "                'ami_analyze',\n",
    "                'jwst_niriss_flat_general.fits')\n",
    "ami_config = get_bigdata('jwst_validation_notebooks',\n",
    "                'validation_data',\n",
    "                'ami_analyze',\n",
    "                'ami_analyze.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Detector1, Image2, ami_analyze\n",
    "\n",
    "Start with `uncal.fits` files and run the Detector1 pipeline, skipping the IPC correction and overriding the dark and superbias reference files (necessary because of simulations generated without bad pixels).\n",
    "\n",
    "Then run the Image2 pipeline, skipping the photometry and resample steps, and using a non-default flat field reference file, to produce `cal.fits` products.\n",
    "\n",
    "Then run the AMI3 ami_analyze step on each `cal.fits` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify a keyword in each data file: only necessary for now\n",
    "for fn in datafiles:\n",
    "    with datamodels.open(fn) as model:\n",
    "        model.meta.dither.dither_points = int(model.meta.dither.dither_points)\n",
    "        model.save(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Detector1, Image 2 pipelines, run ami_analyze on cropped data\n",
    "odir = os.getcwd()\n",
    "print('All output files will be saved to %s' % odir)\n",
    "\n",
    "for df in datafiles:\n",
    "    result1 = Detector1Pipeline()\n",
    "    result1.superbias.override_superbias = superbiasfile\n",
    "    result1.dark_current.override_dark = darkfile\n",
    "    result1.ipc.skip = True\n",
    "    result1.save_results = True\n",
    "    result1.output_dir = odir\n",
    "    result1.run(df)\n",
    "            \n",
    "    df_rate = os.path.join(odir,os.path.basename(df.replace('uncal','rate')))\n",
    "    result2 = Image2Pipeline()        \n",
    "    result2.flat_field.override_flat = flatfieldfile\n",
    "    result2.photom.skip = True\n",
    "    result2.resample.skip = True\n",
    "    result2.save_results = True\n",
    "    result2.output_dir = odir\n",
    "    result2.run(df_rate)\n",
    "\n",
    "    df_rateints = os.path.join(odir,os.path.basename(df.replace('uncal','rateints')))\n",
    "    result3 = Image2Pipeline()\n",
    "    result3.flat_field.override_flat = flatfieldfile\n",
    "    result3.photom.skip = True\n",
    "    result3.resample.skip = True\n",
    "    result3.save_results = True\n",
    "    result3.output_dir = odir\n",
    "    result3.run(df_rateints)        \n",
    "    \n",
    "    df_cal = os.path.join(odir,os.path.basename(df.replace('uncal','cal')))\n",
    "    print(\"Generated calibrated files\", df_cal)  \n",
    "\n",
    "    #Run ami_analyze on _cal.fits files\n",
    "    result4 = AmiAnalyzeStep.call(df_cal, config_file='ami_analyze.cfg',output_dir=odir, save_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the ami_analyze file structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "infiles = glob.glob('*ami_analyze.fits')\n",
    "\n",
    "for file in infiles:\n",
    "    fits.info(file)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "# Run the AmiAverage Step\n",
    "\n",
    "Run the AMI3 AmiAverage step on the two 'ami_analyze.fits' files. First, create the base of the output filename from one of the input filenames (the output name will have 'amiaveragestep.fits' appended automatically)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = os.path.basename(infiles[0]).split('_ami_analyze', 1)[0]\n",
    "\n",
    "amiavg = AmiAverageStep.call(infiles, save_results=True, output_file=basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"testing\"></a>\n",
    "# Perform Tests or Visualization\n",
    "\n",
    "Perform the validation tests described previously. Generate plots, tables, diagnostics, etc. \n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the ami_average product\n",
    "\n",
    "We will only be using the averaged interferometric observables: closure phase, closure amplitude, fringe phase, and fringe amplitude, as well as the pupil phase and fringe coefficients ('SOLNS' extension). First, define a function to read in all the relevant extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_ami(fn):\n",
    "    with fits.open(fn) as hdu1:\n",
    "        CA = hdu1['CLOSURE_AMP'].data.astype(np.float64)\n",
    "        CP = hdu1['CLOSURE_PHA'].data.astype(np.float64)\n",
    "        FA = hdu1['FRINGE_AMP'].data.astype(np.float64)\n",
    "        FP = hdu1['FRINGE_PHA'].data.astype(np.float64)\n",
    "        PP = hdu1['PUPIL_PHA'].data.astype(np.float64)\n",
    "        soln = hdu1['SOLNS'].data.astype(np.float64)\n",
    "    return CA, CP, FA, FP, PP, soln"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amiavgfile = glob.glob('*amiaveragestep.fits')[0]\n",
    "\n",
    "CA_pipe, CP_pipe, FA_pipe, FP_pipe, PP_pipe, soln_pipe = read_ami(amiavgfile)\n",
    "\n",
    "\n",
    "print('%i Closure Phases' % len(CP_pipe))\n",
    "print('%i Closure Amplitudes' % len(CA_pipe))\n",
    "print('%i Fringe Phases' % len(FP_pipe))\n",
    "print('%i Fringe Amplitudes' % len(FA_pipe))\n",
    "print('%i Pupil Phases' % len(PP_pipe))\n",
    "print('%i Fringe Coeffs' % len(soln_pipe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually average observables from input files\n",
    "\n",
    "Load the observables from each file into lists, and take the mean of the observable arrays across the exposures, preserving the length of each array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CPs = []\n",
    "CAs = []\n",
    "FPs = []\n",
    "FAs = []\n",
    "PPs = []\n",
    "solns = []\n",
    "for fn in infiles:\n",
    "    CA, CP, FA, FP, PP, soln = read_ami(fn)\n",
    "    CAs.append(CA)\n",
    "    CPs.append(CP)\n",
    "    FAs.append(FA)\n",
    "    FPs.append(FP)\n",
    "    PPs.append(PP)\n",
    "    solns.append(soln)\n",
    "\n",
    "CP_man = np.mean(CPs, axis=0)\n",
    "CA_man = np.mean(CAs, axis=0)\n",
    "FP_man = np.mean(FPs, axis=0)\n",
    "FA_man = np.mean(FAs, axis=0)\n",
    "PP_man = np.mean(PPs, axis=0)\n",
    "soln_man = np.mean(solns, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the agreement\n",
    "\n",
    "Test if the pipeline-avergaed and manually-averaged observables are equal, to within a tolerance of $1\\times 10^{-6}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rtol=0.0 # relative tolerance\n",
    "atol=1e-6 # absolute tolerance\n",
    "print('\\n Closure phases:',np.allclose(CP_pipe,CP_man,rtol,atol),'\\n',\n",
    "     'Closure amplitudes:',np.allclose(CA_pipe,CA_man,rtol,atol),'\\n',\n",
    "     'Fringe phases:',np.allclose(FP_pipe,FP_man,rtol,atol),'\\n',\n",
    "     'Fringe amplitudes:',np.allclose(FA_pipe,FA_man,rtol,atol),'\\n',\n",
    "     'Pupil phases:',np.allclose(PP_pipe,PP_man,rtol,atol),'\\n',\n",
    "     'Fringe coefficients:',np.allclose(soln_pipe,soln_man,rtol,atol),'\\n',)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the difference\n",
    "Plot the two averaged sets of observables. If the observables were averaged correctly, the points should lie on top of each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_closure = np.arange(len(CP_pipe))\n",
    "n_fringe = np.arange(len(FP_pipe))\n",
    "n_pup = np.arange(len(PP_pipe))\n",
    "n_soln = np.arange(len(soln_pipe))\n",
    "\n",
    "fig, axs = plt.subplots(2,3, figsize=(15,8))\n",
    "axs[0][0].plot(n_closure,CP_pipe,'ro', alpha=.5, label='pipeline averaged')\n",
    "axs[0][0].plot(n_closure,CP_man,'bs', alpha=.5, label='manually averaged')\n",
    "axs[0][0].plot((n_closure,n_closure),(CP_pipe,CP_man),c='black',linewidth=.5)\n",
    "axs[0][0].set_title('Closure Phases')\n",
    "\n",
    "axs[0][1].plot(n_fringe,FP_pipe,'ro', alpha=.5)\n",
    "axs[0][1].plot(n_fringe,FP_man,'bs', alpha=.5)\n",
    "axs[0][1].plot((n_fringe,n_fringe),(FP_pipe,FP_man),c='black',linewidth=.5)\n",
    "axs[0][1].set_title('Fringe Phases')\n",
    "\n",
    "axs[0][2].plot(n_pup,PP_pipe,'ro', alpha=.5)\n",
    "axs[0][2].plot(n_pup,PP_man,'bs', alpha=.5)\n",
    "axs[0][2].plot((n_pup,n_pup),(PP_pipe,PP_man),c='black',linewidth=.5)\n",
    "axs[0][2].set_title('Pupil Phases')\n",
    "\n",
    "axs[1][0].plot(n_closure,CA_pipe,'ro', alpha=.5)\n",
    "axs[1][0].plot(n_closure,CA_man,'bs', alpha=.5)\n",
    "axs[1][0].plot((n_closure,n_closure),(CA_pipe,CA_man),c='black',linewidth=.5)\n",
    "axs[1][0].set_title('Closure Amplitudes')\n",
    "\n",
    "axs[1][1].plot(n_fringe,FA_pipe,'ro', alpha=.5)\n",
    "axs[1][1].plot(n_fringe,FA_man,'bs', alpha=.5)\n",
    "axs[1][1].plot((n_fringe,n_fringe),(FA_pipe,FA_man),c='black',linewidth=.5)\n",
    "axs[1][1].set_title('Fringe Amplitudes')\n",
    "\n",
    "axs[1][2].plot(n_soln,soln_pipe,'ro', alpha=.5)\n",
    "axs[1][2].plot(n_soln,soln_man,'bs', alpha=.5)\n",
    "axs[1][2].plot((n_soln,n_soln),(soln_pipe,soln_man),c='black',linewidth=.5)\n",
    "axs[1][2].set_title('Fringe Coefficients')\n",
    "\n",
    "fig.text(0.5, 0.04, 'Index', ha='center', va='center', size=14)\n",
    "fig.text(0.06, 0.5, 'Value', ha='center', va='center', rotation='vertical', size=14)\n",
    "fig.legend(loc=7)\n",
    "fig.subplots_adjust(right=0.85)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize the difference between the sets of averaged observables, if any:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2,3, figsize=(15,8))\n",
    "plt.suptitle('Pipeline-averaged minus manually-averaged observables', size=14)\n",
    "axs[0][0].plot(n_closure,CP_pipe - CP_man)\n",
    "axs[0][0].set_title('Closure Phases')\n",
    "\n",
    "axs[0][1].plot(n_fringe,FP_pipe - FP_man)\n",
    "axs[0][1].set_title('Fringe Phases')\n",
    "\n",
    "axs[0][2].plot(n_pup,PP_pipe - PP_man)\n",
    "axs[0][2].set_title('Pupil Phases')\n",
    "\n",
    "axs[1][0].plot(n_closure,CA_pipe - CA_man)\n",
    "axs[1][0].set_title('Closure Amplitudes')\n",
    "\n",
    "axs[1][1].plot(n_fringe,FA_pipe - FA_man)\n",
    "axs[1][1].set_title('Fringe Amplitudes')\n",
    "\n",
    "axs[1][2].plot(n_soln,soln_pipe - soln_man)\n",
    "axs[1][2].set_title('Fringe Coefficients')\n",
    "\n",
    "fig.text(0.5, 0.04, 'Index', ha='center', va='center', size=12)\n",
    "fig.text(0.06, 0.5, 'Difference', ha='center', va='center', rotation='vertical', size=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** Rachel Cooper, Science Support Analyst, ISSB/NIRISS\n",
    "<br>**Updated On:** 07/19/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
