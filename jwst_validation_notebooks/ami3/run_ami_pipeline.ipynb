{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Notebook:  AMI3, AMI3 Pipeline\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: NIRISS\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "<div style=\"text-align: left\"> \n",
    "    \n",
    "<br> [Introduction](#intro)\n",
    "<br> [JWST CalWG Algorithm](#algorithm)\n",
    "<br> [Defining Terms](#terms)\n",
    "<br> [Test Description](#description)\n",
    "<br> [Data Description](#data_descr)\n",
    "<br> [Set up Temporary Directory](#tempdir)\n",
    "<br> [Imports](#imports)\n",
    "<br> [Loading the Data](#data_load)\n",
    "<br> [Run the Pipeline](#pipeline)\n",
    "<br> [Test Results](#testing)\n",
    "<br> [About This Notebook](#about)  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Introduction\n",
    "\n",
    "The notebook verifies that pipeline steps from `calwebb_detector1` through `calwebb_image2` and `calwebb_ami3` run without crashing. `calwebb_ami3` is run on various associations of target and calibrator pairs.\n",
    "\n",
    "For more information on the `calwebb_ami3` pipeline stage visit the links below. \n",
    "\n",
    "> Stage description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_ami3.html\n",
    ">\n",
    "> Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/ami\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"algorithm\"></a>\n",
    "# JWST CalWG Algorithm\n",
    "\n",
    "`calwebb_ami3` is based on the `implaneia` algorithm:\n",
    "> https://github.com/anand0xff/ImPlaneIA/tree/delivery\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"terms\"></a>\n",
    "# Defining Terms\n",
    "\n",
    "Calibrator: reference star to measure PSF to calibrate out instrumental contributions to the interferometric observables \n",
    "\n",
    "PSF: point spread function\n",
    "\n",
    "Target: source of interest for science program \n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"description\"></a>\n",
    "# Test Description\n",
    "\n",
    "This test checks that simulated data runs through the `calwebb_detector1`, `calwebb_image2`, and `calwebb_ami3` steps of the pipeline without crashing. Association files are created for the target/calibrator pair at different dither positions. The notebook verifies that the `calwebb_ami3` runs on these association files.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_descr\"></a>\n",
    "# Data Description\n",
    "\n",
    "The data for this test are simulated AMI datasets that do not have bad pixels. The simulated source data is AB Dor, which is simulated with a 4-point dither pattern:\n",
    "\n",
    "| Source         | Filename| Dither Position |\n",
    "|:----------------|:---------|:-----------------|\n",
    "|AB Dor (Target) |jw01093001001_01101_00005_nis_uncal.fits| 1|\n",
    "| |jw01093001001_01101_00006_nis_uncal.fits| 2 |\n",
    "| |jw01093001001_01101_00007_nis_uncal.fits| 3 |\n",
    "| |jw01093001001_01101_00005_nis_uncal.fits| 4 |\n",
    "\n",
    "HD 37093 is the PSF reference star, which is also simulated with a 4-point dither pattern.\n",
    "\n",
    "| Source         | Filename| Dither Position |\n",
    "|:----------------|:---------|:-----------------|\n",
    "|HD 37093 (Calibrator)| jw01093002001_01101_00005_nis_uncal.fits | 1 |\n",
    "| |jw01093002001_01101_00006_nis_uncal.fits | 2 |\n",
    "| |jw01093002001_01101_00007_nis_uncal.fits | 3 |\n",
    "| |jw01093002001_01101_00005_nis_uncal.fits | 4 |\n",
    "\n",
    "Configuration files are also needed for the various `calwebb_ami3` steps:\n",
    "- ami_analyze.cfg\n",
    "- ami_normalize.cfg\n",
    "- ami_average.cfg\n",
    "- calwebb_ami3.cfig\n",
    "\n",
    "Specific reference files are needed for the analysis, which also do not have bad pixels, and are loaded with this notebook.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tempdir\"></a>\n",
    "# Set up Temporary Directory\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_tempdir = True\n",
    "\n",
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if use_tempdir:\n",
    "    data_dir = TemporaryDirectory()\n",
    "\n",
    "    # Save original directory\n",
    "    orig_dir = os.getcwd()\n",
    "\n",
    "    # Move to new directory\n",
    "    odir = data_dir.name\n",
    "    os.chdir(data_dir.name)\n",
    "\n",
    "# For info, print out where the script is running\n",
    "print(\"Running in {}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "# Imports\n",
    "List the package imports and why they are relevant to this notebook.\n",
    "\n",
    "* astropy.io for opening fits files\n",
    "* numpy for working with arrays\n",
    "* IPython.display for printing markdown output\n",
    "* jwst.datamodels for building model for JWST Pipeline\n",
    "* jwst.pipeline.collect_pipeline_cfgs for gathering configuration files\n",
    "* jwst.pipeline for initiating various pipeline stages\n",
    "* jwst.ami to call the AMI Analyze step\n",
    "* jwst.associations for using association files\n",
    "* from ci_watson.artifactory_helpers import get_bigdata for reading data from Artifactory\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "import numpy as np\n",
    "from IPython.display import Markdown\n",
    "from jwst.datamodels import ImageModel\n",
    "import jwst.datamodels as datamodels\n",
    "\n",
    "from jwst.pipeline.collect_pipeline_cfgs import collect_pipeline_cfgs\n",
    "from jwst.pipeline import Detector1Pipeline, Image2Pipeline, Image3Pipeline, Ami3Pipeline \n",
    "from jwst.ami import AmiAnalyzeStep  \n",
    "from jwst.associations import asn_from_list\n",
    "from jwst.associations.lib.rules_level3_base import DMS_Level3_Base\n",
    "\n",
    "from ci_watson.artifactory_helpers import get_bigdata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_load\"></a>\n",
    "# Loading the Data\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data files that will be imported by Artifactory:\n",
    "datafiles = np.array(['jw01093001001_01101_00005_nis_uncal.fits',\n",
    "                      'jw01093001001_01101_00006_nis_uncal.fits',\n",
    "                      'jw01093001001_01101_00007_nis_uncal.fits',\n",
    "                      'jw01093001001_01101_00008_nis_uncal.fits',\n",
    "                      'jw01093002001_01101_00005_nis_uncal.fits',\n",
    "                      'jw01093002001_01101_00006_nis_uncal.fits',\n",
    "                      'jw01093002001_01101_00007_nis_uncal.fits',\n",
    "                      'jw01093002001_01101_00008_nis_uncal.fits'])\n",
    "\n",
    "# Read in reference files needed for this analysis (these don't have bad pixels, like simulations)\n",
    "superbiasfile = get_bigdata('jwst_validation_notebooks',\n",
    "                            'validation_data',\n",
    "                            'ami_analyze',\n",
    "                            'jwst_niriss_superbias_sim.fits')\n",
    "darkfile = get_bigdata('jwst_validation_notebooks',\n",
    "                       'validation_data',\n",
    "                       'ami_analyze',\n",
    "                       'jwst_niriss_dark_sub80_sim.fits')\n",
    "flatfile = get_bigdata('jwst_validation_notebooks',\n",
    "                       'validation_data',\n",
    "                       'ami_analyze', \n",
    "                       'jwst_niriss_flat_general.fits')\n",
    "\n",
    "# Read in configuration files\n",
    "ami_analyze_cfg = get_bigdata('jwst_validation_notebooks',\n",
    "                              'validation_data',\n",
    "                              'ami_analyze',\n",
    "                              'ami_analyze.cfg')\n",
    "ami_normalize_cfg = get_bigdata('jwst_validation_notebooks',\n",
    "                                'validation_data',\n",
    "                                'ami_analyze',\n",
    "                                'ami_normalize.cfg')\n",
    "ami_average_cfg = get_bigdata('jwst_validation_notebooks',\n",
    "                              'validation_data',\n",
    "                              'ami_analyze',\n",
    "                              'ami_average.cfg')\n",
    "calwebb_ami3_cfg = get_bigdata('jwst_validation_notebooks',\n",
    "                                'validation_data',\n",
    "                                'ami_analyze',\n",
    "                                'calwebb_ami3.cfg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "# Run the Pipeline\n",
    "\n",
    "Since this notebook tests whether the pipeline runs on all the datasets, we will run each stage of the pipeline in separate cells. That way, if a step fails, it will be easier to track down at what stage and step this error occurred.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Detector1 stage of the pipeline to calibrate \\*\\_uncal.fits file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for file in datafiles:\n",
    "\n",
    "    df = get_bigdata('jwst_validation_notebooks',\n",
    "                     'validation_data',\n",
    "                     'ami_analyze',\n",
    "                     file)\n",
    "    \n",
    "    # Modify a keyword in each data file: only necessary for now\n",
    "    # Next three lines are temporary to accommodate recent changes to Mirage and pipeline\n",
    "    # and for Mirage to work with the pipeline.\n",
    "    with datamodels.open(df) as model:\n",
    "        model.meta.dither.dither_points = int(model.meta.dither.dither_points)\n",
    "        model.save(df)\n",
    "\n",
    "    # Run Detector1 stage of pipeline, specifying superbias and dark reference files\n",
    "    result1 = Detector1Pipeline()\n",
    "    result1.superbias.override_superbias = superbiasfile\n",
    "    result1.dark_current.override_dark = darkfile\n",
    "    result1.ipc.skip = True\n",
    "    result1.save_results = True\n",
    "    result1.output_dir = odir\n",
    "    result1.run(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Image2 stage of the pipeline to calibrate \\*\\_rate.fits file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in datafiles:\n",
    "\n",
    "    # Run Image2 stage of the pipeline on the file created above to create rate file,\n",
    "    # specifying flat field file\n",
    "    df_rate = os.path.join(odir, os.path.basename(df.replace('uncal','rate')))\n",
    "    result2 = Image2Pipeline()        \n",
    "    result2.flat_field.override_flat = flatfile\n",
    "    result2.photom.skip = True\n",
    "    result2.resample.skip = True\n",
    "    result2.save_results = True\n",
    "    result2.output_dir = odir\n",
    "    result2.run(df_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Image2 stage of the pipeline to calibrate \\*\\_rateints.fits file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in datafiles:\n",
    "\n",
    "    # Run Image stage of the pipeline to create rateints file, specifying flat field file\n",
    "    df_rateints = os.path.join(odir,os.path.basename(df.replace('uncal','rateints')))\n",
    "    result3 = Image2Pipeline()\n",
    "    result3.flat_field.override_flat = flatfile\n",
    "    result3.photom.skip = True\n",
    "    result3.resample.skip = True\n",
    "    result3.save_results = True\n",
    "    result3.output_dir = odir\n",
    "    result3.run(df_rateints)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run AmiAnalyze step on the \\*\\_cal.fits files created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in datafiles:\n",
    "\n",
    "    # Set up name of calibrated file\n",
    "    df_cal = os.path.join(odir,os.path.basename(df.replace('uncal','cal')))\n",
    "    \n",
    "    # Run AMI Analyze Step of the pipeline\n",
    "    result5 = AmiAnalyzeStep.call(df_cal, config_file = ami_analyze_cfg,\n",
    "                                  output_dir = odir, save_results = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run AmiAnalyze on various target/calibrator pairs\n",
    "\n",
    "Create association files to test calibration of target at different dither positions. Run AmiAnalyze on these association files. \n",
    "\n",
    "Note: the `program` and `targ_name` fields in the association files are the same for all pairs, so I have them set as default values in the `create_asn` routine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Routine for creating association files (in \\*.json format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_asn(outdir, targ1, psf1, prod_name, out_file, asn_id, \n",
    "               program=\"1093_2_targets_f480m_2022.25coords_pipetesting\", \n",
    "               targ_name='t001',\n",
    "               targ2=None, psf2=None):\n",
    "    \n",
    "    # Create association file:\n",
    "    asn = asn_from_list.asn_from_list([os.path.join(outdir,targ1)],\n",
    "                                       product_name = prod_name,\n",
    "                                       output_file = os.path.join(outdir,out_file),\n",
    "                                       output_dir = outdir,rule = DMS_Level3_Base)\n",
    "    \n",
    "    asn['products'][0]['members'].append({'expname': os.path.join(odir,psf1),\n",
    "                                          'exptype': 'psf'})\n",
    "    \n",
    "    # check whether 2nd set of target/calibrator pairs was inputted\n",
    "    if targ2 is not None:   \n",
    "        asn['products'][0]['members'].append({'expname':os.path.join(odir,targ2), \n",
    "                                              'exptype': 'science'})\n",
    "        asn['products'][0]['members'].append({'expname':os.path.join(odir,psf2), \n",
    "                                              'exptype': 'psf'})\n",
    "\n",
    "\n",
    "\n",
    "    asn['asn_type'] = 'ami3'\n",
    "    asn['asn_id'] = asn_id\n",
    "    asn['program'] = program\n",
    "    asn['target'] = targ_name\n",
    "    \n",
    "    with open(os.path.join(outdir,out_file), 'w') as fp:\n",
    "        fp.write(asn.dump()[1])\n",
    "        fp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create association files and run AmiAnalyze on these pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association file 1 to calibrate average of targets at dithers 2 and 3 with the average of calibrators at dithers 2 and 3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asn1_file = \"ami_asn001_targets23_cals23.json\"\n",
    "\n",
    "targ1 = \"jw01093001001_01101_00006_nis_cal.fits\"\n",
    "psf1 = \"jw01093002001_01101_00006_nis_cal.fits\"\n",
    "prod_name = \"jw01093001001_01101\"\n",
    "asn_id = '001'\n",
    "\n",
    "# Add second target/calibrator pair at this dither step\n",
    "targ2 = \"jw01093001001_01101_00007_nis_cal.fits\"\n",
    "psf2 = \"jw01093002001_01101_00007_nis_cal.fits\"\n",
    "\n",
    "create_asn(odir, targ1, psf1, prod_name, asn1_file, asn_id, targ2=targ2, psf2=psf2)\n",
    "\n",
    "# Run AmiAnalyze\n",
    "Ami3Pipeline.call(asn1_file,config_file = calwebb_ami3_cfg,output_dir = odir)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association file 2 to calibrate target at POS1 with calibrator at POS1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create association file:\n",
    "asn2_file = \"ami_asn002_calibrate_targ1_cal1.json\"\n",
    "\n",
    "targ1 = \"jw01093001001_01101_00005_nis_cal.fits\"\n",
    "psf1 = 'jw01093002001_01101_00005_nis_cal.fits'\n",
    "prod_name = \"jw01093001001_01101_00005cal00005\"\n",
    "asn_id = '002'\n",
    "\n",
    "create_asn(odir, targ1, psf1,prod_name, asn2_file, asn_id)\n",
    "\n",
    "# Run AmiAnalyze\n",
    "Ami3Pipeline.call(asn2_file,config_file = calwebb_ami3_cfg,output_dir = odir)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association file 3 to calibrate target at POS2 with calibrator at POS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create association file:\n",
    "asn3_file = \"ami_asn003_calibrate_targ2_cal2.json\"\n",
    "\n",
    "targ1 = \"jw01093001001_01101_00006_nis_cal.fits\"\n",
    "psf1 = \"jw01093002001_01101_00006_nis_cal.fits\"\n",
    "prod_name = \"jw01093001001_01101_00006cal00006\"\n",
    "asn_id = '003'\n",
    "\n",
    "create_asn(odir, targ1, psf1, prod_name, asn3_file, asn_id)\n",
    "\n",
    "# Run AmiAnalyze\n",
    "Ami3Pipeline.call(asn3_file,config_file = calwebb_ami3_cfg,output_dir = odir)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association file 4 to calibrate target at POS3 with calibrator at POS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create association file:\n",
    "asn4_file = \"ami_asn004_calibrate_targ3_cal3.json\"\n",
    "\n",
    "targ1 = \"jw01093001001_01101_00007_nis_cal.fits\"\n",
    "psf1 = \"jw01093002001_01101_00007_nis_cal.fits\"\n",
    "prod_name = \"jw01093001001_01101_00007cal00007\"\n",
    "asn_id = '004'\n",
    "\n",
    "create_asn(odir, targ1, psf1, prod_name, asn4_file, asn_id)\n",
    "\n",
    "# Run AmiAnalyze\n",
    "Ami3Pipeline.call(asn3_file,config_file = calwebb_ami3_cfg,output_dir = odir)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association file 5 to calibrate target at POS4 with calibrator at POS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create association file:\n",
    "asn5_file = \"ami_asn005_calibrate_targ4_cal4.json\"\n",
    "\n",
    "targ1 = \"jw01093001001_01101_00008_nis_cal.fits\"\n",
    "psf1 = \"jw01093002001_01101_00008_nis_cal.fits\"\n",
    "prod_name = \"jw01093001001_01101_00008cal00008\"\n",
    "asn_id = '005'\n",
    "\n",
    "create_asn(odir, targ1, psf1, prod_name, asn5_file, asn_id)\n",
    "\n",
    "# Run AmiAnalyze\n",
    "Ami3Pipeline.call(asn3_file,config_file = calwebb_ami3_cfg,output_dir = odir)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association file 6 to calibrate calibrator at POS2 with calibrator at POS3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create association file:\n",
    "asn6_file = \"ami_asn006_calibrate_cal2_cal3.json\"\n",
    "\n",
    "targ1 = \"jw01093002001_01101_00006_nis_cal.fits\"\n",
    "psf1 = \"jw01093002001_01101_00007_nis_cal.fits\"\n",
    "prod_name = \"jw01093002001_01101_00006cal00007\"\n",
    "asn_id = '006'\n",
    "\n",
    "create_asn(odir, targ1, psf1, prod_name, asn6_file, asn_id, targ_name='t002')\n",
    "\n",
    "# Run AmiAnalyze\n",
    "Ami3Pipeline.call(asn3_file,config_file = calwebb_ami3_cfg,output_dir = odir)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Association file 7 to calibrate calibrator at POS3 with calibrator at POS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create association file:\n",
    "asn7_file = \"ami_asn007_calibrate_cal3_cal2.json\"\n",
    "\n",
    "targ1 = \"jw01093002001_01101_00007_nis_cal.fits\"\n",
    "psf1 = \"jw01093002001_01101_00006_nis_cal.fits\"\n",
    "prod_name = \"jw01093002001_01101_00007cal00006\"\n",
    "asn_id = '007'\n",
    "\n",
    "create_asn(odir, targ1, psf1, prod_name, asn7_file, asn_id, targ_name='t002')\n",
    "\n",
    "# Run AmiAnalyze\n",
    "Ami3Pipeline.call(asn3_file,config_file = calwebb_ami3_cfg,output_dir = odir)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"testing\"></a>\n",
    "# Test Results\n",
    "\n",
    "Did the above cells run without errors? If so, **huzzah** the test passed! \n",
    "\n",
    "If not, track down why the pipeline failed to run on these datasets.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Authors:** Deepashri Thatte, Senior Staff Scientist, NIRISS\n",
    "<br>Stephanie LaMassa, Scientist, NIRISS\n",
    "<br>**Updated On:** 08/04/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
