{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Notebook: calwebb_image2, background subtraction for MIRI imaging with flight data\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: e.g., FGS, MIRI, NIRCam, NIRISS \n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "\n",
    "<div style=\"text-align: left\"> \n",
    "    \n",
    "<br> [Introduction\\*](#intro)\n",
    "<br> [JWST CalWG Algorithm\\*](#algorithm)\n",
    "<br> [Defining Terms](#terms)\n",
    "<br> [Test Description\\*](#description)\n",
    "<br> [Data Description\\*](#data_descr)\n",
    "<br> [Imports\\*](#imports)\n",
    "<br> [Loading the Data\\*](#data_load)\n",
    "<br> [Run the Pipeline](#pipeline)\n",
    "<br> [Passing criteria](#testing) \n",
    "<br> [About This Notebook\\*](#about)\n",
    "<br>    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Introduction\n",
    "\n",
    "\n",
    "This is the validation notebook for the background subtraction step as part of calwebb_image2. This step takes in a set of images and a set of background observations. If more than one background observation is given, they are combined into a sigma clipped mean before being subtracted from each of the science data images. For more information on the pipeline step visit the links below. \n",
    "\n",
    "Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/background_step/description.html\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/background\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"algorithm\"></a>\n",
    "# JWST CalWG Algorithm\n",
    "\n",
    "The page describing the algorithm and any details can be found here:\n",
    "\n",
    "https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Imaging+Background+Subtraction\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"terms\"></a>\n",
    "# Defining Terms\n",
    "\n",
    "Here are some common terms that will be used throughout the notebook\n",
    "\n",
    "> JWST: James Webb Space Telescope\n",
    "\n",
    "> MIRI: Mid-Infrared Instrument\n",
    "\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"description\"></a>\n",
    "# Test Description\n",
    "\n",
    "This test is performed by using a set of data with multiple bright point sources and dust located around SN 2021axdf . There is a set of 4 images at four dithered positions in the F2550W filter. This test also takes in a set of four background images, at four dithered positions, with the same filter. All images will be processed through calwebb_detector1, and put into an association file to be run through calwebb_image2. This will tell the background step which are the science observations and which are the background observations so that it will do a sigma clipped mean of the background exposures, then subtract the mean background image from each of the science observations.\n",
    "\n",
    "The notebook shows the images (background, science, averaged background, and background subtracted) through the course of the notebook to demonstrate how well the algorithm works. The notebook then takes the rate images through calwebb_image2 and calwebb_image3 in order to look at the combined F2550W image that includes all four dithered positions and the background subtraction in image2.\n",
    "\n",
    "For observations with the F2550W filter, it is recommended that background observations also be taken, in order to subtract off the high background that is seen with this filter. This notebook tests that subtraction to ensure that the user can get reasonable data for this filter after the background subtraction.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_descr\"></a>\n",
    "# Data Description\n",
    "\n",
    "\n",
    "The set of data used in this particular test were taken with the F2550W filter of SN 2021axdf. There is a set of 4 science images at four dithered positions. This test also takes in a set of four background images, at four dithered positions, in the same filter. They were taken as part of Proposal 2754 - Unique Constraints on Early Dust Growth in Core-Collapse Supernovae. This is a DD proposal to study dust constraints for CCSNe before 500 days post-explosion.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tempdir\"></a>\n",
    "# Set up Temporary Directory\n",
    "The following cell sets up a temporary directory (using python's `tempfile.TemporaryDirectory()`), and changes the script's active directory into that directory (using python's `os.chdir()`). This is so that, when the notebook is run through, it will download files to (and create output files in) the temporary directory rather than in the notebook's directory. This makes cleanup significantly easier (since all output files are deleted when the notebook is shut down), and also means that different notebooks in the same directory won't interfere with each other when run by the automated webpage generation process.\n",
    "\n",
    "If you want the notebook to generate output in the notebook's directory, simply don't run this cell.\n",
    "\n",
    "If you have a file (or files) that are kept in the notebook's directory, and that the notebook needs to use while running, you can copy that file into the directory (the code to do so is present below, but commented out).\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****\n",
    "#\n",
    "# Set this variable to False to not use the temporary directory\n",
    "#\n",
    "#****\n",
    "use_tempdir = True\n",
    "\n",
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if use_tempdir:\n",
    "    data_dir = TemporaryDirectory()\n",
    "\n",
    "    # Save original directory\n",
    "    orig_dir = os.getcwd()\n",
    "\n",
    "    # Move to new directory\n",
    "    os.chdir(data_dir.name)\n",
    "\n",
    "# For info, print out where the script is running\n",
    "print(\"Running in {}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If Desired, set up CRDS to use a local cache\n",
    "\n",
    "By default, the notebook template environment sets up its CRDS cache (the \"CRDS_PATH\" environment variable) in /grp/crds/cache. However, if the notebook is running on a local machine without a fast and reliable connection to central storage, it makes more sense to put the CRDS cache locally. Currently, the cell below offers several options, and will check the supplied boolean variables one at a time until one matches.\n",
    "\n",
    "* if `use_local_crds_cache` is False, then the CRDS cache will be kept in /grp/crds/cache\n",
    "* if `use_local_crds_cache` is True, the CRDS cache will be kept locally\n",
    "  * if `crds_cache_tempdir` is True, the CRDS cache will be kept in the temporary directory\n",
    "  * if `crds_cache_notebook_dir` is True, the CRDS cache will be kept in the same directory as the notebook.\n",
    "  * if `crds_cache_home` is True, the CRDS cache will be kept in $HOME/crds/cache\n",
    "  * if `crds_cache_custom_dir` is True, the CRDS cache will be kept in whatever is stored in the \n",
    "    `crds_cache_dir_name` variable.\n",
    "\n",
    "If the above cell (creating a temporary directory) is not run, then setting `crds_cache_tempdir` to True will store the CRDS cache in the notebook's directory (the same as setting `crds_cache_notebook_dir` to True)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Choose CRDS cache location\n",
    "use_local_crds_cache = True\n",
    "crds_cache_tempdir = False\n",
    "crds_cache_notebook_dir = False\n",
    "crds_cache_home = False\n",
    "crds_cache_custom_dir = False\n",
    "crds_cache_dir_name = \"\"\n",
    "\n",
    "if use_local_crds_cache:\n",
    "    if crds_cache_tempdir:\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.getcwd(), \"crds\")\n",
    "    elif crds_cache_notebook_dir:\n",
    "        try:\n",
    "            os.environ['CRDS_PATH'] = os.path.join(orig_dir, \"crds\")\n",
    "        except Exception as e:\n",
    "            os.environ['CRDS_PATH'] = os.path.join(os.getcwd(), \"crds\")\n",
    "    elif crds_cache_home:\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif crds_cache_custom_dir:\n",
    "        os.environ['CRDS_PATH'] = crds_cache_dir_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "# Imports\n",
    "List the package imports and why they are relevant to this notebook.\n",
    "\n",
    "\n",
    "* astropy.io for opening fits files\n",
    "* inspect to get the docstring of our objects.\n",
    "* IPython.display for printing markdown output\n",
    "* jwst.datamodels for building model for JWST Pipeline\n",
    "* jwst.module.PipelineStep is the pipeline step being tested\n",
    "* matplotlib.pyplot.plt to generate plot\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from astropy.io import fits\n",
    "import glob\n",
    "\n",
    "from jwst.datamodels import RampModel, ImageModel\n",
    "from jwst.pipeline import Detector1Pipeline, Image2Pipeline, calwebb_image3\n",
    "from jwst import associations\n",
    "from jwst.associations.lib.rules_level2_base import DMSLevel2bBase, DMS_Level3_Base\n",
    "from jwst.associations import asn_from_list\n",
    "from jwst.background import BackgroundStep\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_load\"></a>\n",
    "# Loading the Data\n",
    "\n",
    "Download data from  Artifactory or Box to use in the notebook.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at rate images\n",
    "\n",
    "Display the rate science images and background images to see locations of sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.utils.data import download_file\n",
    "from pathlib import Path\n",
    "from shutil import move\n",
    "from os.path import splitext\n",
    "\n",
    "def get_box_files(file_list):\n",
    "    for box_url,file_name in file_list:\n",
    "        if 'https' not in box_url:\n",
    "            box_url = 'https://stsci.box.com/shared/static/' + box_url\n",
    "        downloaded_file = download_file(box_url)\n",
    "        if Path(file_name).suffix == '':\n",
    "            ext = splitext(box_url)[1]\n",
    "            file_name += ext\n",
    "        move(downloaded_file, file_name)\n",
    "\n",
    "\n",
    "file_urls = ['https://stsci.box.com/shared/static/j2f1klymtj8yfy3ryqsficy2js4q68xc.fits', \n",
    "             'https://stsci.box.com/shared/static/64xsicjfdqnp2y70htwkqfpbp6hn664r.fits',\n",
    "             'https://stsci.box.com/shared/static/hnmt7i6qomluigg6gxwlf4zvifg98uno.fits',\n",
    "             'https://stsci.box.com/shared/static/5m6n24qjv2xzyn87dxufwuidful0f805.fits',\n",
    "             'https://stsci.box.com/shared/static/4x1z2t0ji9je2o5qvisojl3m3nqi8vnl.fits',\n",
    "             'https://stsci.box.com/shared/static/p5co8n3pjjq7ecv45klaekkryoii3gcv.fits',\n",
    "             'https://stsci.box.com/shared/static/0czufensqnvz1m05o4jknt9dh7pv6g3t.fits',\n",
    "             'https://stsci.box.com/shared/static/z00chmebwzw8us8e7q0un4sj6y1yy5p3.fits']\n",
    "             \n",
    "\n",
    "files = ['jw02754001001_06101_00001_mirimage_rate.fits', \n",
    "         'jw02754001001_06101_00002_mirimage_rate.fits', \n",
    "         'jw02754001001_06101_00003_mirimage_rate.fits',\n",
    "         'jw02754001001_06101_00004_mirimage_rate.fits',\n",
    "         'jw02754002001_02101_00001_mirimage_rate.fits',\n",
    "         'jw02754002001_02101_00002_mirimage_rate.fits',\n",
    "         'jw02754002001_02101_00003_mirimage_rate.fits',\n",
    "         'jw02754002001_02101_00004_mirimage_rate.fits']\n",
    "         \n",
    "\n",
    "box_download_list = [(url,name) for url,name in zip(file_urls,files)]\n",
    "\n",
    "\n",
    "get_box_files(box_download_list)\n",
    "\n",
    "\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scislopelist = ['jw02754001001_06101_00001_mirimage_rate.fits', \n",
    "         'jw02754001001_06101_00002_mirimage_rate.fits', \n",
    "         'jw02754001001_06101_00003_mirimage_rate.fits',\n",
    "         'jw02754001001_06101_00004_mirimage_rate.fits']\n",
    "\n",
    "bkgslopelist = ['jw02754002001_02101_00001_mirimage_rate.fits',\n",
    "         'jw02754002001_02101_00002_mirimage_rate.fits',\n",
    "         'jw02754002001_02101_00003_mirimage_rate.fits',\n",
    "         'jw02754002001_02101_00004_mirimage_rate.fits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at science images\n",
    "\n",
    "for image in scislopelist:\n",
    "    im = ImageModel(image)\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(im.data, cmap='rainbow', origin='lower', vmin=800,vmax=1200)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    print('background region values', im.data[600, 600])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at background images\n",
    "# Pixel to examine that should have a source in at least one background image\n",
    "xval = 850\n",
    "yval = 875\n",
    "\n",
    "for backimage in bkgslopelist:\n",
    "    bkgim = ImageModel(backimage)\n",
    "    print(bkgim.meta.filename)\n",
    "    selectedstar = bkgim.data[yval, xval] # Choose a pixel that is on a source in at least one image\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(bkgim.data, cmap='rainbow', origin='lower', vmin=800,vmax=1200)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    print('brightness of selected pixel', selectedstar, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a Level2 association file of the science and background exposures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an association file of all of the rate files\n",
    "\n",
    "#asn_files = [scislopelist[0].meta.filename, scislopelist[1].meta.filename, scislopelist[2].meta.filename,\n",
    "#            scislopelist[3].meta.filename]\n",
    "#bgr_files = [bkgslopelist[0].meta.filename, bkgslopelist[1].meta.filename, bkgslopelist[2].meta.filename,\n",
    "#            bkgslopelist[3].meta.filename]\n",
    "asn_files = scislopelist\n",
    "bgr_files = bkgslopelist\n",
    "\n",
    "asn = asn_from_list.asn_from_list(asn_files, rule=DMSLevel2bBase, meta={'program':'test', 'target':'randomfield', 'asn_pool':'test'})\n",
    "\n",
    "# now add the opposite nod as background exposure:\n",
    "for product in asn['products']:\n",
    "    product['members'].append({'expname':bgr_files[0], 'exptype':'background'})\n",
    "    product['members'].append({'expname':bgr_files[1], 'exptype':'background'})\n",
    "    product['members'].append({'expname':bgr_files[2], 'exptype':'background'})\n",
    "    product['members'].append({'expname':bgr_files[3], 'exptype':'background'})\n",
    "    \n",
    "# write this out to a json file\n",
    "with open('imager_bkgsubtest_asn.json', 'w') as fp:\n",
    "    fp.write(asn.dump()[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run association file through background subtraction step of calwebb_image2\n",
    "\n",
    "The default value of sigma for the background subtract step is set to 3, but may need to be adjusted downward to 2 or 1 in order to actually sigma clip the sources in the images. Test this for your data. For this particular data set, 2 is sufficient, but for brighter sources, 1 may be the best option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Image2Pipeline()\n",
    "# Set pipeline parameters\n",
    "pipe2.save_results = True\n",
    "pipe2.bkg_subtract.sigma = 2  # Set this in order to catch the outliers and leave only background\n",
    "pipe2.bkg_subtract.maxiters = 3\n",
    "pipe2.bkg_subtract.save_combined_background = True \n",
    "\n",
    "pipe2.assign_wcs.skip = True\n",
    "pipe2.flat_field.skip = True\n",
    "pipe2.photom.skip = True\n",
    "pipe2.resample.skip = True\n",
    "pipe2.save_bsub = True\n",
    "\n",
    "\n",
    "pipe2.run('imager_bkgsubtest_asn.json')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at averaged background image\n",
    "\n",
    "See how well the sigma clipping did at removing the sources from the background image. If the sources in the background image are bright, the value of sigma should be set to 1. If the sources are faint enough, the default value of 3 should be good enough. \n",
    "\n",
    "Also look at the value of a specific pixel in the averaged image, one that has a source in at least one of the background images, to see if the flux was adequately removed in the sigma clipping process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can only be uncommented in builds after 7.7.1\n",
    "averaged_backgrounds = glob.glob('*combinedbackground.fits')\n",
    "print(averaged_backgrounds)\n",
    "\n",
    "avgbkg = ImageModel(averaged_backgrounds[0])\n",
    "selectedavgstar = avgbkg.data[yval, xval]  # Choose a pixel location that contains a source in at least one background image\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.imshow(avgbkg.data, cmap='rainbow', origin='lower', vmin=800,vmax=1200)\n",
    "plt.colorbar()\n",
    "plt.show()\n",
    "\n",
    "print('brightness of selected pixel', selectedavgstar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the values of pixels in the background images at the location of one of the stars to see whether the star flux is being rejected as part of the sigma clipping. In calwebb_image2, the sigma value was set to 2, which is lower than the default value of 3. This allows the most pixels to be rejected as outliers, and should leave only the background values in the final averaged image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check averaging of background images\n",
    "\n",
    "print(bkgslopelist,'\\n')\n",
    "im1 = ImageModel(bkgslopelist[0])\n",
    "im2 = ImageModel(bkgslopelist[1])\n",
    "im3 = ImageModel(bkgslopelist[2])\n",
    "im4 = ImageModel(bkgslopelist[3])\n",
    "\n",
    "print('Value in image1 ', im1.data[yval, xval])\n",
    "print('Value in image2 ', im2.data[yval, xval])\n",
    "print('Value in image3 ', im3.data[yval, xval])\n",
    "print('Value in image4 ', im4.data[yval, xval],'\\n')\n",
    "\n",
    "avgvalue = (im1.data[yval, xval]+ im2.data[yval, xval] + im3.data[yval, xval] + im4.data[yval, xval])/4\n",
    "print('Averaged value = ', avgvalue)\n",
    "print()\n",
    "\n",
    "print('Brightness of selected pixel in averaged image', selectedavgstar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at background subtracted data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at background image\n",
    "subtracted_images = glob.glob('*bsub.fits')\n",
    "\n",
    "for bkgsubimage in subtracted_images:\n",
    "    bkgsub = ImageModel(bkgsubimage)\n",
    "\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.imshow(bkgsub.data, cmap='rainbow', origin='lower', vmin=-10,vmax=5)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    print('background region values', bkgsub.data[850, 500])\n",
    "    try:\n",
    "        np.testing.assert_allclose(bkgsub.data[850, 500], 0.01, atol=0.8)\n",
    "    except:\n",
    "        print('Subtracted background value is not near zero')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"testing\"></a>\n",
    "# Passing criteria\n",
    "\n",
    "Examine the images shown and the pixel values reported through the notebook. If the averaged background image is subtracted from the science images (subtracted background values nearer 0), and the averaged background image shows a smooth background with the sources removed, then this test passes. The four background images should be averaged together after the sources were rejected via sigma clipping. Check that the subtracted background values are near 0.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook extension: Look at combined image\n",
    "\n",
    "Create combined image through calwebb_image2 and calwebb_image3 to see what combined background subtracted image looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe2 = Image2Pipeline()\n",
    "# Set pipeline parameters\n",
    "pipe2.save_results = True\n",
    "pipe2.bkg_subtract.sigma = 2  # Set this in order to catch the outliers and leave only background\n",
    "pipe2.bkg_subtract.maxiters = 3\n",
    "pipe2.bkg_subtract.save_combined_background = True \n",
    "\n",
    "pipe2.save_bsub = True\n",
    "\n",
    "pipe2.run('imager_bkgsubtest_asn.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use asn_from_list to create association table\n",
    "\n",
    "calfiles = glob.glob('*_cal.fits')\n",
    "asn = asn_from_list.asn_from_list(calfiles, rule=DMS_Level3_Base, product_name='prop2754_bkgsub_combined.fits')\n",
    "\n",
    "# dump association table to a .json file for use in image3\n",
    "with open('prop2754_bkgsub_combined.json', 'w') as fp:\n",
    "    fp.write(asn.dump()[1])\n",
    "\n",
    "print(asn) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up options for skymatch that will find and subtract background sky levels to leave background in final combined image near zero.\n",
    "Matching method that subtracts background sky to use: 'global+match'\n",
    "\n",
    "The default method, 'match' does not subtract background to near zero, which in this case, would leave a negative background value after the background subtraction done in calwebb_image2.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Image3 to combine images\n",
    "\n",
    "# Put in parameters needed to give better source finding results\n",
    "\n",
    "# set any specific parameters\n",
    "# tweakreg parameters to allow data to run\n",
    "fwhm = 7.312  # Gaussian kernel FWHM of objects expected, default=2.5\n",
    "minobj = 5  # minimum number of objects needed to match positions for a good fit, default=15\n",
    "snr = 100 # signal to noise threshold, default=5\n",
    "sigma = 3 # clipping limit, in sigma units, used when performing fit, default=3\n",
    "fit_geom ='shift' # ftype of affine transformation to be considered when fitting catalogs, default='general'\n",
    "use2dhist = False  # boolean indicating whether to use 2D histogram to find initial offset, default=True\n",
    "matchmeth = 'global+match'\n",
    "matchdown = True\n",
    "matchsub = False\n",
    "\n",
    "pipe3 = calwebb_image3.Image3Pipeline()    \n",
    "pipe3.tweakreg.kernel_fwhm = fwhm\n",
    "pipe3.tweakreg.snr_threshold = snr\n",
    "pipe3.tweakreg.minobj = minobj\n",
    "pipe3.tweakreg.sigma = sigma\n",
    "pipe3.tweakreg.fitgeometry = fit_geom\n",
    "pipe3.tweakreg.use2dhist = use2dhist\n",
    "pipe3.source_catalog.kernel_fwhm = fwhm\n",
    "pipe3.source_catalog.snr_threshold = snr\n",
    "pipe3.skymatch.skymethod = matchmeth\n",
    "pipe3.skymatch.match_down = matchdown\n",
    "pipe3.skymatch.subtract = matchsub\n",
    "pipe3.skymatch.save_results = True\n",
    "pipe3.outlier_detection.save_results = True\n",
    "pipe3.resample.save_results = True\n",
    "pipe3.source_catalog.save_results = True\n",
    "pipe3.save_results = True\n",
    "\n",
    "pipe3.run('prop2754_bkgsub_combined.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in i2d combined Image\n",
    "im_i2d = ImageModel('prop2754_bkgsub_combined_i2d.fits') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sky match methods \n",
    "    Method               \n",
    "    local                          \n",
    "    global                          \n",
    "    match\n",
    "    global+match\n",
    "    \n",
    "The value found by skymatch is the background level calculated for the overall sky value. If skymatch.subtract is True, the subtraction will be done in the skymatch step. If subtract= False, the subtraction is done in the resample step. \n",
    "\n",
    "If the match option is used, the sky values are normalized to either the lowest or highest value (set by match_down) and delta levels are subtracted for each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the level of background calculated in the sky_match step\n",
    "print('Skymatch method used :',im_i2d.meta.background.method)\n",
    "print('Sky level calculated in skymatch step and subtracted from cal images while being combined.')\n",
    "print(im_i2d.meta.background.level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "#plt.imshow(viz2(im_i2d.data), origin='lower')\n",
    "plt.imshow(im_i2d.data, origin='lower', cmap='rainbow', vmin=-1, vmax=5)\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** M Cracraft, Principal Staff Scientist, INS/MIRI branch\n",
    "<br>**Updated On:** 01/13/23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
