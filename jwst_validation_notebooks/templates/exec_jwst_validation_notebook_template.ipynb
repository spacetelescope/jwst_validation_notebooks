{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Notebook: \n",
    "# < pipeline name >, < step name>\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: e.g., FGS, MIRI, NIRCam, NIRISS, NIRSpec \n",
    "\n",
    "### Table of Contents\n",
    "Follow this general outline. Additional sections may be added and others can be excluded, as needed. Sections in with a (\\*) symbol are required.\n",
    "\n",
    "<div style=\"text-align: left\"> \n",
    "    \n",
    "<br> [Introduction\\*](#intro)\n",
    "<br> [JWST CalWG Algorithm\\*](#algorithm)\n",
    "<br> [Defining Terms](#terms)\n",
    "<br> [Test Description\\*](#description)\n",
    "<br> [Data Description\\*](#data_descr)\n",
    "<br> [Imports\\*](#imports)\n",
    "<br> [Loading the Data\\*](#data_load)\n",
    "<br> [Run the Pipeline](#pipeline)\n",
    "<br> [Perform Tests or Visualization](#testing) \n",
    "<br> [About This Notebook\\*](#about)\n",
    "<br>    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Introduction\n",
    "\n",
    "Give a short introduction explaining the purpose of this notebook and providing relevant links. Here is an example: \n",
    "\n",
    "> This is the validation notebook for the source catalog step. This step creates a final catalog of source photometry and morphologies. Here we are testing the step for accuracy of the catalog. For more information on the pipeline step visit the links below. \n",
    "\n",
    "> Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/source_catalog/index.html\n",
    "\n",
    "> Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/source_catalog\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"algorithm\"></a>\n",
    "# JWST CalWG Algorithm\n",
    "\n",
    "Provide a short description of the implemented algorithm, and/or link to the Confluence page.\n",
    "\n",
    "For example: \n",
    "> https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Point+Source+CatalogÂ \n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"terms\"></a>\n",
    "# Defining Terms\n",
    "\n",
    "If necessary, provide terms or acronymns that may not be known a general audience (i.e., a new team member or an external user). For example:\n",
    "\n",
    "> JWST: James Webb Space Telescope\n",
    "\n",
    "> NIRSpec: Near-Infrared Spectrogragh\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"description\"></a>\n",
    "# Test Description\n",
    "Provide a description of the test that is being performed.\n",
    "\n",
    "For example:\n",
    "\n",
    ">This test is performed by creating a set of simulated data with multiple point sources located at specified coordinates. The simulator puts in the expected distortion, so the initial output data comes out of the simulator in distorted coordinates. When this data is then run through calwebb_detector1, calwebb_image2 and calwebbb_image3, the combined, undistorted image should have the point sources registered at the expected locations. In flight, this test can be repeated with known stars that should be found at their expected coordinates.\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_descr\"></a>\n",
    "# Data Description\n",
    "Provide a description of the test data that is being used.\n",
    "\n",
    "For example:\n",
    "\n",
    ">The set of data used in this particular test were created with the MIRI Data Simulator (MIRISim). The simulator created four imaging mode files, two exposures each at two different dither positions, using the specified filter.\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tempdir\"></a>\n",
    "# Set up Temporary Directory\n",
    "The following cell sets up a temporary directory (using python's `tempfile.TemporaryDirectory()`), and changes the script's active directory into that directory (using python's `os.chdir()`). This is so that, when the notebook is run through, it will download files to (and create output files in) the temporary directory rather than in the notebook's directory. This makes cleanup significantly easier (since all output files are deleted when the notebook is shut down), and also means that different notebooks in the same directory won't interfere with each other when run by the automated webpage generation process.\n",
    "\n",
    "If you want the notebook to generate output in the notebook's directory, simply don't run this cell.\n",
    "\n",
    "If you have a file (or files) that are kept in the notebook's directory, and that the notebook needs to use while running, you can copy that file into the directory (the code to do so is present below, but commented out).\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T23:10:55.487188Z",
     "iopub.status.busy": "2021-02-24T23:10:55.486867Z",
     "iopub.status.idle": "2021-02-24T23:10:55.489047Z",
     "shell.execute_reply": "2021-02-24T23:10:55.488715Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "import shutil\n",
    "data_dir = TemporaryDirectory()\n",
    "\n",
    "# If you have files that are in the notebook's directory, but that the notebook will need to use while\n",
    "# running, copy them into the temporary directory here.\n",
    "#\n",
    "# files = ['name_of_file']\n",
    "# for file_name in files:\n",
    "#     shutil.copy(file_name, os.path.join(data_dir.name, file_name))\n",
    "\n",
    "os.chdir(data_dir.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "# Imports\n",
    "List the package imports and why they are relevant to this notebook.\n",
    "\n",
    "\n",
    "* astropy.io for opening fits files\n",
    "* inspect to get the docstring of our objects.\n",
    "* IPython.display for printing markdown output\n",
    "* jwst.datamodels for building model for JWST Pipeline\n",
    "* jwst.module.PipelineStep is the pipeline step being tested\n",
    "* matplotlib.pyplot.plt to generate plot\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-24T23:10:55.490935Z",
     "iopub.status.busy": "2021-02-24T23:10:55.490606Z",
     "iopub.status.idle": "2021-02-24T23:10:55.492194Z",
     "shell.execute_reply": "2021-02-24T23:10:55.491909Z"
    }
   },
   "outputs": [],
   "source": [
    "# import inspect\n",
    "# from astropy.io import fits\n",
    "# from IPython.display import Markdown\n",
    "# from jwst.datamodels import RampModel\n",
    "# from jwst.module import PipelineStep\n",
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_load\"></a>\n",
    "# Loading the Data\n",
    "\n",
    "### Data for internal use: Artifactory method\n",
    "Artifactory should be used for data that is for internal use only.\n",
    "\n",
    "1. Create a [Jira \"Task\" Issue in the JWST Simulations Jira project](https://jira.stsci.edu/issues/?jql=project%20%3D%20JWSTSIMS%20AND%20resolution%20%3D%20Unresolved%20ORDER%20BY%20priority%20DESC%2C%20updated%20DESC) requesting to have your data added to Artifactory. Assign the ticket to Misty Cracraft ([@cracraft](https://github.com/cracraft)) or Alicia Canipe ([@aliciacanipe](https://github.com/aliciacanipe)), and provide more information about the data: simulation information, data location, and pipeline step(s). Once your data has been added to Artifactory, Misty Cracraft ([@cracraft](https://github.com/cracraft)) or Alicia Canipe ([@aliciacanipe](https://github.com/aliciacanipe)) will resolve the issue and notify you that your data is ready to be used (the full path to the data will be provided by the person who notified you that your data was ingested successfully).  \n",
    "\n",
    "2. Make sure you have the proper OS environmental variable set to access STScI's instance of Artifactory. This can be done via command line or put into a setup file like a ```.bash_profile``` file.\n",
    "\n",
    "```\n",
    "export TEST_BIGDATA=https://bytesalad.stsci.edu/artifactory/\n",
    "```\n",
    "\n",
    "3. Make sure your environment has ```ci_watson``` installed.\n",
    "```\n",
    "pip install ci_watson\n",
    "```\n",
    "\n",
    "4. In your notebook, import the ```ci_watson``` package needed.\n",
    "\n",
    "```python\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "```\n",
    "\n",
    "5. Read in each file stored in Artifactory (the full path should have been provided by the person who ingested the data).\n",
    "\n",
    "```python\n",
    "satfile = get_bigdata('jwst_validation_notebooks',\n",
    "                                     'validation_data',\n",
    "                                     'jump',\n",
    "                                    'jump_miri_test',\n",
    "                                    'miri_sat_55k.fits')\n",
    "```\n",
    "\n",
    "### Data for external use: Box method\n",
    "Artifactory is only accessible to internal users on the STScI network. If you would like to contribute a test notebook that uses externally available data, this test data should be stored in a Box folder instead. The final workflow using Box is still in discussion, but for now you can use a Box folder with the correct permissions set up:\n",
    "\n",
    "```python\n",
    "from astropy.utils.data import download_file\n",
    "\n",
    "main_box_url =\"https://data.science.stsci.edu/redirect/JWST/TSO/pipeline_testing_miri_ima_tso/\"\n",
    "filename = 'pipetest_miri_imtso_FULL_10g10i_F770W.fits'\n",
    "file = download_file(mainurl+filename)\n",
    "```\n",
    "\n",
    "Box assigns a default alpha-numerical string as the filename, so you may want to update the filename before processing, or verify that the format is correct. Depending on the data, you can try:\n",
    "\n",
    "```python\n",
    "# open file into correct format and write to local disk for processing\n",
    "hdu = fits.open(file)\n",
    "hdu.info()\n",
    "hdu.writeto(filename)\n",
    "```\n",
    "or use a ```jwst datamodel```:\n",
    "\n",
    "```python\n",
    "from jwst.datamodels import RampModel\n",
    "model = RampModel(file)\n",
    "model.save(filename)\n",
    "```\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "# Run the Steps or Pipeline\n",
    "\n",
    "Run the steps or the pipeline whose outputs will be validated for this test. For example:\n",
    "\n",
    "```python\n",
    "# import the pipeline you want to run (e.g., ramps-to-slopes)\n",
    "from jwst.pipeline import calwebb_detector1\n",
    "\n",
    "# initialize\n",
    "m = calwebb_detector1.Detector1Pipeline()\n",
    "\n",
    "# make changes to the parameters/reference files used\n",
    "m.saturation.override_saturation = 'mysatfile.fits'\n",
    "m.superbias.override_superbias = 'mysuperbias.fits'\n",
    "m.refpix.odd_even_rows = False\n",
    "\n",
    "# skip steps you don't want to run\n",
    "m.group_scale.skip = True\n",
    "m.ipc.skip = True\n",
    "m.dark_current.skip = True\n",
    "m.persistence.skip = True\n",
    "\n",
    "# name your output file\n",
    "m.output_file = 'myoutputfilename.fits'\n",
    "\n",
    "# run the pipeline with these paramters\n",
    "m.run('uncalfile.fits')\n",
    "```  \n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"testing\"></a>\n",
    "# Perform Tests or Visualization\n",
    "\n",
    "Perform the validation tests described previously. Generate plots, tables, diagnostics, etc. \n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** Author Name, Job Title, Branch Name\n",
    "<br>**Updated On:** MM/DD/YYYY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
