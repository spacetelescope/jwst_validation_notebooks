{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Testing Notebook: MIRI LRS Slitless\n",
    "\n",
    "## Spec2: Extract1d()\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: MIRI\n",
    "\n",
    "### Table of Contents\n",
    "<div style=\"text-align: left\"> \n",
    "\n",
    "<br> [Imports](#imports_ID) <br> [Introduction](#intro_ID) <br> [Get Documentaion String for Markdown Blocks](#markdown_from_docs) <br> [Loading Data](#data_ID) <br> [Run JWST Pipeline](#pipeline_ID) <br> [Create Figure or Print Output](#residual_ID) <br> [About This Notebook](#about_ID) <br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "data_dir = TemporaryDirectory()\n",
    "os.chdir(data_dir.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports_ID\"></a>\n",
    "# Imports\n",
    "List the library imports and why they are relevant to this notebook.\n",
    "\n",
    "* os, glob for general  OS operations\n",
    "* numpy\n",
    "* astropy.io for opening fits files\n",
    "* inspect to get the docstring of our objects.\n",
    "* IPython.display for printing markdown output\n",
    "* jwst.datamodels for building model for JWST Pipeline\n",
    "* jwst.module.PipelineStep is the pipeline step being tested\n",
    "* matplotlib.pyplot to generate plot\n",
    "* json for editing json files\n",
    "* crds for retrieving reference files as needed\n",
    "* ci_watson for data retrieval from artifactory\n",
    "* scipy.interpolate\n",
    "* gwcs.wcstools for retrieving the bounding box\n",
    "\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.testing import assert_allclose\n",
    "import os\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d, interp2d\n",
    "\n",
    "import astropy.io.fits as fits\n",
    "import astropy.units as u\n",
    "import jwst.datamodels as datamodels\n",
    "from jwst.datamodels import RampModel, ImageModel\n",
    "from jwst.pipeline import Detector1Pipeline, Spec2Pipeline\n",
    "from jwst.extract_1d import Extract1dStep\n",
    "from gwcs.wcstools import grid_from_bounding_box\n",
    "from jwst.associations.asn_from_list import asn_from_list\n",
    "from jwst.associations.lib.rules_level2_base import DMSLevel2bBase\n",
    "\n",
    "\n",
    "import json\n",
    "import crds\n",
    "\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "# Introduction\n",
    "\n",
    "\n",
    "In this notebook we will test the **extract1d()** step of Spec2Pipeline() for **LRS slitless** observations. LRS slitless observations are always time series observations.\n",
    "\n",
    "Step description: https://jwst-pipeline.readthedocs.io/en/stable/jwst/extract_1d/index.html\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/extract_1d\n",
    "\n",
    "### Short description of the algorithm\n",
    "\n",
    "Slitless observations are not nodded. The algorithm in its default settings centres on the source and extracts using a fixed-width aperture. The default aperture is 11 pixels wide.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_ID\"></a>\n",
    "# Loading Data\n",
    "\n",
    "We are using here a simulated LRS slit observation, generated with MIRISim v2.3.0 (as of Dec 2020). It is a simple time series observation modelled on a known exoplanet host, using ngroups=100 and nints=10.\n",
    "\n",
    "We retrieve the data from artifactory.\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Slitlessfile = get_bigdata('jwst_validation_notebooks',\n",
    "                                     'validation_data',\n",
    "                                     'calwebb_tso3',\n",
    "                                    'tso3_miri_test',\n",
    "                                    'pipetest_miri_lrs_tso_100G10I.fits')\n",
    "\n",
    "det1_configfile = get_bigdata('jwst_validation_notebooks',\n",
    "                                     'validation_data',\n",
    "                                     'calwebb_tso3',\n",
    "                                    'tso3_miri_test',\n",
    "                                    'calwebb_tso1.cfg')\n",
    "\n",
    "spec2_configfile = get_bigdata('jwst_validation_notebooks',\n",
    "                                     'validation_data',\n",
    "                                     'calwebb_tso3',\n",
    "                                    'tso3_miri_test',\n",
    "                                    'calwebb_tso-spec2.cfg')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect configuration files locally if they aren't yet there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if not os.path.exists('../cfg_files/'):\n",
    "#    os.mkdir('../cfg_files/')\n",
    "#    cfgs = collect_pipeline_cfgs.collect_pipeline_cfgs(dst='../cfg_files/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline_ID\"></a>\n",
    "# Run JWST Pipeline\n",
    "\n",
    "First we run the data through the Detector1() pipeline to convert the raw counts into slopes. This should use the calwebb_tso1.cfg file. The output of this stage will then be run through the Spec2Pipeline. Extract_1d is the final step of this pipeline stage, so we will just run through the whole pipeline, explicitly also saving the Photom() step output for comparison.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detector1Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det1 = Detector1Pipeline.call(Slitlessfile, config_file=det1_configfile, save_results=True)\n",
    "rifile = glob('*tso*_rateints.fits')\n",
    "print(rifile)\n",
    "\n",
    "det1_ints = datamodels.open(rifile[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spec2Pipeline\n",
    "\n",
    "Next we go ahead to the Spec2 pipeline. First we run the Spec2Pipeline() **skipping** the extract1d() step. Then we run the extract_1d() step separately and examine the output. We will run the step with default parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipe2 = Spec2Pipeline()\n",
    "#pipe2.extract_1d.skip = True\n",
    "#pipe2.photom.save_results = True\n",
    "\n",
    "#sp2 = pipe2(det1_ints)\n",
    "\n",
    "sp2 = Spec2Pipeline.call(det1_ints,save_results=True, config_file=spec2_configfile, steps={\"extract_1d\": {\"skip\": True}})\n",
    "print(sp2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calfile = glob('*tso*_calints.fits')\n",
    "print(calfile)\n",
    "\n",
    "print(np.shape(sp2[0].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retrieve the wcs information from the PHOTOM output file so we know the coordinates of the bounding box and the wavelength grid. We use the ``grid_from_bounding_box`` function to generate these grids. We convert the wavelength grid into a wavelength vector by averaging over each row. This works because LRS distortion is minimal, so lines of equal wavelength run along rows (not 100% accurate but for this purpose this is correct).\n",
    "\n",
    "This cell performs a check that both nods have the same wavelength assignment over the full bounding box, which is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_w = sp2[0].meta.wcs.bounding_box[0][1] - sp2[0].meta.wcs.bounding_box[0][0]\n",
    "bbox_ht = sp2[0].meta.wcs.bounding_box[1][1] - sp2[0].meta.wcs.bounding_box[1][0]\n",
    "print('Model bbox = {0} '.format(sp2[0].meta.wcs.bounding_box))\n",
    "print('Model: Height x width of bounding box = {0} x {1} pixels'.format(bbox_ht, bbox_w))\n",
    "\n",
    "x,y = grid_from_bounding_box(sp2[0].meta.wcs.bounding_box)\n",
    "ra, dec, lam = sp2[0].meta.wcs(x, y)\n",
    "\n",
    "lam_vec = np.mean(lam, axis=1)\n",
    "\n",
    "imsub = sp2[0].data[:,int(np.min(y)):int(np.max(y)+1), int(np.min(x)):int(np.max(x)+1)]\n",
    "print('Cutout has dimensions ({0})'.format(np.shape(imsub)))\n",
    "print('The cutout was taken from pixel {0} to pixel {1} in x'.format(int(np.min(x)),int(np.max(x)+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we run the ``extract_1d()`` step on the same file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1d_pipe = Extract1dStep.call(sp2[0], save_results=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we replicate this extraction manually using the extraction width and source position. We find the source position from the spectral trace (this is pretty crude, but works okay). The extraction width is extracted from the json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extreffile='jwst_miri_extract1d_0004.json'\n",
    "basename=crds.core.config.pop_crds_uri(extreffile)\n",
    "path=crds.locate_file(basename,\"jwst\")\n",
    "jref = json.load(open(path))\n",
    "\n",
    "xwidth = jref['apertures'][1]['extract_width']\n",
    "disp_ax = jref['apertures'][1]['dispaxis']\n",
    "print(disp_ax)\n",
    "print('Pipeline will extract with aperture of {0} px'.format(xwidth))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell we plot the x-dispersion trace of the image at the middle point of the bounding box in the y-direction. We identify the x-coordinate of the spectral trace by just identifying the max pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate the mid point of the bounding box in the dispersion direction\n",
    "bb = sp2[0].meta.wcs.bounding_box\n",
    "bb_mid = int(np.round((sp2[0].meta.wcs.bounding_box[1][1] - sp2[0].meta.wcs.bounding_box[1][0]) / 2.))\n",
    "\n",
    "#trace = imsub[0, bb_mid, :]\n",
    "trace = sp2[0].data[0, bb_mid, :]\n",
    "pk_loc = np.argmax(trace)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(trace)\n",
    "plt.axvline(pk_loc, linestyle='--')\n",
    "plt.show()\n",
    "print('Peak location is at px {0}'.format(pk_loc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As part of the extraction procedure we also apply the aperture correction. This accounts for the flux loss as a function of extraction width and wavelength (no slit losses as this mode is slitless). The steps for this are:\n",
    "* retrieve the reference file and load as datamodel\n",
    "* perform a 2D interpolation to get a vector of aperture correction values for the extraction width and the wavelwengths in lam_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apcorr_file = 'jwst_miri_apcorr_0007.fits'\n",
    "\n",
    "# retrieve this file\n",
    "basename = crds.core.config.pop_crds_uri(apcorr_file)\n",
    "filepath = crds.locate_file(basename, \"jwst\")\n",
    "acref =  datamodels.open(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check that list item 1 is for slitlessprism\n",
    "ind = 1\n",
    "try:\n",
    "    assert acref.apcorr_table[ind]['subarray']=='SLITLESSPRISM'\n",
    "except:    \n",
    "    print(\"AssertionError: index does not correspond to the correct subarray!\")\n",
    "\n",
    "# first identify where the aperture width is in the \"size\" array\n",
    "size_ind = np.argwhere(acref.apcorr_table[ind]['size'] == xwidth)\n",
    "\n",
    "# take the vector from the apcorr_table at this location and extract. \n",
    "apcorr_vec = acref.apcorr_table[1]['apcorr'][:,size_ind[0][0]]\n",
    "print(np.shape(apcorr_vec))\n",
    "print(np.shape(acref.apcorr_table[1]['wavelength']))\n",
    "\n",
    "# now we create an interpolated vector of values corresponding to the lam_vec wavelengths. \n",
    "# NOTE: the wavelengths are running in descending order so make sure assume_sorted = FALSE\n",
    "intp_ac = interp1d(acref.apcorr_table[1]['wavelength'], apcorr_vec, assume_sorted=False)\n",
    "iapcorr = intp_ac(lam_vec)\n",
    "\n",
    "\n",
    "plt.figure(figsize=[10,6])\n",
    "plt.plot(acref.apcorr_table[1]['wavelength'], apcorr_vec, 'g-', label='ref file')\n",
    "plt.plot(lam_vec, iapcorr, 'r-', label='interpolated')\n",
    "#plt.plot(lam_vec, ac_vals, 'r-', label='aperture corrections for {} px ap'.format(xwidth))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xwidth_half = int(np.ceil(xwidth / 2))\n",
    "print('Half width for extraction = {0} px'.format(xwidth_half))\n",
    "\n",
    "x1ds = []\n",
    "\n",
    "# calculate the pixel area in sr\n",
    "pix_scale = 0.11 * u.arcsec\n",
    "pixar_as2 = pix_scale**2\n",
    "pixar_sr = pixar_as2.to(u.sr)\n",
    "\n",
    "\n",
    "\n",
    "# now convert flux from MJy/sr to Jy using the pixel area, and apply the aperture correction\n",
    "for i in range(sp2[0].meta.exposure.nints):\n",
    "    x1d_2d = sp2[0].data[i, 6:397, 32:43]\n",
    "    x1d = np.sum(x1d_2d, axis=1)\n",
    "    if (sp2[0].meta.bunit_data == 'MJy/sr'):\n",
    "        x1d_cal = x1d * pixar_sr.value * 1e6 * iapcorr\n",
    "    x1ds.append(x1d_cal)\n",
    "\n",
    "print(len(x1ds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, nrows=1, figsize=[15,4], sharex='col', sharey='row')\n",
    "plt.xlabel('wavelength')\n",
    "plt.ylabel('flux (Jy)')\n",
    "plt.ylim([0.004, 0.009])\n",
    "# plot just the first 3 integrations for quick visual inspection:\n",
    "for i in range(3):\n",
    "    ax[i].plot(lam_vec, x1ds[i], 'r-', label='manual cal')\n",
    "    ax[i].plot(x1d_pipe.spec[i].spec_table['WAVELENGTH'],x1d_pipe.spec[i].spec_table['FLUX'], 'g--', label='pipe cal'.format(i))\n",
    "    ax[i].set_title('integration {0}'.format(i+1))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we interpolate the manually extracted spectrum onto the pipeline-generated wavelength grid so we can compare them numerically.\n",
    "\n",
    "**We compute the percentage difference between the 2 and assert the mean of this difderence between 5 and 12 micron is <= 1 percent. If this next block passes without error, the test is successful.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=[16,10])\n",
    "\n",
    "diffs = []\n",
    "\n",
    "for ii, xx in enumerate(x1ds):\n",
    "    plti = ii+1\n",
    "    ax = fig.add_subplot(5, 2, plti)\n",
    "    f = interp1d(lam_vec, xx, kind='linear', fill_value='extrapolate')\n",
    "    ixsub_cal = f(x1d_pipe.spec[ii].spec_table['WAVELENGTH'])\n",
    "    diff = ((x1d_pipe.spec[ii].spec_table['FLUX'] - ixsub_cal) / x1d_pipe.spec[ii].spec_table['FLUX']) * 100.\n",
    "    ax.plot(x1d_pipe.spec[ii].spec_table['WAVELENGTH'], diff, label='int {0}'.format(plti))\n",
    "    ax.axhline(y=1.0, xmin=0., xmax=1., color='r', ls='--')\n",
    "    ax.axhline(y=-1.0, xmin=0., xmax=1., color='r', ls='--')\n",
    "    ax.set_ylim([-10., 10])\n",
    "    \n",
    "    inds = (x1d_pipe.spec[ii].spec_table['WAVELENGTH'] >= 5.0) & (x1d_pipe.spec[ii].spec_table['WAVELENGTH'] <= 12.)\n",
    "    ax.annotate('mean diff 5-12 um = {:.2f}%'.format(np.mean(diff[inds])), xy=(0.1, 0.1), xycoords='axes fraction')\n",
    "    try:\n",
    "        assert np.mean(diff[inds]) <= 1.0\n",
    "    except:    \n",
    "        print(\"AssertionError: Mean difference between pipeline and manual extraction >= 1 per cent in 5-12 um. CHECK.\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Authors: B. Sargent/S. Kendrew, MIRI branch\n",
    "* Last updated: Feb 4th, 2021"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
