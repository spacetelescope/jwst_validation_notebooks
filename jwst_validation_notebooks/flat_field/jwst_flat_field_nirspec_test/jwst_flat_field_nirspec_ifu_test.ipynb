{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Testing Notebook: spec2, flat_field step for ifu\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: NIRSpec \n",
    "\n",
    "Tested on CV3 data\n",
    "\n",
    "### Table of Contents\n",
    "<div style=\"text-align: left\"> \n",
    "\n",
    "<br> [Imports](#imports_ID) <br> [Introduction](#intro_ID) <br> [Testing Data Set](#data_ID) <br> [Run the JWST pipeline and flat_field validation tests](#pipeline_ID): [FS Full-Frame test](#FULLFRAME), [FS ALLSLITS test](#ALLSLITS), [MOS test](#MOS), [IFU test](#IFU) <br> [About This Notebook](#about_ID)<br> [Results](#results) <br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports_ID\"></a>\n",
    "# Imports\n",
    "The library imports relevant to this notebook are aready taken care of by importing PTT.\n",
    "\n",
    "* astropy.io for opening fits files\n",
    "* jwst.module.PipelineStep is the pipeline step being tested\n",
    "* matplotlib.pyplot.plt to generate plot\n",
    "\n",
    "NOTE: This notebook assumes that the pipeline version to be tested is already installed and its environment is activated.\n",
    "\n",
    "To be able to run this notebook you need to install nptt. \n",
    "\n",
    "If all goes well you will be able to import PTT.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "import shutil\n",
    "import os\n",
    "import urllib\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "use_tempdir = True\n",
    "if use_tempdir:\n",
    "    # Create temporary directory\n",
    "    data_dir = TemporaryDirectory()\n",
    "    # Save original directory\n",
    "    orig_dir = os.getcwd()\n",
    "    # Move to new directory\n",
    "    os.chdir(data_dir.name)\n",
    "\n",
    "# For info, print out where the script is running\n",
    "print(\"Running in {}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbpresent": {
     "id": "45177853-942e-4949-9e30-f544d70ef5f4"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "import psutil\n",
    "from astropy.io import fits\n",
    "\n",
    "# Only print a DeprecationWarning the first time it shows up, not every time.\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"once\", category=DeprecationWarning)\n",
    "    import jwst\n",
    "    from jwst.pipeline.calwebb_detector1 import Detector1Pipeline\n",
    "    from jwst.pipeline.calwebb_spec2 import Spec2Pipeline\n",
    "    from jwst.assign_wcs.assign_wcs_step import AssignWcsStep\n",
    "    from jwst.msaflagopen.msaflagopen_step import MSAFlagOpenStep\n",
    "    from jwst.extract_2d.extract_2d_step import Extract2dStep\n",
    "    from jwst.srctype.srctype_step import SourceTypeStep\n",
    "    from jwst.wavecorr.wavecorr_step import WavecorrStep\n",
    "    from jwst.flatfield.flat_field_step import FlatFieldStep\n",
    "\n",
    "# The latest version of NPTT is installed in the requirements text file at:\n",
    "# /jwst_validation_notebooks/environment.yml\n",
    "\n",
    "# import NPTT\n",
    "import nirspec_pipe_testing_tool as nptt\n",
    "\n",
    "# To get data from Artifactory\n",
    "from ci_watson.artifactory_helpers import get_bigdata\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print versions used for the pipeline and NPTT\n",
    "\n",
    "pipeline_version = jwst.__version__\n",
    "nptt_version = nptt.__version__\n",
    "\n",
    "print(\"Using jwst pipeline version: \", pipeline_version)\n",
    "print(\"Using NPTT version: \", nptt_version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro_ID\"></a>\n",
    "# Test Description\n",
    "\n",
    "The test is a direct comparison of the result of our implementation of the flat field step algorithm versus the pipeline's implementation, i.e.: \n",
    "              difference =  absolute( Flat_nirspec_implementation - Flat_pipeline)\n",
    "\n",
    "We expect the absolute difference to be of the order of 1x10^-6. We set this threshold by assuming that the difference should yield computer precision 1x10^-7 numbers. We then relaxed one order of magnitude due to interpolation differences in the algorithms.\n",
    "\n",
    "For the test to be considered PASSED, every single slit (for FS data), slitlet (for MOS data) or slice (for IFU data) in the input file has to pass. If there is any failure, the whole test will be considered as FAILED. \n",
    "\n",
    "The code for this test for Fixed Slits (FS) can be obtained from: https://github.com/spacetelescope/nirspec_pipe_testing_tool/blob/master/nirspec_pipe_testing_tool/calwebb_spec2_pytests/auxiliary_code/flattest_fs.py. For Multi Object Spectroscopy (MOS), the code is in the same repository but is named ```flattest_mos.py```, and for Integral Field Unit (IFU) data, the test is named ```flattest_ifu.py```.\n",
    "\n",
    "The input file is defined in the variable ```input_file``` (see section [Testing Data Set and Variable Setup](#data_ID)).\n",
    "\n",
    "Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/flatfield/main.html\n",
    "\n",
    "Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/flatfield\n",
    "\n",
    "\n",
    "### Test Results\n",
    "\n",
    "If the test **PASSED** this means that all slits, slitlets, or slices individually passed the test. However, if ony one individual slit (for FS data), slitlet (for MOS data) or slice (for IFU data) test failed, the whole test will be reported as **FAILED**.\n",
    "\n",
    "\n",
    "### Calibration WG Requested Algorithm: \n",
    "\n",
    "A short description and link to the page: https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Spectral+Flat+Field+Correction\n",
    "\n",
    "\n",
    "### Defining Term\n",
    "Acronymns used un this notebook:\n",
    "\n",
    "pipeline: calibration pipeline\n",
    "\n",
    "spec2: spectroscopic calibration pipeline level 2b\n",
    "\n",
    "PTT: NIRSpec pipeline testing tool (https://github.com/spacetelescope/nirspec_pipe_testing_tool)\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline_ID\"></a>\n",
    "# Run the JWST pipeline and assign_wcs validation tests\n",
    "\n",
    "The pipeline can be run from the command line in two variants: full or per step.\n",
    "\n",
    "Tu run the spec2 pipeline in full use the command: \n",
    "\n",
    "$ strun jwst.pipeline.Spec2Pipeline jwtest_rate.fits\n",
    "\n",
    "Tu only run the flat_field step, use the command:\n",
    "\n",
    "$ strun jwst.flat_field.FlatFieldStep jwtest_extract_2d.fits\n",
    "\n",
    "These options are also callable from a script with the testing environment active. The Python call for running the pipeline in full or by step are:\n",
    "\n",
    "$\\gt$ from jwst.pipeline.calwebb_spec2 import Spec2Pipeline\n",
    "\n",
    "$\\gt$ Spec2Pipeline.call(jwtest_rate.fits)\n",
    " \n",
    "or\n",
    " \n",
    "$\\gt$ from jwst.flat_field.flat_field_step import FlatFieldStep\n",
    " \n",
    "$\\gt$ FlatFieldStep.call(jwtest_extract_2d.fits)\n",
    "\n",
    "For the imaging pipeline the call would be as follows:\n",
    "\n",
    "$\\gt$ from jwst.pipeline.calwebb_image2 import Image2Pipeline\n",
    "\n",
    "$\\gt$ Image2Pipeline.call(jwtest_rate.fits)\n",
    "\n",
    "NPTT can run the spec2 pipeline either in full or per step, as well as the imaging pipeline in full. In this notebook we will use NPTT to run the pipeline and the validation tests. To run NPTT, follow the directions in the corresponding repo page.\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> For each mode, the following variables will need to be set:\n",
    "- output_directory = string, path where you want intermediary files and plots to be saved in, if writefile=True\n",
    "- input_file = string or object, this is the output file from the previous step, e.g. jwtest1_NRS1_extract2d.fits\n",
    "- dflat_path = string, path of where the D-flat reference fits files\n",
    "- sflat_path = string, path of where the S-flat reference fits files\n",
    "- fflat_path = string, path of where the F-flat reference fits files\n",
    "- writefile = boolean, if True writes the fits files of the calculated flat, and the difference jpeg images\n",
    "- save_figs = boolean, whether to save plots or not\n",
    "- show_figs = boolean, whether to show plots or not \n",
    "- threshold_diff = float, threshold difference between pipeline output and ESA file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_ID\"></a>\n",
    "# Testing Data Set\n",
    "\n",
    "All testing data is from the CV3 campaign. We chose these files because this is our most complete data set, i.e. all modes and filter-grating combinations.\n",
    "\n",
    "Data used was for testing:\n",
    "- IFU_G395H_F290LP \n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_data = {\n",
    "\n",
    "                'ifu_g395h_f290lp':{\n",
    "                                  'uncal_file_nrs1': 'ifu_g395h_f290lp_nrs1_uncal.fits',\n",
    "                                  'uncal_file_nrs2': 'ifu_g395h_f290lp_nrs2_uncal.fits',\n",
    "                                  'msa_shutter_config': None }\n",
    "\n",
    "                }\n",
    "\n",
    "               \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to pull data from Artifactory\n",
    "def get_artifactory_file(data_set_dict, detector):\n",
    "    \"\"\"This function creates a list with all the files needed per detector to run the test.\n",
    "    Args:\n",
    "        data_set_dict: dictionary, contains inputs for a specific mode and configuration\n",
    "        detector: string, either nrs1 or nrs2\n",
    "    Returns:\n",
    "        data: list, contains all files needed to run test\n",
    "    \"\"\"\n",
    "    files2obtain = ['uncal_file_nrs1', 'msa_shutter_config']\n",
    "    data = []\n",
    "    for file in files2obtain:\n",
    "        data_file = None\n",
    "        try: \n",
    "            if '_nrs' in file and '2' in detector:\n",
    "                file = file.replace('_nrs1', '_nrs2')\n",
    "\n",
    "            data_file = get_bigdata('jwst_validation_notebooks',\n",
    "                                         'validation_data',\n",
    "                                         'nirspec_data', \n",
    "                                         data_set_dict[file])\n",
    "        except TypeError:\n",
    "            data.append(None)\n",
    "            continue\n",
    "\n",
    "        data.append(data_file)\n",
    "\n",
    "    return data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set NPTT switches for this test and other variables\n",
    "writefile = True   # needs to be true for test to complete\n",
    "save_figs = False\n",
    "show_figs = True\n",
    "results_dict = {}\n",
    "detectors = ['nrs1', 'nrs2']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data for IFU\n",
    "\n",
    "for mode_config, data_set_dict in testing_data.items():\n",
    "    if 'ifu' not in mode_config:\n",
    "        continue\n",
    "        \n",
    "    print('Starting to run pipeline and test for mode: ', mode_config)\n",
    "    \n",
    "    for detector in detectors:\n",
    "        print('Testing files for detector: ', detector)\n",
    "        data = get_artifactory_file(data_set_dict, detector)\n",
    "        uncal_file, msa_shutter_config = data\n",
    "        print('Working with uncal_file: ', uncal_file)\n",
    "        uncal_basename = os.path.basename(uncal_file)\n",
    "        \n",
    "        # Make sure these keywords are properly set\n",
    "        filt = fits.getval(uncal_file, 'FILTER')\n",
    "        # if unfortunately the filter was not set in upper case letters\n",
    "        if filt != filt.upper():\n",
    "            fits.setval(uncal_file, 'FILTER', value=filt.upper())\n",
    "        if 'OPAQUE' in filt or 'allslits' in uncal_basename.lower():\n",
    "            if 'clear' in uncal_basename.lower():\n",
    "                filt = 'CLEAR'\n",
    "            else:\n",
    "                l = uncal_basename.split(\"_\")\n",
    "                for li in l:\n",
    "                    if 'lp' in li.lower():\n",
    "                        filt = li\n",
    "                        break\n",
    "            fits.setval(uncal_file, 'FILTER', value=filt)\n",
    "        print('Filter = ', filt)\n",
    "\n",
    "        # Run the stage 1 pipeline \n",
    "        print('Running the detector1 pipeline...')\n",
    "        rate_object = Detector1Pipeline.call(uncal_file)\n",
    "        \n",
    "        # to check the latest set of reference files for spec2, change the OBS-DATE keyword\n",
    "        #rate_object.meta.observation.date = '2022-02-02'\n",
    "\n",
    "        # Make sure the FXD_SLIT keyword is set correctly\n",
    "        try:\n",
    "            if 'full' in rate_object.meta.instrument.fixed_slit:\n",
    "                rate_object.meta.instrument.fixed_slit = 'NONE'\n",
    "        except TypeError:\n",
    "            print('FXD_SLIT keyword = ', rate_object.meta.instrument.fixed_slit)\n",
    "        \n",
    "        # Run the stage 2 pipeline steps\n",
    "        print('\\nRunning the spec2 pipeline...')\n",
    "        skip_file = False\n",
    "        try:\n",
    "            parameter_dict = {\"assign_wcs\": {\"save_results\": True},\n",
    "                              \"flat_field\": {\"save_results\": True, \n",
    "                                             \"save_interpolated_flat\": True},\n",
    "                              \"pathloss\": {\"skip\": True},\n",
    "                              \"barshadow\": {\"skip\": True},\n",
    "                              \"photom\": {\"skip\": True},\n",
    "                              \"resample_spec\": {\"skip\": True},\n",
    "                              \"cube_build\": {\"skip\": True},\n",
    "                              \"extract_1d\": {\"skip\": True}\n",
    "                             }\n",
    "            flat_field_object = Spec2Pipeline.call(rate_object, steps=parameter_dict)\n",
    "        except Exception as e:\n",
    "            print(\"* Spec2 pipeline DID NOT RUN for detector \", detector)\n",
    "            print(\"   Traceback: \\n\", e)\n",
    "            skip_file = True\n",
    "            \n",
    "        if not skip_file:   \n",
    "            # get same the flat field reference files the pipeline used\n",
    "            if isinstance(flat_field_object, list):\n",
    "                flat_field_object = flat_field_object[0]\n",
    "            rf_flats = [flat_field_object.meta.ref_file.dflat.name, \n",
    "                        flat_field_object.meta.ref_file.fflat.name, \n",
    "                        flat_field_object.meta.ref_file.sflat.name]\n",
    "            obs_date = flat_field_object.meta.observation.date\n",
    "            rf_flats = [rf.replace(\"crds://\", \"\") for rf in rf_flats]\n",
    "            crds_url = \"https://jwst-crds.stsci.edu/unchecked_get/references/jwst/\"\n",
    "            for rf in rf_flats:\n",
    "                urllib.request.urlretrieve(crds_url+rf, rf)\n",
    "            dflat, fflat, sflat = rf_flats[0], rf_flats[1], rf_flats[2]\n",
    "            print('Flat field reference files used by the pipeline (will be used for the test too)')\n",
    "            print('  OBS-DATE = ', obs_date)\n",
    "            print('  D-flat = ', dflat)\n",
    "            print('  S-flat = ', sflat)\n",
    "            print('  F-flat = ', fflat)\n",
    "\n",
    "            # accepted threshold difference with respect to benchmark files\n",
    "            threshold_diff = 9.999e-5\n",
    "            if 'prism' in uncal_basename.lower():\n",
    "                threshold_diff = 9.999e-3\n",
    "            \n",
    "            # Run the validation test\n",
    "            %matplotlib inline\n",
    "            interpolated_flat = os.path.basename(uncal_file).replace('uncal', 'interpolatedflat')\n",
    "            print('Running flat field test for IFU...')\n",
    "            result, result_msg, log_msgs = nptt.calwebb_spec2_pytests.auxiliary_code.flattest_ifu.flattest(\n",
    "                                                                            flat_field_object,\n",
    "                                                                            dflat_path=dflat,\n",
    "                                                                            sflat_path=sflat, \n",
    "                                                                            fflat_path=fflat,\n",
    "                                                                            writefile=writefile,\n",
    "                                                                            mk_all_slices_plt=False, \n",
    "                                                                            show_figs=show_figs, \n",
    "                                                                            save_figs=save_figs,\n",
    "                                                                            interpolated_flat=interpolated_flat,\n",
    "                                                                            threshold_diff=threshold_diff,\n",
    "                                                                            debug=False)\n",
    "        else:\n",
    "            result, result_msg = 'skipped', 'skipped'\n",
    "\n",
    "        # Did the test passed \n",
    "        print(\"Did flat_field for \", mode_config, \" validation test passed? \", result_msg, \"\\n\\n\")\n",
    "        rd = {uncal_basename: result}\n",
    "        results_dict.update(rd)\n",
    "        \n",
    "        # close all open files\n",
    "        psutil.Process().open_files()\n",
    "        closing_files = []\n",
    "        for fd in psutil.Process().open_files():\n",
    "            if data_dir.name in fd.path:\n",
    "                closing_files.append(fd)\n",
    "        for fd in closing_files:\n",
    "            try:\n",
    "                print('Closing file: ', fd, '\\n\\n')\n",
    "                open(fd.fd).close()\n",
    "            except:\n",
    "                print('File already closed: ', fd, '\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quickly see if the test passed \n",
    "\n",
    "print('These are the final results of the tests: ')\n",
    "for key, val in results_dict.items():\n",
    "    if not isinstance(val, str):\n",
    "        if val:\n",
    "            val = 'PASSED'\n",
    "        else:\n",
    "            val = 'FAILED'\n",
    "    print('{:<42} {:<8}'.format(key, val))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** Maria Pe√±a-Guerrero, Sr. Science Software Engineer, NIRSpec\n",
    "<br>**Updated On:** Mar/10/2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
