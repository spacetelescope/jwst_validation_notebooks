{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"title_ID\"></a>\n",
    "# JWST Pipeline Validation Notebook: NIRCam, calwebb_image3, source_catalog\n",
    "\n",
    "<span style=\"color:red\"> **Instruments Affected**</span>: e.g., FGS, MIRI, NIRCam, NIRISS, NIRSpec \n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "<div style=\"text-align: left\"> \n",
    "    \n",
    "<br> [Introduction](#intro)\n",
    "<br> [JWST CalWG Algorithm](#algorithm)\n",
    "<br> [Defining Terms](#terms)\n",
    "<br> [Test Description](#description)\n",
    "<br> [Data Description](#data_descr)\n",
    "<br> [Set up Temporary Directory](#tempdir)\n",
    "<br> [Imports](#imports)\n",
    "<br> [Loading the Data](#data_load)\n",
    "<br> [Run the Image3Pipeline](#pipeline)\n",
    "<br> [Perform Visual Inspection](#visualization) \n",
    "<br> [Manually Find Matches](#manual)\n",
    "<br> [About This Notebook](#about)\n",
    "<br>    \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"intro\"></a>\n",
    "# Introduction\n",
    "\n",
    "This is the NIRCam validation notebook for the Source Catalog step, which generates a catalog based on input exposures.\n",
    "\n",
    "* Step description: https://jwst-pipeline.readthedocs.io/en/latest/jwst/source_catalog/index.html\n",
    "\n",
    "* Pipeline code: https://github.com/spacetelescope/jwst/tree/master/jwst/source_catalog\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"algorithm\"></a>\n",
    "# JWST CalWG Algorithm\n",
    "\n",
    "This is the NIRCam imaging validation notebook for the Source Catalog step, which uses image combinations or stacks of overlapping images to generate \"browse-quality\" source catalogs.  Having automated source catalogs will help accelerate the science output of JWST. The source catalogs should include both point and \"slightly\" extended sources at a minimum.  The catalog should provide an indication if the source is a point or an extended source. For point sources, the source catalog should include measurements corrected to infinite aperture using aperture corrections provided by a reference file.  \n",
    "\n",
    "See: \n",
    "* https://outerspace.stsci.edu/display/JWSTCC/Vanilla+Point+Source+Catalog\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"terms\"></a>\n",
    "# Defining Terms\n",
    "\n",
    "* JWST: James Webb Space Telescope\n",
    "\n",
    "* NIRCam: Near-Infrared Camera\n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"description\"></a>\n",
    "# Test Description\n",
    "\n",
    "Here we generate the source catalog and visually inspect a plot of the image with the source catalog overlaid. We also look at some other diagnostic plots and then cross-check the output catalog against Mirage catalog inputs. \n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_descr\"></a>\n",
    "# Data Description\n",
    "\n",
    "The set of data used in this test were created with the Mirage simulator. The simulator created a NIRCam imaging mode exposures for the short wave NRCA1 detector. \n",
    "\n",
    "\n",
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"tempdir\"></a>\n",
    "# Set up Temporary Directory\n",
    "The following cell sets up a temporary directory (using python's `tempfile.TemporaryDirectory()`), and changes the script's active directory into that directory (using python's `os.chdir()`). This is so that, when the notebook is run through, it will download files to (and create output files in) the temporary directory rather than in the notebook's directory. This makes cleanup significantly easier (since all output files are deleted when the notebook is shut down), and also means that different notebooks in the same directory won't interfere with each other when run by the automated webpage generation process.\n",
    "\n",
    "If you want the notebook to generate output in the notebook's directory, simply don't run this cell.\n",
    "\n",
    "If you have a file (or files) that are kept in the notebook's directory, and that the notebook needs to use while running, you can copy that file into the directory (the code to do so is present below, but commented out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#****\n",
    "#\n",
    "# Set this variable to False to not use the temporary directory\n",
    "#\n",
    "#****\n",
    "use_tempdir = True\n",
    "\n",
    "# Create a temporary directory to hold notebook output, and change the working directory to that directory.\n",
    "from tempfile import TemporaryDirectory\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "if use_tempdir:\n",
    "    data_dir = TemporaryDirectory()\n",
    "\n",
    "    # If you have files that are in the notebook's directory, but that the notebook will need to use while\n",
    "    # running, copy them into the temporary directory here.\n",
    "    #\n",
    "    # files = ['name_of_file']\n",
    "    # for file_name in files:\n",
    "    #     shutil.copy(file_name, os.path.join(data_dir.name, file_name))\n",
    "\n",
    "    # Save original directory\n",
    "    orig_dir = os.getcwd()\n",
    "\n",
    "    # Move to new directory\n",
    "    os.chdir(data_dir.name)\n",
    "\n",
    "# For info, print out where the script is running\n",
    "print(\"Running in {}\".format(os.getcwd()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if 'CRDS_CACHE_TYPE' in os.environ:\n",
    "    if os.environ['CRDS_CACHE_TYPE'] == 'local':\n",
    "        os.environ['CRDS_PATH'] = os.path.join(os.environ['HOME'], 'crds', 'cache')\n",
    "    elif os.path.isdir(os.environ['CRDS_CACHE_TYPE']):\n",
    "        os.environ['CRDS_PATH'] = os.environ['CRDS_CACHE_TYPE']\n",
    "print('CRDS cache location: {}'.format(os.environ['CRDS_PATH']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"imports\"></a>\n",
    "# Imports\n",
    "List the package imports and why they are relevant to this notebook.\n",
    "\n",
    "\n",
    "* astropy for various tools and packages\n",
    "* inspect to get the docstring of our objects.\n",
    "* IPython.display for printing markdown output\n",
    "* jwst.datamodels for JWST Pipeline data models\n",
    "* jwst.module.PipelineStep is the pipeline step being tested\n",
    "* matplotlib.pyplot.plt to generate plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting, the inline must come before the matplotlib import\n",
    "%matplotlib inline\n",
    "# %matplotlib notebook\n",
    "\n",
    "# These gymnastics are needed to make the sizes of the figures\n",
    "# be the same in both the inline and notebook versions\n",
    "%config InlineBackend.print_figure_kwargs = {'bbox_inches': None}\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['savefig.dpi'] = 80\n",
    "mpl.rcParams['figure.dpi'] = 80\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "params = {'legend.fontsize': 6,\n",
    "          'figure.figsize': (8, 8),\n",
    "          'figure.dpi': 150,\n",
    "         'axes.labelsize': 6,\n",
    "         'axes.titlesize': 6,\n",
    "         'xtick.labelsize':6,\n",
    "         'ytick.labelsize':6}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "# Box download imports \n",
    "from astropy.utils.data import download_file\n",
    "from pathlib import Path\n",
    "from shutil import move\n",
    "from os.path import splitext\n",
    "\n",
    "# python general\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# astropy modules\n",
    "import astropy\n",
    "from astropy.io import fits\n",
    "from astropy.table import QTable, Table, vstack, unique\n",
    "from astropy.wcs.utils import skycoord_to_pixel\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.visualization import simple_norm\n",
    "from astropy import units as u\n",
    "import photutils\n",
    "\n",
    "# jwst \n",
    "from jwst.pipeline import calwebb_image3\n",
    "from jwst import datamodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image(data_2d, xpixel=None, ypixel=None, title=None):\n",
    "    ''' Function to generate a 2D image of the data, \n",
    "    with an option to highlight a specific pixel.\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    norm = simple_norm(data_2d, 'sqrt', percent=99.)\n",
    "    \n",
    "    plt.imshow(data_2d, norm=norm, origin='lower', cmap='gray')\n",
    "    \n",
    "    if xpixel and ypixel:\n",
    "        plt.plot(xpixel, ypixel, marker='o', color='red', label='Selected Pixel')\n",
    "\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.colorbar(label='MJy/sr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_with_cat(data_2d, catalog, flux_limit=None, title=None):\n",
    "    ''' Function to generate a 2D image of the data, \n",
    "    with sources overlaid.\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    norm = simple_norm(data_2d, 'sqrt', percent=99.)\n",
    "    \n",
    "    plt.imshow(data_2d, norm=norm, origin='lower', cmap='gray')\n",
    "    \n",
    "    for row in catalog:\n",
    "        if flux_limit:\n",
    "            if np.isnan(row['aper_total_flux']):\n",
    "                pass\n",
    "            else:\n",
    "                if row['aper_total_flux'] > flux_limit:\n",
    "                    plt.plot(row['xcentroid'], row['ycentroid'], marker='o', markersize='3', color='red')\n",
    "        else:\n",
    "            plt.plot(row['xcentroid'], row['ycentroid'], marker='o', markersize='1', color='red')\n",
    "\n",
    "    plt.xlabel('Pixel column')\n",
    "    plt.ylabel('Pixel row')\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)\n",
    "\n",
    "    plt.subplots_adjust(left=0.15)\n",
    "    plt.colorbar(label='MJy/sr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_scatterplot(catalog_colx, catalog_coly, title=None):\n",
    "    ''' Function to generate a generic scatterplot.\n",
    "    '''\n",
    "    \n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = plt.subplot()\n",
    "    ax.scatter(catalog_colx,catalog_coly) \n",
    "    plt.xlabel(catalog_colx.name)\n",
    "    plt.ylabel(catalog_coly.name)\n",
    "\n",
    "    \n",
    "    if title:\n",
    "        plt.title(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input_table(sourcelist):\n",
    "    '''Function to read in and access the simulator source input files.'''\n",
    "\n",
    "    all_source_table = Table()\n",
    "\n",
    "    # point source and galaxy source tables have different headers\n",
    "    # change column headers to match for filtering later\n",
    "    if \"point\" in sourcelist:\n",
    "        col_names = [\"RA\", \"Dec\", \"RA_degrees\", \"Dec_degrees\",\n",
    "                     \"PixelX\", \"PixelY\", \"Magnitude\",\n",
    "                     \"counts_sec\", \"counts_frame\"]\n",
    "    elif \"galaxy\" in sourcelist:\n",
    "        col_names = [\"PixelX\", \"PixelY\", \"RA\", \"Dec\",\n",
    "                     \"RA_degrees\", \"Dec_degrees\", \"V2\", \"V3\", \"radius\",\n",
    "                     \"ellipticity\", \"pos_angle\", \"sersic_index\",\n",
    "                     \"Magnitude\", \"countrate_e_s\", \"counts_per_frame_e\"]\n",
    "    else:\n",
    "        print('Error! Source list column names need to be defined.')\n",
    "        sys.exit(0)\n",
    "\n",
    "    # read in the tables\n",
    "    input_source_table = Table.read(sourcelist,format='ascii')\n",
    "    orig_colnames = input_source_table.colnames\n",
    "\n",
    "    # only grab values for source catalog analysis\n",
    "    short_source_table = Table({'In_RA': input_source_table['RA_degrees'],\n",
    "                              'In_Dec': input_source_table['Dec_degrees']},\n",
    "                              names=['In_RA', 'In_Dec'])\n",
    "\n",
    "    # combine source lists into one master list\n",
    "    all_source_table = vstack([all_source_table, short_source_table])\n",
    "\n",
    "    # set up columns to track which sources were detected by Photutils\n",
    "    all_source_table['Out_RA'] = np.nan\n",
    "    all_source_table['Out_Dec'] = np.nan\n",
    "    all_source_table['Detected'] = 'N'\n",
    "    all_source_table['RA_Diff'] = np.nan\n",
    "    all_source_table['Dec_Diff'] = np.nan\n",
    "\n",
    "    # filter by RA, Dec (for now)\n",
    "    no_duplicates = unique(all_source_table,keys=['In_RA','In_Dec'])\n",
    "\n",
    "    return no_duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"data_load\"></a>\n",
    "# Loading the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulated exposures used for this test are stored in Box. Grab them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box_files(file_list):\n",
    "    for box_url,file_name in file_list:\n",
    "        if 'https' not in box_url:\n",
    "            box_url = 'https://stsci.box.com/shared/static/' + box_url\n",
    "        downloaded_file = download_file(box_url, timeout=600)\n",
    "        if Path(file_name).suffix == '':\n",
    "            ext = splitext(box_url)[1]\n",
    "            file_name += ext\n",
    "        move(downloaded_file, file_name)\n",
    "\n",
    "file_urls = ['https://stsci.box.com/shared/static/72fds4rfn4ppxv2tuj9qy2vbiao110pc.fits', \n",
    "             'https://stsci.box.com/shared/static/gxwtxoz5abnsx7wriqligyzxacjoz9h3.fits', \n",
    "             'https://stsci.box.com/shared/static/tninaa6a28tsa1z128u3ffzlzxr9p270.fits',\n",
    "             'https://stsci.box.com/shared/static/g4zlkv9qi0vc5brpw2lamekf4ekwcfdn.json',\n",
    "             'https://stsci.box.com/shared/static/kvusxulegx0xfb0uhdecu5dp8jkeluhm.list']\n",
    "\n",
    "file_names = ['jw00042002001_01101_00004_nrca5_cal.fits', \n",
    "             'jw00042002001_01101_00005_nrca5_cal.fits', \n",
    "             'jw00042002001_01101_00006_nrca5_cal.fits',\n",
    "             'level3_lw_imaging_files_asn.json',\n",
    "             'jw00042002001_01101_00004_nrca5_uncal_galaxySources.list']\n",
    "\n",
    "box_download_list = [(url,name) for url,name in zip(file_urls,file_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_box_files(box_download_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"pipeline\"></a>\n",
    "# Run the Image3Pipeline\n",
    "\n",
    "Run calwebb_image3 to get the output source catalog and the final 2D image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3 = calwebb_image3.Image3Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3.assign_mtwcs.skip=True\n",
    "img3.save_results=True\n",
    "img3.resample.save_results=True\n",
    "img3.source_catalog.snr_threshold = 5\n",
    "img3.source_catalog.save_results=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "img3.run(file_names[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"visualization\"></a>\n",
    "# Perform Visual Inspection\n",
    "\n",
    "Perform the visual inspection of the catalog and the final image. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = Table.read(\"lw_imaging_cat.ecsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_image = datamodels.ImageModel(\"lw_imaging_i2d.fits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_image(combined_image.data, title=\"Final combined NIRCam image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_image_with_cat(combined_image.data, catalog, title=\"Final image w/ catalog overlaid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "create_scatterplot(catalog['label'], catalog['aper_total_flux'],title='Total Flux in '+str(catalog['aper_total_flux'].unit))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_scatterplot(catalog['label'], catalog['aper_total_abmag'],title='Total AB mag')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"manual\"></a>\n",
    "# Manually Find Matches \n",
    "\n",
    "Since this is a simulated data set, we can compare the output catalog information from the pipeline with the input catalog information used to create the simulation. Grab the input catalog RA, Dec values and the output catalog RA, Dec values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_outputs = get_input_table(file_names[4])\n",
    "in_ra = test_outputs['In_RA'].data\n",
    "in_dec = test_outputs['In_Dec'].data\n",
    "out_ra = catalog['sky_centroid'].ra.deg\n",
    "out_dec = catalog['sky_centroid'].dec.deg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the tolerance and initialize our counters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tol = 1.e-3\n",
    "found_count=0\n",
    "multiples_count=0\n",
    "missed_count=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we loop through the input RA, Dec values and compare them to the RA, Dec values in the output catalog. For cases where there are multiple matches for our tolerance level, count those cases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ra,dec,idx in zip(in_ra, in_dec,range(len(test_outputs))):\n",
    "\n",
    "    match = np.where((np.abs(ra-out_ra) < tol) & (np.abs(dec-out_dec) < tol))\n",
    "    \n",
    "    if np.size(match) == 1: \n",
    "        found_count +=1 \n",
    "        test_outputs['Detected'][idx] = 'Y'\n",
    "        test_outputs['Out_RA'][idx] = out_ra[match]\n",
    "        test_outputs['Out_Dec'][idx] = out_dec[match]\n",
    "        test_outputs['RA_Diff'][idx] = np.abs(ra-out_ra[match])\n",
    "        test_outputs['Dec_Diff'][idx] = np.abs(dec-out_dec[match])  \n",
    "\n",
    "    if np.size(match) > 1:  \n",
    "        multiples_count +=1       \n",
    "        \n",
    "    if np.size(match) < 1:\n",
    "        missed_count +=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how it did. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_percent_found = (found_count/len(test_outputs))*100\n",
    "\n",
    "print('\\n')\n",
    "print('SNR threshold used for pipeline: ',img3.source_catalog.snr_threshold)\n",
    "print('Total found:',found_count)\n",
    "print('Total missed:',missed_count)\n",
    "print('Number of multiples: ',multiples_count)\n",
    "print('Total number of input sources:',len(test_outputs))\n",
    "print('Total number in output catalog:',len(catalog))\n",
    "print('Total percent found:',total_percent_found)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use photutils to find catalog matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Photutils includes a package to match sources between catalogs by providing a max separation value. Set that value and compare the two catalogs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog_in = SkyCoord(ra=in_ra*u.degree, dec=in_dec*u.degree)\n",
    "catalog_out = SkyCoord(ra=out_ra*u.degree, dec=out_dec*u.degree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sep = 1.0 * u.arcsec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx, d2d, d3d = cat_in.match_to_catalog_3d(cat_out)\n",
    "idx, d2d, d3d = catalog_in.match_to_catalog_sky(catalog_out)\n",
    "sep_constraint = d2d < max_sep\n",
    "catalog_in_matches = catalog_in[sep_constraint]\n",
    "catalog_out_matches = catalog_out[idx[sep_constraint]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, ```catalog_in_matches``` and ```catalog_out_matches``` are the matched sources in ```catalog_in``` and ```catalog_out```, respectively, which are separated less than our ```max_sep``` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of matched sources using max separation of '+str(max_sep)+': ',len(catalog_out_matches))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"about_ID\"></a>\n",
    "## About this Notebook\n",
    "**Author:** Alicia Canipe, Senior Staff Scientist, NIRCam\n",
    "<br>**Updated On:** 05/26/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Top of Page](#title_ID)\n",
    "<img style=\"float: right;\" src=\"./stsci_pri_combo_mark_horizonal_white_bkgd.png\" alt=\"stsci_pri_combo_mark_horizonal_white_bkgd\" width=\"200px\"/> "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
